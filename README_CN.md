# Data Pipeline Ingestion Agent (æ•°æ®æŠ½å–æ™ºèƒ½Agent)

æ™ºèƒ½æ•°æ®æŠ½å–Agentï¼Œæ”¯æŒè‡ªç„¶è¯­è¨€ã€è¡¨å•æˆ–YAML/JSONé…ç½®ï¼Œè‡ªåŠ¨ç”ŸæˆPySpark ETLä»£ç å¹¶æäº¤åˆ°Azure Databricksã€‚

## æ ¸å¿ƒç‰¹æ€§

- ğŸ¤– **æ™ºèƒ½è‡ªç„¶è¯­è¨€è§£æ**: æ”¯æŒä¸­æ–‡å’Œè‹±æ–‡æè¿°ï¼Œè‡ªåŠ¨è¯†åˆ«æº/ç›®æ ‡æ•°æ®åº“ä¿¡æ¯
- ğŸ“ **å¯è§†åŒ–è¡¨å•**: å¼•å¯¼å¼å¡«å†™ï¼Œé™ä½ä½¿ç”¨é—¨æ§›
- ğŸ“„ **YAML/JSONé…ç½®**: é€‚åˆé«˜çº§ç”¨æˆ·å’Œè‡ªåŠ¨åŒ–åœºæ™¯
- ğŸ¯ **è‡ªåŠ¨éªŒè¯**: ç¼ºå°‘å¿…è¦ä¿¡æ¯æ—¶ä¼šæç¤ºç”¨æˆ·è¡¥å……
- â˜ï¸ **Azure Databricksé›†æˆ**: ä¸€é”®æäº¤åˆ°Databricks clusteræ‰§è¡Œ

## å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒé…ç½®
```bash
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶
```

å¿…å¡«ç¯å¢ƒå˜é‡ï¼š
```bash
AZURE_DATABRICKS_HOST=https://adb-xxx.azuredatabricks.net
AZURE_DATABRICKS_TOKEN=dapi***
DEFAULT_DATABRICKS_CLUSTER_ID=xxx-xxx-xxx
DEFAULT_UNITY_CATALOG=xxxxx
```

### 2. å®‰è£…
```bash
pip install -e .[ui]
```

### 3. å¯åŠ¨UI
```bash
streamlit run src/ingestion_agent/ui/streamlit_app.py
```

## ä½¿ç”¨æ–¹å¼

### æ–¹å¼1: è‡ªç„¶è¯­è¨€
```
ä» postgres hostname=mydb.postgres.database.azure.com 
æ•°æ®åº“=production è¡¨=public.orders 
ç”¨æˆ·å=admin å¯†ç =pass123 
æŠ½å–æ•°æ®ï¼Œå†™å…¥è¡¨ test.orders
```

è‡ªåŠ¨è¯†åˆ«ï¼š
- âœ… æ•°æ®åº“ç±»å‹ (postgres/mysql/sqlserver)
- âœ… è¿æ¥ä¿¡æ¯ (hostname:port/database)
- âœ… è¡¨å (schema.table)
- âœ… å‡­è¯ (username/password)
- âœ… ç›®æ ‡è¡¨ (catalog.schema.table)

### æ–¹å¼2: è¡¨å•å¡«å†™ ï¼ˆæ¨èï¼‰
1. é€‰æ‹©"Form (è¡¨å•)"æ¨¡å¼
2. å¡«å†™æºæ•°æ®åº“ä¿¡æ¯
3. å¡«å†™å‡­è¯ï¼ˆç”¨æˆ·åå¯†ç ï¼‰
4. å¡«å†™ç›®æ ‡è¡¨ä¿¡æ¯
5. ç‚¹å‡»"Generate from Form"

### æ–¹å¼3: YAMLé…ç½®
```yaml
job_name: ingest_pgsql_to_databricks
description: "Extract data from PostgreSQL and load to Databricks Unity Catalog bronze layer"

source:
  type: postgres                 # Options: postgres, mysql, sqlserver
  jdbc_url: jdbc:postgresql://[å¡«å†™ä¸»æœºå].postgres.database.chinacloudapi.cn:5432/[å¡«å†™æ•°æ®åº“å]
  table: public.orders           # Format: schema.table (PostgreSQL defaults to 'public' schema)
  frequency: daily
  # increment_field: updated_at  # Optional: for incremental extraction
  options:
    user: [å¡«å†™ç”¨æˆ·å]
    password: [å¡«å†™å¯†ç ]
    sslmode: require             # Required for Azure PostgreSQL
sink:
  type: delta                    # Always use delta for Unity Catalog
  catalog: uc_tarhone            # Unity Catalog name (must be created in workspace)
  database: test                 # Schema name in Unity Catalog
  table: orders                  # Table name
  layer: bronze                  # Options: bronze, silver, gold
  mode: overwrite                # Options: overwrite, append
  options: {}                    # Additional Delta Lake options (usually empty for managed tables)
  # path: abfss://container@storage.dfs.core.chinacloudapi.cn/bronze/test/orders  # Auto-generated for managed tables
```

## å¿…è¦ä¿¡æ¯

### æºæ•°æ®åº“
- âœ… æ•°æ®åº“ç±»å‹
- âœ… ä¸»æœºåœ°å€
- âœ… æ•°æ®åº“å
- âœ… è¡¨å (schema.table)
- âœ… ç”¨æˆ·å
- âœ… å¯†ç 

### ç›®æ ‡ (Databricks)
- âœ… Schemaåç§°
- âœ… è¡¨åç§°
- âœ… Catalog
- âœ… æ¨¡å¼: é»˜è®¤ overwrite

## ğŸ” å®‰å…¨æç¤º

**å½“å‰**: æ”¯æŒæ˜æ–‡å¯†ç ï¼ˆä»…å¼€å‘/æµ‹è¯•ï¼‰

**ç”Ÿäº§ç¯å¢ƒ**ï¼ˆè¯¦è§ SECURITY.mdï¼‰:
1. Azure Key Vault
2. Databricks Secrets
3. Managed Identity

## å¸¸è§é—®é¢˜

**Q: Catalog not found?**
```sql
CREATE CATALOG IF NOT EXISTS uc_tarhone;
CREATE SCHEMA IF NOT EXISTS uc_tarhone.test;
```

**Q: å¦‚ä½•ä¿æŠ¤å¯†ç ?**
å‚è€ƒ `SECURITY.md`

**Q: æ”¯æŒå“ªäº›æ•°æ®åº“?**
PostgreSQL, MySQL, SQL Server/Azure SQL

## æ–‡æ¡£

- [English README](README.md)
- [å®‰å…¨æœ€ä½³å®è·µ](SECURITY.md)
- [ç¤ºä¾‹é…ç½®](src/ingestion_agent/examples/)
