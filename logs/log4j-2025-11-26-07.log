25/11/26 07:00:03 WARN DriverDaemon: Unexpected exception: java.lang.NullPointerException
java.lang.NullPointerException
	at org.apache.spark.sql.internal.SharedState.getSchedulerStats(SharedState.scala:416)
	at org.apache.spark.sql.SQLContext.getSchedulerStats(SQLContext.scala:768)
	at com.databricks.backend.daemon.driver.DriverCorral$.getAutoscalingInfo(DriverCorral.scala:1712)
	at com.databricks.backend.daemon.driver.DriverCorral.com$databricks$backend$daemon$driver$DriverCorral$$handleRPCRequest(DriverCorral.scala:1079)
	at com.databricks.backend.daemon.driver.DriverCorral$$anonfun$receive$1.applyOrElse(DriverCorral.scala:1128)
	at com.databricks.backend.daemon.driver.DriverCorral$$anonfun$receive$1.applyOrElse(DriverCorral.scala:1126)
	at com.databricks.rpc.ServerBackend.$anonfun$internalReceive$2(ServerBackend.scala:119)
	at com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)
	at com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)
	at com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:116)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:657)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:678)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)
	at com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:652)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:569)
	at com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:528)
	at com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:24)
	at com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:115)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleRPC$2(JettyServer.scala:958)
	at scala.util.Try$.apply(Try.scala:213)
	at com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:958)
	at com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:874)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2(JettyServer.scala:503)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2$adapted(JettyServer.scala:478)
	at com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:387)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:53)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)
	at com.databricks.logging.activity.ActivityContextFactory$.withAttributionTags(ActivityContextFactory.scala:53)
	at com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:381)
	at com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:164)
	at com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:478)
	at com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:375)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:523)
	at com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:550)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:80)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.lang.Thread.run(Thread.java:750)
25/11/26 07:00:08 WARN DriverDaemon: Unexpected exception: java.lang.NullPointerException
java.lang.NullPointerException
	at org.apache.spark.sql.internal.SharedState.getSchedulerStats(SharedState.scala:416)
	at org.apache.spark.sql.SQLContext.getSchedulerStats(SQLContext.scala:768)
	at com.databricks.backend.daemon.driver.DriverCorral$.getAutoscalingInfo(DriverCorral.scala:1712)
	at com.databricks.backend.daemon.driver.DriverCorral.com$databricks$backend$daemon$driver$DriverCorral$$handleRPCRequest(DriverCorral.scala:1079)
	at com.databricks.backend.daemon.driver.DriverCorral$$anonfun$receive$1.applyOrElse(DriverCorral.scala:1128)
	at com.databricks.backend.daemon.driver.DriverCorral$$anonfun$receive$1.applyOrElse(DriverCorral.scala:1126)
	at com.databricks.rpc.ServerBackend.$anonfun$internalReceive$2(ServerBackend.scala:119)
	at com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)
	at com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)
	at com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:116)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:657)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:678)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)
	at com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:652)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:569)
	at com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:528)
	at com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:24)
	at com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:115)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleRPC$2(JettyServer.scala:958)
	at scala.util.Try$.apply(Try.scala:213)
	at com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:958)
	at com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:874)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2(JettyServer.scala:503)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2$adapted(JettyServer.scala:478)
	at com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:387)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:53)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)
	at com.databricks.logging.activity.ActivityContextFactory$.withAttributionTags(ActivityContextFactory.scala:53)
	at com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:381)
	at com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:164)
	at com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:478)
	at com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:375)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:523)
	at com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:550)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:80)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.lang.Thread.run(Thread.java:750)
25/11/26 07:00:11 INFO ProgressReporter$: Removed result fetcher for 2081346830872482017_7571052252010323293_job-929358892198333-run-400333104312677-action-5022948843659687
25/11/26 07:00:11 WARN PythonDriverWrapper: Spark is detected to be down after running a command
25/11/26 07:00:11 WARN PythonDriverWrapper: Fatal exception (spark down) in ReplId-1ce26-dea4c-8a10e-1
com.databricks.backend.common.rpc.SparkStoppedException: Spark down: 
	at com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:636)
	at com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:663)
	at com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$runInnerLoop$1(DriverWrapper.scala:503)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:70)
	at com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:503)
	at com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:438)
	at com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:262)
	at java.lang.Thread.run(Thread.java:750)
25/11/26 07:00:11 INFO PythonDriverLocalBase$RedirectThread: Python RedirectThread exit
25/11/26 07:00:11 INFO PythonDriverLocalBase$RedirectThread: Python RedirectThread exit
25/11/26 07:00:11 INFO ReplCrashUtils$: python shell exit code: 143
25/11/26 07:00:11 INFO ReplCrashUtils$: strace is not enabled. To turn it on, set the Spark conf `spark.databricks.driver.strace.enabled` to true.
25/11/26 07:00:12 INFO DrainingState: Started draining: min wait 10000, grace period 5000, max wait 15000.
25/11/26 07:00:13 WARN DriverDaemon: Unexpected exception: java.lang.NullPointerException
java.lang.NullPointerException
	at org.apache.spark.sql.internal.SharedState.getSchedulerStats(SharedState.scala:416)
	at org.apache.spark.sql.SQLContext.getSchedulerStats(SQLContext.scala:768)
	at com.databricks.backend.daemon.driver.DriverCorral$.getAutoscalingInfo(DriverCorral.scala:1712)
	at com.databricks.backend.daemon.driver.DriverCorral.com$databricks$backend$daemon$driver$DriverCorral$$handleRPCRequest(DriverCorral.scala:1079)
	at com.databricks.backend.daemon.driver.DriverCorral$$anonfun$receive$1.applyOrElse(DriverCorral.scala:1128)
	at com.databricks.backend.daemon.driver.DriverCorral$$anonfun$receive$1.applyOrElse(DriverCorral.scala:1126)
	at com.databricks.rpc.ServerBackend.$anonfun$internalReceive$2(ServerBackend.scala:119)
	at com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)
	at com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)
	at com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:116)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:657)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:678)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)
	at com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:652)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:569)
	at com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:528)
	at com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:24)
	at com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:115)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleRPC$2(JettyServer.scala:958)
	at scala.util.Try$.apply(Try.scala:213)
	at com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:958)
	at com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:874)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2(JettyServer.scala:503)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2$adapted(JettyServer.scala:478)
	at com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:387)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:53)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)
	at com.databricks.logging.activity.ActivityContextFactory$.withAttributionTags(ActivityContextFactory.scala:53)
	at com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:381)
	at com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:164)
	at com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:478)
	at com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:375)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:523)
	at com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:550)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:80)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.lang.Thread.run(Thread.java:750)
25/11/26 07:00:17 INFO DrainingState: Grace period finished
25/11/26 07:00:17 INFO DrainingState: starting shutdown for com.databricks.rpc.JettyServer$$anon$2@113b38ca
25/11/26 07:00:17 INFO JettyServer$$anon$2: shutting down JettyServer
25/11/26 07:00:17 INFO DrainingState: finished shutdown for com.databricks.rpc.JettyServer$$anon$2@113b38ca
25/11/26 07:00:17 INFO DrainingState: Drain complete, exiting now.
25/11/26 07:00:17 INFO ShutdownHookManager: Shutdown hook called
25/11/26 07:00:17 INFO ShutdownHookManager: Deleting directory /local_disk0/tmp/spark-f3959364-7bc5-4f7a-8d90-57098fc00eaf
25/11/26 07:00:17 INFO ShutdownHookManager: Deleting directory /local_disk0/tmp/spark-223ead5a-515e-47eb-89d0-b7317a3842c1
25/11/26 07:00:17 INFO ShutdownHookManager: Deleting directory /local_disk0/spark-7ca06c49-bfb0-45ab-ba2b-bff2ad8db25c
25/11/26 07:00:17 INFO ShutdownHookManager: Deleting directory /local_disk0/spark-7ca06c49-bfb0-45ab-ba2b-bff2ad8db25c/pyspark-5ee4ddb1-62b8-48e2-adc3-f147a949f088
25/11/26 07:00:17 INFO ShutdownHookManager: Deleting directory /local_disk0/tmp/spark-79137f60-aa0d-4245-b8ac-c69780d41595
25/11/26 07:00:17 INFO ShutdownHookManager: Deleting directory /local_disk0/spark-7ca06c49-bfb0-45ab-ba2b-bff2ad8db25c/pyspark-92cf684c-b48d-4978-8abd-16d87e6aef2f
25/11/26 07:00:17 INFO ShutdownHookManager: Deleting directory /local_disk0/dbio_cache_root_574-9ed7a902-0679-42d3-a994-133a05da1172
25/11/26 07:00:17 INFO DriverDaemon$: Stopping Log4j2...
25/11/26 07:00:27 INFO DriverDaemon$: Started Log4j2
25/11/26 07:00:29 INFO DriverDaemon$: Current JVM Version 1.8.0_462
25/11/26 07:00:29 INFO DriverDaemon$: ========== driver starting up ==========
25/11/26 07:00:29 INFO DriverDaemon$: Java: Azul Systems, Inc. 1.8.0_462
25/11/26 07:00:29 INFO DriverDaemon$: OS: Linux/amd64 5.15.0-1091-azure
25/11/26 07:00:29 INFO DriverDaemon$: CWD: /databricks/driver
25/11/26 07:00:29 INFO DriverDaemon$: Mem: Max: 7.9G loaded GCs: PS Scavenge, PS MarkSweep
25/11/26 07:00:29 INFO DriverDaemon$: Logging multibyte characters: âœ“
25/11/26 07:00:29 INFO DriverDaemon$: 'publicFile.rolling.rewrite' appender in root logger: class org.apache.logging.log4j.core.appender.rewrite.RewriteAppender
25/11/26 07:00:29 INFO DriverDaemon$: == Modules:
25/11/26 07:00:30 INFO DriverDaemon$: Starting prometheus metrics log export timer
25/11/26 07:00:30 INFO DriverConf: Configured feature flag data source LaunchDarkly
25/11/26 07:00:30 INFO DriverConf: Configured feature flag data source LaunchDarkly
25/11/26 07:00:30 WARN DriverConf: REGION environment variable is not defined. getConfForCurrentRegion will always return default value
25/11/26 07:00:31 INFO DriverDaemon$: Loaded JDBC drivers in 52 ms
25/11/26 07:00:31 INFO DriverDaemon$: Universe Git Hash: f574797ba68fce84d3a50e05c13993f77f57aea0
25/11/26 07:00:31 INFO DriverDaemon$: Spark Git Hash: d0b1371a97d80366f49e5e050bac9e7922e31fd0
25/11/26 07:00:31 WARN SparkConfUtils$: Setting the same key twice for spark.hadoop.hive.server2.keystore.password
25/11/26 07:00:31 WARN SparkConfUtils$: Setting the same key twice for spark.databricks.io.directoryCommit.enableLogicalDelete
25/11/26 07:00:31 WARN SparkConfUtils$: Setting the same key twice for spark.hadoop.hive.server2.keystore.path
25/11/26 07:00:31 INFO SparkConfUtils$: Customize spark config according to file /tmp/custom-spark.conf
25/11/26 07:00:31 WARN RunHelpers$: Missing tag isolation client: java.util.NoSuchElementException: key not found: TagDefinition(clientType,The client type for a request, used for isolating resources for the request.,DATA_LABEL_SYSTEM_NOT_SENSITIVE,false,false,List(),UsageLogRedactionConfig(List()))
25/11/26 07:00:31 INFO DatabricksILoop$: Creating throwaway interpreter
25/11/26 07:00:31 INFO MetastoreMonitor$: Internal metastore configured
25/11/26 07:00:31 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:3306/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:00:31 INFO NestedConnectionMonitor$$anon$1: Configured feature flag data source LaunchDarkly
25/11/26 07:00:31 INFO NestedConnectionMonitor$$anon$1: Configured feature flag data source LaunchDarkly
25/11/26 07:00:31 WARN NestedConnectionMonitor$$anon$1: REGION environment variable is not defined. getConfForCurrentRegion will always return default value
25/11/26 07:00:31 INFO FeatureFlagRegisterConf: Configured feature flag data source LaunchDarkly
25/11/26 07:00:31 INFO FeatureFlagRegisterConf: Configured feature flag data source LaunchDarkly
25/11/26 07:00:31 WARN FeatureFlagRegisterConf: REGION environment variable is not defined. getConfForCurrentRegion will always return default value
25/11/26 07:00:31 INFO DriverCorral: Creating the driver context
25/11/26 07:00:31 INFO DatabricksILoop$: Class Server Dir: /local_disk0/tmp/repl/spark-1151128536340376051-09eaf8b0-9451-4628-a2ef-785e1bbf6667
25/11/26 07:00:31 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:00:31 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:00:31 WARN SparkConfUtils$: Setting the same key twice for spark.hadoop.hive.server2.keystore.password
25/11/26 07:00:31 WARN SparkConfUtils$: Setting the same key twice for spark.databricks.io.directoryCommit.enableLogicalDelete
25/11/26 07:00:31 WARN SparkConfUtils$: Setting the same key twice for spark.hadoop.hive.server2.keystore.path
25/11/26 07:00:31 INFO SparkConfUtils$: Customize spark config according to file /tmp/custom-spark.conf
25/11/26 07:00:31 WARN SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
25/11/26 07:00:31 INFO DynamicRpcConf: Configured feature flag data source LaunchDarkly
25/11/26 07:00:31 INFO DynamicRpcConf: Configured feature flag data source LaunchDarkly
25/11/26 07:00:31 WARN DynamicRpcConf: REGION environment variable is not defined. getConfForCurrentRegion will always return default value
25/11/26 07:00:32 INFO DatabricksILoop$: Cleaning expired driver directory pythonEnv-2d6622a0-0617-4f8a-8064-5b99ca270e58
25/11/26 07:00:32 INFO DatabricksILoop$: Cleaning expired driver directory pythonEnv-0b307e5e-7059-41a1-9ba8-90a1694acde5
25/11/26 07:00:32 INFO SparkContext: Running Spark version 3.3.2
25/11/26 07:00:32 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:00:32 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:00:32 INFO MetastoreMonitor: Metastore healthcheck successful (connection duration = 1481 milliseconds)
25/11/26 07:00:32 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:9207/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:00:32 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:00:32 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:00:32 INFO ResourceUtils: ==============================================================
25/11/26 07:00:32 INFO ResourceUtils: No custom resources configured for spark.driver.
25/11/26 07:00:32 INFO ResourceUtils: ==============================================================
25/11/26 07:00:32 INFO SparkContext: Submitted application: Databricks Shell
25/11/26 07:00:32 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 8874, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/11/26 07:00:32 INFO ResourceProfile: Limiting resource is cpu
25/11/26 07:00:32 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/11/26 07:00:33 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:00:33 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:00:33 INFO MetastoreMonitor: PoPProxy healthcheck successful (connection duration = 420 milliseconds)
25/11/26 07:00:33 INFO SecurityManager: Changing view acls to: root
25/11/26 07:00:33 INFO SecurityManager: Changing modify acls to: root
25/11/26 07:00:33 INFO SecurityManager: Changing view acls groups to: 
25/11/26 07:00:33 INFO SecurityManager: Changing modify acls groups to: 
25/11/26 07:00:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set(); RPC SSL disabled
25/11/26 07:00:33 INFO Utils: Successfully started service 'sparkDriver' on port 37321.
25/11/26 07:00:33 INFO SparkEnv: Registering MapOutputTracker
25/11/26 07:00:33 INFO SecurityManager: Changing view acls to: root
25/11/26 07:00:33 INFO SecurityManager: Changing modify acls to: root
25/11/26 07:00:33 INFO SecurityManager: Changing view acls groups to: 
25/11/26 07:00:33 INFO SecurityManager: Changing modify acls groups to: 
25/11/26 07:00:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set(); RPC SSL disabled
25/11/26 07:00:33 INFO SparkEnv: Registering BlockManagerMaster
25/11/26 07:00:33 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/11/26 07:00:33 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/11/26 07:00:33 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/11/26 07:00:33 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-fb673428-8b4f-4b40-8dbc-d29bd9836804
25/11/26 07:00:33 INFO MemoryStore: MemoryStore started with capacity 4.4 GiB
25/11/26 07:00:34 INFO SparkEnv: Registering OutputCommitCoordinator
25/11/26 07:00:34 INFO SparkContext: Spark configuration:
libraryDownload.sleepIntervalSeconds=5
libraryDownload.timeoutSeconds=180
spark.akka.frameSize=256
spark.app.name=Databricks Shell
spark.app.startTime=1764140432531
spark.cleaner.referenceTracking.blocking=false
spark.databricks.SC200982.blockBuiltInFunctionOverride=true
spark.databricks.acl.client=com.databricks.spark.sql.acl.client.SparkSqlAclClient
spark.databricks.acl.provider=com.databricks.sql.acl.ReflectionBackedAclProvider
spark.databricks.acl.scim.client=com.databricks.spark.sql.acl.client.DriverToWebappScimClient
spark.databricks.automl.serviceEnabled=true
spark.databricks.autotune.maintenance.client.classname=com.databricks.maintenanceautocompute.MACClientImpl
spark.databricks.cloudProvider=Azure
spark.databricks.cloudfetch.hasRegionSupport=true
spark.databricks.cloudfetch.requestDownloadUrlsWithHeaders=*********(redacted)
spark.databricks.cloudfetch.requesterClassName=*********(redacted)
spark.databricks.clusterSource=UI
spark.databricks.clusterUsageTags.attribute_tag_budget=
spark.databricks.clusterUsageTags.attribute_tag_dust_bazel_path=
spark.databricks.clusterUsageTags.attribute_tag_dust_execution_env=
spark.databricks.clusterUsageTags.attribute_tag_dust_maintainer=
spark.databricks.clusterUsageTags.attribute_tag_dust_resource_class=
spark.databricks.clusterUsageTags.attribute_tag_dust_runbot_id=
spark.databricks.clusterUsageTags.attribute_tag_dust_runner=
spark.databricks.clusterUsageTags.attribute_tag_dust_suite=
spark.databricks.clusterUsageTags.attribute_tag_platform_name=
spark.databricks.clusterUsageTags.attribute_tag_service=
spark.databricks.clusterUsageTags.autoTerminationMinutes=60
spark.databricks.clusterUsageTags.azureSubscriptionId=8cf1045d-f235-4fd3-beff-c67785d438b1
spark.databricks.clusterUsageTags.cloudProvider=Azure
spark.databricks.clusterUsageTags.clusterAllTags=[{"key":"Vendor","value":"Databricks"},{"key":"Creator","value":"fantian@tianfan.partner.onmschina.cn"},{"key":"ClusterName","value":"ai_pipeline"},{"key":"ClusterId","value":"1125-113639-ndjs76hq"},{"key":"DatabricksEnvironment","value":"workerenv-2559323315997869"}]
spark.databricks.clusterUsageTags.clusterAvailability=ON_DEMAND_AZURE
spark.databricks.clusterUsageTags.clusterCreator=Webapp
spark.databricks.clusterUsageTags.clusterFirstOnDemand=1
spark.databricks.clusterUsageTags.clusterGeneration=4
spark.databricks.clusterUsageTags.clusterId=1125-113639-ndjs76hq
spark.databricks.clusterUsageTags.clusterLastActivityTime=1764139715713
spark.databricks.clusterUsageTags.clusterLogDeliveryEnabled=false
spark.databricks.clusterUsageTags.clusterLogDestination=
spark.databricks.clusterUsageTags.clusterLogDestinationType=
spark.databricks.clusterUsageTags.clusterMaxWorkers=8
spark.databricks.clusterUsageTags.clusterMetastoreAccessType=RDS_DIRECT
spark.databricks.clusterUsageTags.clusterMinWorkers=1
spark.databricks.clusterUsageTags.clusterName=ai_pipeline
spark.databricks.clusterUsageTags.clusterNoDriverDaemon=false
spark.databricks.clusterUsageTags.clusterNodeType=Standard_D4ds_v5
spark.databricks.clusterUsageTags.clusterNodeTypeFlexibilityEnabled=false
spark.databricks.clusterUsageTags.clusterNumCustomTags=0
spark.databricks.clusterUsageTags.clusterNumSshKeys=0
spark.databricks.clusterUsageTags.clusterOwnerOrgId=2559323315997869
spark.databricks.clusterUsageTags.clusterOwnerUserId=*********(redacted)
spark.databricks.clusterUsageTags.clusterPinned=false
spark.databricks.clusterUsageTags.clusterPythonVersion=3
spark.databricks.clusterUsageTags.clusterResourceClass=default
spark.databricks.clusterUsageTags.clusterScalingType=autoscaling
spark.databricks.clusterUsageTags.clusterSizeType=VM_CONTAINER
spark.databricks.clusterUsageTags.clusterSku=STANDARD_SKU
spark.databricks.clusterUsageTags.clusterSpotBidMaxPrice=-1.0
spark.databricks.clusterUsageTags.clusterState=Restarting
spark.databricks.clusterUsageTags.clusterStateMessage=Starting Spark
spark.databricks.clusterUsageTags.clusterTargetWorkers=1
spark.databricks.clusterUsageTags.clusterUnityCatalogMode=*********(redacted)
spark.databricks.clusterUsageTags.clusterWorkers=1
spark.databricks.clusterUsageTags.computeKind=CLASSIC_PREVIEW
spark.databricks.clusterUsageTags.containerType=LXC
spark.databricks.clusterUsageTags.dataPlaneRegion=chinanorth3
spark.databricks.clusterUsageTags.driverContainerId=44e2732adecc4b9b93ef1e2854e94c28
spark.databricks.clusterUsageTags.driverContainerPrivateIp=10.139.64.5
spark.databricks.clusterUsageTags.driverInstanceId=2a145075d1af445bb31ad568cbdafffe
spark.databricks.clusterUsageTags.driverInstancePrivateIp=10.139.0.4
spark.databricks.clusterUsageTags.driverNodeType=Standard_D4ds_v5
spark.databricks.clusterUsageTags.driverPublicDns=52.130.161.173
spark.databricks.clusterUsageTags.effectiveSparkVersion=12.2.x-scala2.12
spark.databricks.clusterUsageTags.enableCredentialPassthrough=*********(redacted)
spark.databricks.clusterUsageTags.enableDfAcls=false
spark.databricks.clusterUsageTags.enableElasticDisk=true
spark.databricks.clusterUsageTags.enableGlueCatalogCredentialPassthrough=*********(redacted)
spark.databricks.clusterUsageTags.enableJdbcAutoStart=true
spark.databricks.clusterUsageTags.enableJobsAutostart=true
spark.databricks.clusterUsageTags.enableLocalDiskEncryption=false
spark.databricks.clusterUsageTags.enableSqlAclsOnly=false
spark.databricks.clusterUsageTags.hailEnabled=false
spark.databricks.clusterUsageTags.ignoreTerminationEventInAlerting=false
spark.databricks.clusterUsageTags.instanceWorkerEnvId=workerenv-2559323315997869
spark.databricks.clusterUsageTags.instanceWorkerEnvNetworkType=default
spark.databricks.clusterUsageTags.isDpCpPrivateLinkEnabled=false
spark.databricks.clusterUsageTags.isGroupCluster=false
spark.databricks.clusterUsageTags.isIMv2Enabled=true
spark.databricks.clusterUsageTags.isServicePrincipalCluster=false
spark.databricks.clusterUsageTags.isSingleNode=false
spark.databricks.clusterUsageTags.isSingleUserCluster=*********(redacted)
spark.databricks.clusterUsageTags.managedResourceGroup=databricks-rg-Databricks-cn3-prod-52ba56scwuu2k
spark.databricks.clusterUsageTags.ngrokNpipEnabled=false
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2=0
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Abfss=0
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Dbfs=0
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2File=0
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Gcs=0
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2S3=0
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Volumes=0
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Workspace=0
spark.databricks.clusterUsageTags.numPerGlobalInitScriptsV2=0
spark.databricks.clusterUsageTags.orgId=2559323315997869
spark.databricks.clusterUsageTags.privateLinkEnabled=false
spark.databricks.clusterUsageTags.region=chinanorth3
spark.databricks.clusterUsageTags.runtimeEngine=STANDARD
spark.databricks.clusterUsageTags.shardName=az-chinanorth2
spark.databricks.clusterUsageTags.sparkEnvVarContainsBacktick=false
spark.databricks.clusterUsageTags.sparkEnvVarContainsDollarSign=false
spark.databricks.clusterUsageTags.sparkEnvVarContainsDoubleQuotes=false
spark.databricks.clusterUsageTags.sparkEnvVarContainsEscape=false
spark.databricks.clusterUsageTags.sparkEnvVarContainsNewline=false
spark.databricks.clusterUsageTags.sparkEnvVarContainsSingleQuotes=false
spark.databricks.clusterUsageTags.sparkImageLabel=release__12.2.x-snapshot-scala2.12__databricks__12.2.62__f574797__d0b1371__jenkins__b6e50ce__format-3
spark.databricks.clusterUsageTags.sparkMasterUrlType=*********(redacted)
spark.databricks.clusterUsageTags.sparkVersion=12.2.x-scala2.12
spark.databricks.clusterUsageTags.userId=*********(redacted)
spark.databricks.clusterUsageTags.userProvidedRemoteVolumeCount=*********(redacted)
spark.databricks.clusterUsageTags.userProvidedRemoteVolumeSizeGb=*********(redacted)
spark.databricks.clusterUsageTags.userProvidedRemoteVolumeType=*********(redacted)
spark.databricks.clusterUsageTags.userProvidedSparkVersion=*********(redacted)
spark.databricks.clusterUsageTags.workerEnvironmentId=workerenv-2559323315997869
spark.databricks.credential.aws.secretKey.redactor=*********(redacted)
spark.databricks.credential.redactor=*********(redacted)
spark.databricks.credential.scope.fs.adls.gen2.tokenProviderClassName=*********(redacted)
spark.databricks.credential.scope.fs.gs.auth.access.tokenProviderClassName=*********(redacted)
spark.databricks.credential.scope.fs.impl=*********(redacted)
spark.databricks.credential.scope.fs.s3a.tokenProviderClassName=*********(redacted)
spark.databricks.delta.logStore.crossCloud.fatal=true
spark.databricks.delta.multiClusterWrites.enabled=true
spark.databricks.deltaSharing.clientClassName=com.databricks.deltasharing.DataSharingClientImpl
spark.databricks.driver.cleanUpSparkSessionsOnUCSharedClusters=true
spark.databricks.driver.enableDncOomMessage=false
spark.databricks.driver.preferredMavenCentralMirrorUrl=*********(redacted)
spark.databricks.driverNfs.clusterWidePythonLibsEnabled=true
spark.databricks.driverNfs.enabled=true
spark.databricks.driverNfs.pathSuffix=.ephemeral_nfs
spark.databricks.driverNodeTypeId=Standard_D4ds_v5
spark.databricks.enablePublicDbfsFuse=false
spark.databricks.eventLog.dir=eventlogs
spark.databricks.eventLog.enabled=true
spark.databricks.eventLog.listenerClassName=com.databricks.backend.daemon.driver.DBCEventLoggingListener
spark.databricks.instanceId=2a145075d1af445bb31ad568cbdafffe
spark.databricks.io.cache.initialDiskSize=161061273600
spark.databricks.io.directoryCommit.enableLogicalDelete=false
spark.databricks.isShieldWorkspace=false
spark.databricks.managedCatalog.clientClassName=com.databricks.managedcatalog.ManagedCatalogClientImpl
spark.databricks.metrics.filesystem_io_metrics=true
spark.databricks.mlflow.autologging.enableGenAIFlavors=true
spark.databricks.mlflow.autologging.enabled=true
spark.databricks.overrideDefaultCommitProtocol=org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol
spark.databricks.passthrough.adls.gen2.tokenProviderClassName=*********(redacted)
spark.databricks.passthrough.adls.tokenProviderClassName=*********(redacted)
spark.databricks.passthrough.glue.credentialsProviderFactoryClassName=*********(redacted)
spark.databricks.passthrough.glue.executorServiceFactoryClassName=*********(redacted)
spark.databricks.passthrough.oauth.refresher.impl=*********(redacted)
spark.databricks.passthrough.s3a.threadPoolExecutor.factory.class=com.databricks.backend.daemon.driver.aws.S3APassthroughThreadPoolExecutorFactory
spark.databricks.passthrough.s3a.tokenProviderClassName=*********(redacted)
spark.databricks.preemption.enabled=true
spark.databricks.privateLinkEnabled=false
spark.databricks.proxyHadoopTraffic.host=storage-proxy.databricks.com
spark.databricks.proxyHadoopTraffic.port=9210
spark.databricks.python.defaultPythonRepl=ipykernel
spark.databricks.redactor=com.databricks.spark.util.DatabricksSparkLogRedactorProxy
spark.databricks.repl.enableClassFileCleanup=true
spark.databricks.safer.unifiedPath.applyFlag.enabled=true
spark.databricks.secret.envVar.keys.toRedact=*********(redacted)
spark.databricks.secret.sparkConf.keys.toRedact=*********(redacted)
spark.databricks.service.dbutils.repl.backend=com.databricks.dbconnect.ReplDBUtils
spark.databricks.service.dbutils.server.backend=com.databricks.dbconnect.SparkServerDBUtils
spark.databricks.session.share=false
spark.databricks.sparkContextId=1151128536340376051
spark.databricks.sql.configMapperClass=com.databricks.dbsql.config.SqlConfigMapperBridge
spark.databricks.tahoe.logStore.aws.class=com.databricks.tahoe.store.MultiClusterLogStore
spark.databricks.tahoe.logStore.azure.class=com.databricks.tahoe.store.AzureLogStore
spark.databricks.tahoe.logStore.class=com.databricks.tahoe.store.DelegatingLogStore
spark.databricks.tahoe.logStore.gcp.class=com.databricks.tahoe.store.GCPLogStore
spark.databricks.telemetry.prometheus.samplingRate=100
spark.databricks.unityCatalog.credentialManager.apiTokenProviderClassName=*********(redacted)
spark.databricks.unityCatalog.credentialManager.tokenRefreshEnabled=*********(redacted)
spark.databricks.unityCatalog.enabled=true
spark.databricks.unityCatalog.enforce.permissions=false
spark.databricks.unityCatalog.externalLocationFallbackMode.enabled=false
spark.databricks.unityCatalog.volumes.enabled=true
spark.databricks.workerNodeTypeId=Standard_D4ds_v5
spark.databricks.workspaceUrl=*********(redacted)
spark.databricks.wsfs.workspacePrivatePreview=true
spark.databricks.wsfsPublicPreview=true
spark.delta.sharing.profile.provider.class=*********(redacted)
spark.driver.allowMultipleContexts=false
spark.driver.extraJavaOptions=-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED
spark.driver.host=10.139.64.5
spark.driver.maxResultSize=4g
spark.driver.port=37321
spark.driver.tempDirectory=/local_disk0/tmp
spark.eventLog.enabled=false
spark.executor.extraClassPath=/databricks/spark/dbconf/log4j/executor:/databricks/spark/dbconf/jets3t/:/databricks/spark/dbconf/hadoop:/databricks/hive/conf:/databricks/jars/*
spark.executor.extraJavaOptions=-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djava.io.tmpdir=/local_disk0/tmp -XX:ReservedCodeCacheSize=512m -XX:+UseCodeCacheFlushing -XX:PerMethodRecompilationCutoff=-1 -XX:PerBytecodeRecompilationCutoff=-1 -Djava.security.properties=/databricks/spark/dbconf/java/extra.security -XX:-UseContainerSupport -XX:+PrintFlagsFinal -XX:+PrintGCDateStamps -XX:+PrintGCDetails -verbose:gc -Xss4m -Djava.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni -Djavax.xml.datatype.DatatypeFactory=com.sun.org.apache.xerces.internal.jaxp.datatype.DatatypeFactoryImpl -Djavax.xml.parsers.DocumentBuilderFactory=com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -Djavax.xml.validation.SchemaFactory:http://www.w3.org/2001/XMLSchema=com.sun.org.apache.xerces.internal.jaxp.validation.XMLSchemaFactory -Dorg.xml.sax.driver=com.sun.org.apache.xerces.internal.parsers.SAXParser -Dorg.w3c.dom.DOMImplementationSourceList=com.sun.org.apache.xerces.internal.dom.DOMXSImplementationSourceImpl -Djavax.net.ssl.sessionCacheSize=10000 -Dscala.reflect.runtime.disable.typetag.cache=true -Dcom.google.cloud.spark.bigquery.repackaged.io.netty.tryReflectionSetAccessible=true -Dlog4j2.formatMsgNoLookups=true -Ddatabricks.serviceName=spark-executor-1
spark.executor.id=driver
spark.executor.memory=8874m
spark.executor.tempDirectory=/local_disk0/tmp
spark.extraListeners=com.databricks.backend.daemon.driver.DBCEventLoggingListener
spark.files.fetchFailure.unRegisterOutputOnHost=true
spark.files.overwrite=true
spark.files.useFetchCache=false
spark.hadoop.databricks.dbfs.client.version=v2
spark.hadoop.databricks.fs.perfMetrics.enable=true
spark.hadoop.databricks.loki.fileStatusCache.abfs.enabled=false
spark.hadoop.databricks.loki.fileStatusCache.gcs.enabled=false
spark.hadoop.databricks.loki.fileStatusCache.s3a.enabled=false
spark.hadoop.databricks.loki.fileSystemCache.enabled=true
spark.hadoop.databricks.s3.create.deleteUnnecessaryFakeDirectories=false
spark.hadoop.databricks.s3.verifyBucketExists.enabled=false
spark.hadoop.databricks.s3commit.client.sslTrustAll=false
spark.hadoop.fs.AbstractFileSystem.gs.impl=shaded.databricks.com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS
spark.hadoop.fs.abfs.impl=com.databricks.common.filesystem.LokiFileSystem
spark.hadoop.fs.abfs.impl.disable.cache=true
spark.hadoop.fs.abfss.impl=com.databricks.common.filesystem.LokiFileSystem
spark.hadoop.fs.abfss.impl.disable.cache=true
spark.hadoop.fs.adl.impl=com.databricks.adl.AdlFileSystem
spark.hadoop.fs.adl.impl.disable.cache=true
spark.hadoop.fs.azure.authorization.caching.enable=false
spark.hadoop.fs.azure.cache.invalidator.type=com.databricks.encryption.utils.CacheInvalidatorImpl
spark.hadoop.fs.azure.skip.metrics=true
spark.hadoop.fs.azure.user.agent.prefix=*********(redacted)
spark.hadoop.fs.cpfs-abfss.impl=*********(redacted)
spark.hadoop.fs.cpfs-abfss.impl.disable.cache=true
spark.hadoop.fs.cpfs-adl.impl=*********(redacted)
spark.hadoop.fs.cpfs-adl.impl.disable.cache=true
spark.hadoop.fs.cpfs-s3.impl=*********(redacted)
spark.hadoop.fs.cpfs-s3a.impl=*********(redacted)
spark.hadoop.fs.cpfs-s3n.impl=*********(redacted)
spark.hadoop.fs.dbfs.impl=com.databricks.backend.daemon.data.client.DbfsHadoop3
spark.hadoop.fs.dbfsartifacts.impl=com.databricks.backend.daemon.data.client.DBFSV1
spark.hadoop.fs.fcfs-abfs.impl=*********(redacted)
spark.hadoop.fs.fcfs-abfs.impl.disable.cache=true
spark.hadoop.fs.fcfs-abfss.impl=*********(redacted)
spark.hadoop.fs.fcfs-abfss.impl.disable.cache=true
spark.hadoop.fs.fcfs-s3.impl=*********(redacted)
spark.hadoop.fs.fcfs-s3.impl.disable.cache=true
spark.hadoop.fs.fcfs-s3a.impl=*********(redacted)
spark.hadoop.fs.fcfs-s3a.impl.disable.cache=true
spark.hadoop.fs.fcfs-s3n.impl=*********(redacted)
spark.hadoop.fs.fcfs-s3n.impl.disable.cache=true
spark.hadoop.fs.fcfs-wasb.impl=*********(redacted)
spark.hadoop.fs.fcfs-wasb.impl.disable.cache=true
spark.hadoop.fs.fcfs-wasbs.impl=*********(redacted)
spark.hadoop.fs.fcfs-wasbs.impl.disable.cache=true
spark.hadoop.fs.file.impl=com.databricks.backend.daemon.driver.WorkspaceLocalFileSystem
spark.hadoop.fs.gs.impl=com.databricks.common.filesystem.LokiFileSystem
spark.hadoop.fs.gs.impl.disable.cache=true
spark.hadoop.fs.gs.outputstream.upload.chunk.size=16777216
spark.hadoop.fs.idbfs.impl=com.databricks.io.idbfs.IdbfsFileSystem
spark.hadoop.fs.mlflowdbfs.impl=com.databricks.mlflowdbfs.MlflowdbfsFileSystem
spark.hadoop.fs.s3.impl=com.databricks.common.filesystem.LokiFileSystem
spark.hadoop.fs.s3.impl.disable.cache=true
spark.hadoop.fs.s3a.assumed.role.credentials.provider=*********(redacted)
spark.hadoop.fs.s3a.attempts.maximum=10
spark.hadoop.fs.s3a.block.size=67108864
spark.hadoop.fs.s3a.connection.maximum=200
spark.hadoop.fs.s3a.connection.timeout=50000
spark.hadoop.fs.s3a.fast.upload=true
spark.hadoop.fs.s3a.fast.upload.active.blocks=32
spark.hadoop.fs.s3a.fast.upload.default=true
spark.hadoop.fs.s3a.impl=com.databricks.common.filesystem.LokiFileSystem
spark.hadoop.fs.s3a.impl.disable.cache=true
spark.hadoop.fs.s3a.max.total.tasks=1000
spark.hadoop.fs.s3a.multipart.size=10485760
spark.hadoop.fs.s3a.multipart.threshold=104857600
spark.hadoop.fs.s3a.retry.interval=250ms
spark.hadoop.fs.s3a.retry.limit=6
spark.hadoop.fs.s3a.retry.throttle.interval=500ms
spark.hadoop.fs.s3a.threads.max=136
spark.hadoop.fs.s3n.impl=com.databricks.common.filesystem.LokiFileSystem
spark.hadoop.fs.s3n.impl.disable.cache=true
spark.hadoop.fs.stage.impl=com.databricks.backend.daemon.driver.managedcatalog.PersonalStagingFileSystem
spark.hadoop.fs.stage.impl.disable.cache=true
spark.hadoop.fs.wasb.impl=shaded.databricks.org.apache.hadoop.fs.azure.NativeAzureFileSystem
spark.hadoop.fs.wasb.impl.disable.cache=true
spark.hadoop.fs.wasbs.impl=shaded.databricks.org.apache.hadoop.fs.azure.NativeAzureFileSystem
spark.hadoop.fs.wasbs.impl.disable.cache=true
spark.hadoop.hive.hmshandler.retry.attempts=10
spark.hadoop.hive.hmshandler.retry.interval=2000
spark.hadoop.hive.server2.enable.doAs=false
spark.hadoop.hive.server2.idle.operation.timeout=7200000
spark.hadoop.hive.server2.idle.session.timeout=900000
spark.hadoop.hive.server2.keystore.password=*********(redacted)
spark.hadoop.hive.server2.keystore.path=/databricks/keys/jetty-ssl-driver-keystore.jks
spark.hadoop.hive.server2.session.check.interval=60000
spark.hadoop.hive.server2.thrift.http.cookie.auth.enabled=false
spark.hadoop.hive.server2.thrift.http.port=10000
spark.hadoop.hive.server2.transport.mode=http
spark.hadoop.hive.server2.use.SSL=true
spark.hadoop.hive.warehouse.subdir.inherit.perms=false
spark.hadoop.mapred.output.committer.class=com.databricks.backend.daemon.data.client.DirectOutputCommitter
spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version=2
spark.hadoop.parquet.abfs.readahead.optimization.enabled=true
spark.hadoop.parquet.block.size.row.check.max=10
spark.hadoop.parquet.block.size.row.check.min=10
spark.hadoop.parquet.filter.columnindex.enabled=false
spark.hadoop.parquet.memory.pool.ratio=0.5
spark.hadoop.parquet.page.metadata.validation.enabled=true
spark.hadoop.parquet.page.size.check.estimate=false
spark.hadoop.parquet.page.verify-checksum.enabled=true
spark.hadoop.parquet.page.write-checksum.enabled=true
spark.hadoop.spark.databricks.io.parquet.verifyChecksumOnWrite.enabled=false
spark.hadoop.spark.databricks.io.parquet.verifyChecksumOnWrite.throwsException=false
spark.hadoop.spark.driverproxy.customHeadersToProperties=*********(redacted)
spark.hadoop.spark.hadoop.aws.glue.cache.db.size=1000
spark.hadoop.spark.hadoop.aws.glue.cache.db.ttl-mins=30
spark.hadoop.spark.hadoop.aws.glue.cache.table.size=1000
spark.hadoop.spark.hadoop.aws.glue.cache.table.ttl-mins=30
spark.hadoop.spark.sql.parquet.output.committer.class=org.apache.spark.sql.parquet.DirectParquetOutputCommitter
spark.hadoop.spark.sql.sources.outputCommitterClass=com.databricks.backend.daemon.data.client.MapReduceDirectOutputCommitter
spark.home=/databricks/spark
spark.logConf=true
spark.master=spark://10.139.64.5:7077
spark.metrics.conf=/databricks/spark/conf/metrics.properties
spark.r.backendConnectionTimeout=604800
spark.r.numRBackendThreads=1
spark.rdd.compress=true
spark.repl.class.outputDir=/local_disk0/tmp/repl/spark-1151128536340376051-09eaf8b0-9451-4628-a2ef-785e1bbf6667
spark.rpc.message.maxSize=256
spark.scheduler.listenerbus.eventqueue.capacity=20000
spark.scheduler.mode=FAIR
spark.serializer.objectStreamReset=100
spark.shuffle.manager=SORT
spark.shuffle.memoryFraction=0.2
spark.shuffle.reduceLocality.enabled=false
spark.shuffle.service.enabled=true
spark.shuffle.service.port=4048
spark.sparklyr-backend.threads=1
spark.sparkr.use.daemon=false
spark.speculation=false
spark.speculation.multiplier=3
spark.speculation.quantile=0.9
spark.sql.allowMultipleContexts=false
spark.sql.hive.convertCTAS=true
spark.sql.hive.convertMetastoreParquet=true
spark.sql.hive.metastore.jars=/databricks/databricks-hive/*
spark.sql.hive.metastore.sharedPrefixes=org.mariadb.jdbc,com.mysql.jdbc,org.postgresql,com.microsoft.sqlserver,microsoft.sql.DateTimeOffset,microsoft.sql.Types,com.databricks,com.codahale,com.fasterxml.jackson,shaded.databricks
spark.sql.hive.metastore.version=0.13.0
spark.sql.legacy.createHiveTableByDefault=false
spark.sql.parquet.cacheMetadata=true
spark.sql.parquet.compression.codec=snappy
spark.sql.sources.commitProtocolClass=com.databricks.sql.transaction.directory.DirectoryAtomicCommitProtocol
spark.sql.sources.default=delta
spark.sql.streaming.checkpointFileManagerClass=com.databricks.spark.sql.streaming.DatabricksCheckpointFileManager
spark.sql.streaming.stopTimeout=15s
spark.sql.warehouse.dir=*********(redacted)
spark.storage.blockManagerTimeoutIntervalMs=300000
spark.storage.memoryFraction=0.5
spark.streaming.driver.writeAheadLog.allowBatching=true
spark.streaming.driver.writeAheadLog.closeFileAfterWrite=true
spark.task.reaper.enabled=true
spark.task.reaper.killTimeout=60s
spark.ui.port=40001
spark.ui.prometheus.enabled=true
spark.worker.aioaLazyConfig.dbfsReadinessCheckClientClass=com.databricks.backend.daemon.driver.NephosDbfsReadinessCheckClient
spark.worker.aioaLazyConfig.iamReadinessCheckClientClass=com.databricks.backend.daemon.driver.NephosIamRoleCheckClient
spark.worker.cleanup.enabled=false
25/11/26 07:00:34 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/11/26 07:00:34 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme s3. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:00:34 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme s3a. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:00:34 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme s3n. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:00:34 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme abfs. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:00:34 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme abfss. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:00:34 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme gs. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:00:34 INFO log: Logging initialized @14087ms to org.eclipse.jetty.util.log.Slf4jLog
25/11/26 07:00:34 INFO Server: jetty-9.4.46.v20220331; built: 2022-03-31T16:38:08.030Z; git: bc17a0369a11ecf40bb92c839b9ef0a8ac50ea18; jvm 1.8.0_462-b08
25/11/26 07:00:34 INFO Server: Started @14291ms
25/11/26 07:00:34 INFO AbstractConnector: Started ServerConnector@71ea9a0d{HTTP/1.1, (http/1.1)}{10.139.64.5:40001}
25/11/26 07:00:34 INFO Utils: Successfully started service 'SparkUI' on port 40001.
25/11/26 07:00:34 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4b50ebea{/,null,AVAILABLE,@Spark}
25/11/26 07:00:35 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/11/26 07:00:35 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/11/26 07:00:35 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/11/26 07:00:35 WARN DBRDebuggerEventReporter: Driver/10.139.64.5 got terminated abnormally due to OTHER.
25/11/26 07:00:35 WARN DBRDebuggerEventReporter: 
25/11/26 07:00:36 INFO FairSchedulableBuilder: Fair scheduler configuration not found, created default pool: default, schedulingMode: FAIR, minShare: 0, weight: 1
25/11/26 07:00:36 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/11/26 07:00:36 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/11/26 07:00:36 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/11/26 07:00:36 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.139.64.5:7077...
25/11/26 07:00:36 INFO TransportClientFactory: Successfully created connection to /10.139.64.5:7077 after 53 ms (0 ms spent in bootstraps)
25/11/26 07:00:36 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251126070036-0001
25/11/26 07:00:36 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251126070036-0001/0 on worker-20251126065325-10.139.64.4-44021 (10.139.64.4:44021) with 4 core(s)
25/11/26 07:00:36 INFO StandaloneSchedulerBackend: Granted executor ID app-20251126070036-0001/0 on hostPort 10.139.64.4:44021 with 4 core(s), 8.7 GiB RAM
25/11/26 07:00:36 INFO TaskSchedulerImpl: Task preemption enabled.
25/11/26 07:00:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43879.
25/11/26 07:00:36 INFO NettyBlockTransferService: Server created on 10.139.64.5:43879
25/11/26 07:00:36 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/11/26 07:00:36 INFO BlockManager: external shuffle service port = 4048
25/11/26 07:00:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.5, 43879, None)
25/11/26 07:00:36 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.5:43879 with 4.4 GiB RAM, BlockManagerId(driver, 10.139.64.5, 43879, None)
25/11/26 07:00:36 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.5, 43879, None)
25/11/26 07:00:36 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.5, 43879, None)
25/11/26 07:00:36 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251126070036-0001/0 is now RUNNING
25/11/26 07:00:36 INFO DBCEventLoggingListener: Initializing DBCEventLoggingListener (compressionEnabled=true)
25/11/26 07:00:36 INFO DBCEventLoggingListener: Logging events to eventlogs/1151128536340376051/eventlog
25/11/26 07:00:36 INFO DatabricksILoop$: Finished creating throwaway interpreter
25/11/26 07:00:36 INFO SparkContext: Registered listener com.databricks.backend.daemon.driver.DBCEventLoggingListener
25/11/26 07:00:37 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme s3. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:00:37 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme s3a. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:00:37 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme s3n. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:00:37 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme abfs. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:00:37 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme abfss. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:00:37 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme gs. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:00:37 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@4b50ebea{/,null,STOPPED,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@524a96f5{/jobs,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@751df26c{/jobs/json,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@65f809cb{/jobs/job,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@8cc1bac{/jobs/job/json,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@20f1e26{/stages,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@75c90ec5{/stages/json,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6c6a7553{/stages/stage,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3087b35f{/stages/stage/json,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@19324eab{/stages/pool,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@20bd3082{/stages/pool/json,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@664f1c53{/storage,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@69cd4267{/storage/json,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@85420{/storage/rdd,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@49dce561{/storage/rdd/json,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4e38b4ea{/environment,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@20e1ce62{/environment/json,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3df05c40{/executors,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5b1505c3{/executors/json,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@73c71083{/executors/threadDump,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3f2731e5{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6a636c62{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5863ef93{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@519f6adb{/static,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@23591a2c{/,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6e16fcaf{/api,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4f283b8f{/metrics,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@15beb40b{/jobs/job/kill,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2d95c3ef{/stages/stage/kill,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1b316cac{/metrics/json,null,AVAILABLE,@Spark}
25/11/26 07:00:37 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/11/26 07:00:37 INFO SparkContext: Loading Spark Service RPC Server. Classloader stack:List(com.databricks.backend.daemon.driver.ClassLoaders$MultiReplClassLoader@24710e61, com.databricks.backend.daemon.driver.ClassLoaders$LibraryClassLoader@6565691a, sun.misc.Launcher$AppClassLoader@5aaa6d82, sun.misc.Launcher$ExtClassLoader@42b64ab8)
25/11/26 07:00:38 INFO SparkServiceRPCServer: Initializing Spark Service RPC Server. Classloader stack: List(com.databricks.backend.daemon.driver.ClassLoaders$MultiReplClassLoader@24710e61, com.databricks.backend.daemon.driver.ClassLoaders$LibraryClassLoader@6565691a, sun.misc.Launcher$AppClassLoader@5aaa6d82, sun.misc.Launcher$ExtClassLoader@42b64ab8)
25/11/26 07:00:38 INFO SparkServiceRPCServer: Starting Spark Service RPC Server
25/11/26 07:00:38 INFO SparkServiceRPCServer: Starting Spark Service RPC Server. Classloader stack: List(com.databricks.backend.daemon.driver.ClassLoaders$MultiReplClassLoader@24710e61, com.databricks.backend.daemon.driver.ClassLoaders$LibraryClassLoader@6565691a, sun.misc.Launcher$AppClassLoader@5aaa6d82, sun.misc.Launcher$ExtClassLoader@42b64ab8)
25/11/26 07:00:38 INFO Server: jetty-9.4.46.v20220331; built: 2022-03-31T16:38:08.030Z; git: bc17a0369a11ecf40bb92c839b9ef0a8ac50ea18; jvm 1.8.0_462-b08
25/11/26 07:00:38 INFO AbstractConnector: Started ServerConnector@22265a8d{HTTP/1.1, (http/1.1)}{0.0.0.0:15001}
25/11/26 07:00:38 INFO Server: Started @17878ms
25/11/26 07:00:38 INFO DatabricksILoop$: Successfully registered spark metrics in Prometheus registry
25/11/26 07:00:38 INFO DatabricksILoop$: Successfully initialized SparkContext
25/11/26 07:00:38 INFO SharedState: Scheduler stats enabled.
25/11/26 07:00:38 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/11/26 07:00:38 INFO SharedState: Warehouse path is 'dbfs:/user/hive/warehouse'.
25/11/26 07:00:38 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@29e94753{/storage/iocache,null,AVAILABLE,@Spark}
25/11/26 07:00:38 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6224872f{/storage/iocache/json,null,AVAILABLE,@Spark}
25/11/26 07:00:38 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@32be0ebd{/SQL,null,AVAILABLE,@Spark}
25/11/26 07:00:38 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3b5950f{/SQL/json,null,AVAILABLE,@Spark}
25/11/26 07:00:38 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3b2b9b96{/SQL/execution,null,AVAILABLE,@Spark}
25/11/26 07:00:38 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@36d9efa6{/SQL/execution/json,null,AVAILABLE,@Spark}
25/11/26 07:00:38 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1197cd8{/static/sql,null,AVAILABLE,@Spark}
25/11/26 07:00:38 WARN SQLConf: The SQL config 'spark.sql.hive.convertCTAS' has been deprecated in Spark v3.1 and may be removed in the future. Set 'spark.sql.legacy.createHiveTableByDefault' to false instead.
25/11/26 07:00:38 WARN SQLConf: The SQL config 'spark.sql.hive.convertCTAS' has been deprecated in Spark v3.1 and may be removed in the future. Set 'spark.sql.legacy.createHiveTableByDefault' to false instead.
25/11/26 07:00:41 INFO DriverConf: Configured feature flag data source LaunchDarkly
25/11/26 07:00:41 INFO DriverConf: Configured feature flag data source LaunchDarkly
25/11/26 07:00:41 WARN DriverConf: REGION environment variable is not defined. getConfForCurrentRegion will always return default value
25/11/26 07:00:42 INFO DriverConf: Configured feature flag data source LaunchDarkly
25/11/26 07:00:42 INFO DriverConf: Configured feature flag data source LaunchDarkly
25/11/26 07:00:42 WARN DriverConf: REGION environment variable is not defined. getConfForCurrentRegion will always return default value
25/11/26 07:00:43 INFO HiveUnityCatalogCheckRule: Collecting SQL actions took 142.960342 ms.
25/11/26 07:00:43 INFO DataClientConf: Configured feature flag data source LaunchDarkly
25/11/26 07:00:43 INFO DataClientConf: Configured feature flag data source LaunchDarkly
25/11/26 07:00:43 WARN DataClientConf: REGION environment variable is not defined. getConfForCurrentRegion will always return default value
25/11/26 07:00:43 INFO DataClientConf: Configured feature flag data source LaunchDarkly
25/11/26 07:00:43 INFO DataClientConf: Configured feature flag data source LaunchDarkly
25/11/26 07:00:43 WARN DataClientConf: REGION environment variable is not defined. getConfForCurrentRegion will always return default value
25/11/26 07:00:44 INFO DatabricksMountsStore: Mount store initialization: Attempting to get the list of mounts from metadata manager of DBFS
25/11/26 07:00:44 INFO log: Logging initialized @24040ms to shaded.v9_4.org.eclipse.jetty.util.log.Slf4jLog
25/11/26 07:00:44 INFO TypeUtil: JVM Runtime does not support Modules
25/11/26 07:00:44 INFO DatabricksMountsStore: Mount store initialization: Received a list of 9 mounts accessible from metadata manager of DBFS
25/11/26 07:00:44 INFO DatabricksMountsStore: Updated mounts cache. Changes: List((+,DbfsMountPoint(s3a://databricks-datasets-seoul/, /databricks-datasets)), (+,DbfsMountPoint(uc-volumes:/Volumes, /Volumes)), (+,DbfsMountPoint(unsupported-access-mechanism-for-path--use-mlflow-client:/, /databricks/mlflow-tracking)), (+,DbfsMountPoint(wasbs://dbstoragedyxwjqklqf7me.blob.core.chinacloudapi.cn/2559323315997869, /databricks-results)), (+,DbfsMountPoint(unsupported-access-mechanism-for-path--use-mlflow-client:/, /databricks/mlflow-registry)), (+,DbfsMountPoint(dbfs-reserved-path:/uc-volumes-reserved, /Volume)), (+,DbfsMountPoint(dbfs-reserved-path:/uc-volumes-reserved, /volumes)), (+,DbfsMountPoint(wasbs://dbstoragedyxwjqklqf7me.blob.core.chinacloudapi.cn/2559323315997869, /)), (+,DbfsMountPoint(dbfs-reserved-path:/uc-volumes-reserved, /volume)))
25/11/26 07:00:45 INFO HadoopFSUtil$: Installing the old filesystem implementation for scheme s3n. Current value: com.databricks.sql.acl.fs.CredentialScopeFileSystem. Old value to be restored: com.databricks.common.filesystem.LokiFileSystem.
25/11/26 07:00:45 INFO HadoopFSUtil$: Installing the old filesystem implementation for scheme s3a. Current value: com.databricks.sql.acl.fs.CredentialScopeFileSystem. Old value to be restored: com.databricks.common.filesystem.LokiFileSystem.
25/11/26 07:00:45 INFO HadoopFSUtil$: Installing the old filesystem implementation for scheme abfss. Current value: com.databricks.sql.acl.fs.CredentialScopeFileSystem. Old value to be restored: com.databricks.common.filesystem.LokiFileSystem.
25/11/26 07:00:45 INFO HadoopFSUtil$: Installing the old filesystem implementation for scheme gs. Current value: com.databricks.sql.acl.fs.CredentialScopeFileSystem. Old value to be restored: com.databricks.common.filesystem.LokiFileSystem.
25/11/26 07:00:45 INFO HadoopFSUtil$: Installing the old filesystem implementation for scheme s3. Current value: com.databricks.sql.acl.fs.CredentialScopeFileSystem. Old value to be restored: com.databricks.common.filesystem.LokiFileSystem.
25/11/26 07:00:45 INFO HadoopFSUtil$: Installing the old filesystem implementation for scheme abfs. Current value: com.databricks.sql.acl.fs.CredentialScopeFileSystem. Old value to be restored: com.databricks.common.filesystem.LokiFileSystem.
25/11/26 07:00:45 INFO DatabricksFileSystemV2Factory: Creating wasbs file system for wasbs://root@dbstoragedyxwjqklqf7me.blob.core.chinacloudapi.cn
25/11/26 07:00:45 INFO AzureNativeFileSystemStore: URI scheme: wasbs, using https for connections
25/11/26 07:00:45 INFO NativeAzureFileSystem: Delete with limit configurations: deleteFileCountLimitEnabled=false, deleteFileCountLimit=-1
25/11/26 07:00:45 INFO DbfsHadoop3: Initialized DBFS with DBFSV2 as the delegate.
25/11/26 07:00:45 INFO HiveConf: Found configuration file file:/databricks/hive/conf/hive-site.xml
25/11/26 07:00:46 INFO SessionManager: HiveServer2: Background operation thread pool size: 100
25/11/26 07:00:46 INFO SessionManager: HiveServer2: Background operation thread wait queue size: 100
25/11/26 07:00:46 INFO SessionManager: HiveServer2: Background operation thread keepalive time: 10 seconds
25/11/26 07:00:46 INFO AbstractService: Service:OperationManager is inited.
25/11/26 07:00:46 INFO AbstractService: Service:SessionManager is inited.
25/11/26 07:00:46 INFO SparkSQLCLIService: Service: CLIService is inited.
25/11/26 07:00:46 INFO AbstractService: Service:ThriftHttpCLIService is inited.
25/11/26 07:00:46 INFO HiveThriftServer2: Service: HiveServer2 is inited.
25/11/26 07:00:46 INFO AbstractService: Service:OperationManager is started.
25/11/26 07:00:46 INFO AbstractService: Service:SessionManager is started.
25/11/26 07:00:46 INFO SparkSQLCLIService: Service: CLIService is started.
25/11/26 07:00:46 INFO AbstractService: Service:ThriftHttpCLIService is started.
25/11/26 07:00:46 INFO ThriftCLIService: HTTP Server SSL: adding excluded protocols: [SSLv2, SSLv3]
25/11/26 07:00:46 INFO ThriftCLIService: HTTP Server SSL: SslContextFactory.getExcludeProtocols = [SSL, SSLv2, SSLv2Hello, SSLv3]
25/11/26 07:00:46 INFO Server: jetty-9.4.46.v20220331; built: 2022-03-31T16:38:08.030Z; git: bc17a0369a11ecf40bb92c839b9ef0a8ac50ea18; jvm 1.8.0_462-b08
25/11/26 07:00:46 INFO session: DefaultSessionIdManager workerName=node0
25/11/26 07:00:46 INFO session: No SessionScavenger set, using defaults
25/11/26 07:00:46 INFO session: node0 Scavenging every 660000ms
25/11/26 07:00:46 WARN SecurityHandler: ServletContext@o.e.j.s.ServletContextHandler@466b5ed5{/,null,STARTING} has uncovered http methods for path: /*
25/11/26 07:00:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@466b5ed5{/,null,AVAILABLE}
25/11/26 07:00:46 INFO SslContextFactory: x509=X509@24fb3e2a(1,h=[az-chinanorth2.workers.prod.ns.databricks.com],a=[],w=[]) for Server@5b81d35c[provider=null,keyStore=file:///databricks/keys/jetty-ssl-driver-keystore.jks,trustStore=null]
25/11/26 07:00:46 INFO AbstractConnector: Started ServerConnector@71b2a743{SSL, (ssl, http/1.1)}{0.0.0.0:10000}
25/11/26 07:00:46 INFO Server: Started @26116ms
25/11/26 07:00:46 INFO ThriftCLIService: Started ThriftHttpCLIService in https mode on port 10000 path=/cliservice/* with 5...500 worker threads
25/11/26 07:00:46 INFO AbstractService: Service:HiveServer2 is started.
25/11/26 07:00:46 INFO HiveThriftServer2: HiveThriftServer2 started
25/11/26 07:00:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3da1191b{/sqlserver,null,AVAILABLE,@Spark}
25/11/26 07:00:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@b280053{/sqlserver/json,null,AVAILABLE,@Spark}
25/11/26 07:00:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@d5ef7c0{/sqlserver/session,null,AVAILABLE,@Spark}
25/11/26 07:00:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@12bc51f4{/sqlserver/session/json,null,AVAILABLE,@Spark}
25/11/26 07:00:46 INFO DatabricksILoop$: Trying to load dynamic config on startup: /databricks/driver/conf/dynamicSparkConfig.conf
25/11/26 07:00:46 INFO DatabricksILoop$: Read the dynamic config: ArrayBuffer(SaferConf(spark.databricks.dataLineage.mergeIntoV2Enabled,false,1731558697,241113190524268,1), SaferConf(spark.databricks.cloudFiles.aws.restrictSNSPolicyPrincipalAndAccount,false,1749573002,250606224725199,2), SaferConf(spark.databricks.unityCatalog.clientWithCaller.enabled,true,1753369006,250606151049532,1), SaferConf(spark.databricks.delta.merge.failSourceCachedAfterMaterialization,true,1763647692,251110154546851,1), SaferConf(spark.databricks.autotune.maintenance.enableMetricsForAllUCManagedTables,true,1756330524,250618183020206,1), SaferConf(spark.databricks.sql.jdbcDialectForbidQueriesWithForbiddenKeywords,true,1763644302,250811103850235,6), SaferConf(spark.databricks.unityCatalog.client.UCSEWithMessageTemplateAndClass.enabled,true,1763685074,250930185930488,2), SaferConf(spark.sql.optimizer.optimizeCsvJsonExprs.useSchemaField,false,1728499876,241008194704608,1), SaferConf(spark.databricks.delta.identifierExtraction.newCodePath.enabled,true,1747764696,250221192257794,3), SaferConf(spark.databricks.sql.inlineOuterRefsToConstants.enabled,false,1747429458,250319214018422,2), SaferConf(spark.databricks.autotune.maintenance.client.pushIntervalMinutes,1,1752168673,250118155345061,2), SaferConf(spark.databricks.unityCatalog.client.newErrorClasses.enabled,false,1755882681,250403002450986,1), SaferConf(spark.databricks.sql.jdbcDialectIgnoreQueriesWithForbiddenKeywords,false,1737662132,250123131150571,1), SaferConf(spark.databricks.delta.merge.disableSourceMaterializationNotAllowed,true,1761939217,250429083126347,2)) from /databricks/driver/conf/dynamicSparkConfig.conf, version 1764127249701
25/11/26 07:00:46 INFO LibraryResolutionManager: Preferred maven central mirror is configured to https://maven.aliyun.com/repository/central
25/11/26 07:00:46 WARN OutgoingDirectNotebookBufferRateLimiter$: No value specified for db-outgoing-buffer-throttler-burst. Using default: 100000000000
25/11/26 07:00:46 WARN OutgoingDirectNotebookBufferRateLimiter$: No value specified for db-outgoing-buffer-throttler-steady-rate. Using default: 6000000000
25/11/26 07:00:46 WARN OutgoingDirectNotebookBufferRateLimiter$: No value specified for db-outgoing-buffer-throttler-warning-interval-sec. Using default: 60
25/11/26 07:00:46 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
25/11/26 07:00:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2d00df20{/StreamingQuery,null,AVAILABLE,@Spark}
25/11/26 07:00:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5dd2a2aa{/StreamingQuery/json,null,AVAILABLE,@Spark}
25/11/26 07:00:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3658b0ce{/StreamingQuery/statistics,null,AVAILABLE,@Spark}
25/11/26 07:00:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@383e8680{/StreamingQuery/statistics/json,null,AVAILABLE,@Spark}
25/11/26 07:00:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6cee59d6{/static/sql,null,AVAILABLE,@Spark}
25/11/26 07:00:46 INFO DriverCorral: metastoreType: InternalMysqlMetastore(DbMetastoreConfig{host=consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn, port=3306, dbName=organization2559323315997869, user=[REDACTED], proxyHost=consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn, proxyPort=9207, proxyUser=[REDACTED]}), enableMetastoreHealthCheck: true
25/11/26 07:00:46 INFO JettyServer$: Creating thread pool with name ...
25/11/26 07:00:46 INFO JettyServer$: Thread pool created
25/11/26 07:00:46 INFO JettyServer$: Creating thread pool with name ...
25/11/26 07:00:46 INFO JettyServer$: Thread pool created
25/11/26 07:00:46 INFO DriverDaemon: Starting driver daemon...
25/11/26 07:00:46 WARN SparkConfUtils$: Setting the same key twice for spark.hadoop.hive.server2.keystore.password
25/11/26 07:00:46 WARN SparkConfUtils$: Setting the same key twice for spark.databricks.io.directoryCommit.enableLogicalDelete
25/11/26 07:00:46 WARN SparkConfUtils$: Setting the same key twice for spark.hadoop.hive.server2.keystore.path
25/11/26 07:00:46 INFO SparkConfUtils$: Customize spark config according to file /tmp/custom-spark.conf
25/11/26 07:00:46 WARN SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
25/11/26 07:00:46 INFO DriverDaemon$: Attempting to run: 'set up ttyd daemon'
25/11/26 07:00:46 INFO DriverDaemon$: Attempting to run: 'Configuring RStudio daemon'
25/11/26 07:00:46 INFO DriverDaemon$: Resetting the default python executable
25/11/26 07:00:46 INFO Utils: resolved command to be run: List(virtualenv, /local_disk0/.ephemeral_nfs/cluster_libraries/python, -p, /databricks/python/bin/python, --no-download, --no-setuptools, --no-wheel)
25/11/26 07:00:47 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.139.64.4:46196) with ID 0, ResourceProfileId 0
25/11/26 07:00:47 INFO PythonEnvCloneHelper$: Created python virtualenv: /local_disk0/.ephemeral_nfs/cluster_libraries/python
25/11/26 07:00:47 INFO Utils: resolved command to be run: List(/databricks/python/bin/python, -c, import sys; dirs=[p for p in sys.path if 'package' in p]; print(' '.join(dirs)))
25/11/26 07:00:47 INFO Utils: resolved command to be run: List(/local_disk0/.ephemeral_nfs/cluster_libraries/python/bin/python, -c, from distutils.sysconfig import get_python_lib; print(get_python_lib()))
25/11/26 07:00:47 INFO PythonEnvCloneHelper$: Created sites.pth at /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sites.pth
25/11/26 07:00:47 INFO ClusterWidePythonEnvManager: Registered /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages with the WatchService sun.nio.fs.LinuxWatchService$LinuxWatchKey@384841e3
25/11/26 07:00:47 INFO DriverDaemon$: Attempting to run: 'Update root virtualenv'
25/11/26 07:00:47 INFO DriverDaemon$: Finished updating /etc/environment
25/11/26 07:00:47 INFO DriverDaemon$$anon$1: Thread to send message is ready
25/11/26 07:00:47 INFO NetstatUtil$: Running netstat -lnpt
25/11/26 07:00:47 INFO NetstatUtil$: netstat -lnpt
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 0.0.0.0:7681            0.0.0.0:*               LISTEN      781/ttyd            
tcp        0      0 127.0.0.1:1100          0.0.0.0:*               LISTEN      953/R               
tcp        0      0 0.0.0.0:2812            0.0.0.0:*               LISTEN      78/monit            
tcp        0      0 127.0.0.53:53           0.0.0.0:*               LISTEN      47/systemd-resolved 
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      69/sshd: /usr/sbin/ 
tcp6       0      0 10.139.64.5:43879       :::*                    LISTEN      1714/java           
tcp6       0      0 :::15001                :::*                    LISTEN      1714/java           
tcp6       0      0 :::15002                :::*                    LISTEN      1714/java           
tcp6       0      0 :::7071                 :::*                    LISTEN      332/java            
tcp6       0      0 :::6060                 :::*                    LISTEN      332/java            
tcp6       0      0 10.139.64.5:7077        :::*                    LISTEN      430/java            
tcp6       0      0 10.139.64.5:40000       :::*                    LISTEN      430/java            
tcp6       0      0 10.139.64.5:40001       :::*                    LISTEN      1714/java           
tcp6       0      0 :::2812                 :::*                    LISTEN      78/monit            
tcp6       0      0 10.139.64.5:37321       :::*                    LISTEN      1714/java           
tcp6       0      0 :::10000                :::*                    LISTEN      1714/java           
tcp6       0      0 :::22                   :::*                    LISTEN      69/sshd: /usr/sbin/ 
tcp6       0      0 :::1021                 :::*                    LISTEN      168/wsfs            
tcp6       0      0 :::1017                 :::*                    LISTEN      168/wsfs            
tcp6       0      0 :::1015                 :::*                    LISTEN      199/goofys-dbr      

25/11/26 07:00:47 INFO Server: jetty-9.4.46.v20220331; built: 2022-03-31T16:38:08.030Z; git: bc17a0369a11ecf40bb92c839b9ef0a8ac50ea18; jvm 1.8.0_462-b08
25/11/26 07:00:47 INFO AbstractConnector: Started ServerConnector@7c0fd22d{HTTP/1.1, (http/1.1)}{0.0.0.0:6061}
25/11/26 07:00:47 INFO Server: Started @27264ms
25/11/26 07:00:47 INFO Server: jetty-9.4.46.v20220331; built: 2022-03-31T16:38:08.030Z; git: bc17a0369a11ecf40bb92c839b9ef0a8ac50ea18; jvm 1.8.0_462-b08
25/11/26 07:00:47 INFO SslContextFactory: x509=X509@47bdfc41(1,h=[az-chinanorth2.workers.prod.ns.databricks.com],a=[],w=[]) for Server@33c4dc6c[provider=null,keyStore=null,trustStore=null]
25/11/26 07:00:47 INFO SslContextFactory: No Cipher Suite matching 'TLS_CHACHA20_POLY1305_SHA256' is supported
25/11/26 07:00:47 WARN config: Weak cipher suite TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA enabled for Server@33c4dc6c[provider=null,keyStore=null,trustStore=null]
25/11/26 07:00:47 WARN config: Weak cipher suite TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA enabled for Server@33c4dc6c[provider=null,keyStore=null,trustStore=null]
25/11/26 07:00:47 INFO AbstractConnector: Started ServerConnector@a674645{SSL, (ssl, http/1.1)}{0.0.0.0:6062}
25/11/26 07:00:47 INFO Server: Started @27318ms
25/11/26 07:00:47 INFO DriverDaemon: Started comm channel server
25/11/26 07:00:47 INFO DriverDaemon: Driver daemon started.
25/11/26 07:00:47 INFO DynamicInfoServiceConf: Configured feature flag data source LaunchDarkly
25/11/26 07:00:47 INFO DynamicInfoServiceConf: Configured feature flag data source LaunchDarkly
25/11/26 07:00:47 WARN DynamicInfoServiceConf: REGION environment variable is not defined. getConfForCurrentRegion will always return default value
25/11/26 07:00:48 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:38905 with 4.4 GiB RAM, BlockManagerId(0, 10.139.64.4, 38905, None)
25/11/26 07:00:48 WARN SQLConf: The SQL config 'spark.sql.hive.convertCTAS' has been deprecated in Spark v3.1 and may be removed in the future. Set 'spark.sql.legacy.createHiveTableByDefault' to false instead.
25/11/26 07:00:48 WARN SQLConf: The SQL config 'spark.sql.hive.convertCTAS' has been deprecated in Spark v3.1 and may be removed in the future. Set 'spark.sql.legacy.createHiveTableByDefault' to false instead.
25/11/26 07:00:48 INFO DriverCorral: Loading the root classloader
25/11/26 07:00:48 INFO DriverCorral: Starting sql repl ReplId-b922c-3bbcb-f3dbe
25/11/26 07:00:48 INFO DriverCorral: Starting sql repl ReplId-18f5c-f2a35-d6d29-7
25/11/26 07:00:48 INFO DriverCorral: Starting sql repl ReplId-19f0a-15f2c-cbafc-a
25/11/26 07:00:48 INFO SQLDriverWrapper: setupRepl:ReplId-19f0a-15f2c-cbafc-a: finished to load
25/11/26 07:00:48 INFO SQLDriverWrapper: setupRepl:ReplId-b922c-3bbcb-f3dbe: finished to load
25/11/26 07:00:48 INFO SQLDriverWrapper: setupRepl:ReplId-18f5c-f2a35-d6d29-7: finished to load
25/11/26 07:00:48 INFO DriverCorral: Starting sql repl ReplId-57f4c-fb9e9-adf54-f
25/11/26 07:00:48 INFO SQLDriverWrapper: setupRepl:ReplId-57f4c-fb9e9-adf54-f: finished to load
25/11/26 07:00:49 INFO DriverCorral: Starting sql repl ReplId-5eaa8-a7f75-f0ab7-a
25/11/26 07:00:49 INFO SQLDriverWrapper: setupRepl:ReplId-5eaa8-a7f75-f0ab7-a: finished to load
25/11/26 07:00:49 WARN SQLConf: The SQL config 'spark.sql.hive.convertCTAS' has been deprecated in Spark v3.1 and may be removed in the future. Set 'spark.sql.legacy.createHiveTableByDefault' to false instead.
25/11/26 07:00:49 WARN SQLConf: The SQL config 'spark.sql.hive.convertCTAS' has been deprecated in Spark v3.1 and may be removed in the future. Set 'spark.sql.legacy.createHiveTableByDefault' to false instead.
25/11/26 07:00:49 INFO DriverCorral: Starting r repl ReplId-200ef-e9771-0322f-e
25/11/26 07:00:49 INFO ROutputStreamHandler: Connection succeeded on port 34703
25/11/26 07:00:49 INFO ROutputStreamHandler: Connection succeeded on port 40547
25/11/26 07:00:49 INFO RDriverLocal: 1. RDriverLocal.9b90d57f-eee4-4488-b302-fb44a850218d: object created with for ReplId-200ef-e9771-0322f-e.
25/11/26 07:00:49 INFO RDriverLocal: 2. RDriverLocal.9b90d57f-eee4-4488-b302-fb44a850218d: initializing ...
25/11/26 07:00:49 INFO RDriverLocal: 3. RDriverLocal.9b90d57f-eee4-4488-b302-fb44a850218d: started RBackend thread on port 35009
25/11/26 07:00:49 INFO RDriverLocal: 4. RDriverLocal.9b90d57f-eee4-4488-b302-fb44a850218d: waiting for SparkR to be installed ...
25/11/26 07:00:55 INFO Utils: resolved command to be run: WrappedArray(getconf, PAGESIZE)
25/11/26 07:00:58 INFO RDriverLocal$: SparkR installation completed.
25/11/26 07:00:58 INFO RDriverLocal: 5. RDriverLocal.9b90d57f-eee4-4488-b302-fb44a850218d: launching R process ...
25/11/26 07:00:58 INFO RDriverLocal: 6. RDriverLocal.9b90d57f-eee4-4488-b302-fb44a850218d: cgroup isolation disabled, not placing R process in REPL cgroup.
25/11/26 07:00:58 INFO RDriverLocal$: Skip port 1100
25/11/26 07:00:58 INFO RDriverLocal: 7. RDriverLocal.9b90d57f-eee4-4488-b302-fb44a850218d: starting R process on port 1101 (attempt 1) ...
25/11/26 07:00:58 INFO RDriverLocal$: Debugging command for R process builder: SIMBASPARKINI=/etc/simba.sparkodbc.ini R_LIBS=/local_disk0/.ephemeral_nfs/envs/rEnv-433b38c7-f647-436b-8849-9b92d22ed742:/databricks/spark/R/lib:/local_disk0/.ephemeral_nfs/cluster_libraries/r LD_LIBRARY_PATH=/opt/simba/sparkodbc/lib/64/ SPARKR_BACKEND_CONNECTION_TIMEOUT=604800 DB_STREAM_BEACON_STRING_START=DATABRICKS_STREAM_START-ReplId-200ef-e9771-0322f-e DB_STDOUT_STREAM_PORT=34703 SPARKR_BACKEND_AUTH_SECRET=6d41e6fcd597eee1fa291de0818c41a24bee4576f514419733aaeed572d0d19a DB_STREAM_BEACON_STRING_END=DATABRICKS_STREAM_END-ReplId-200ef-e9771-0322f-e EXISTING_SPARKR_BACKEND_PORT=35009 ODBCINI=/etc/odbc.ini DB_STDERR_STREAM_PORT=40547 /bin/bash /local_disk0/tmp/_startR.sh2160309629655070206resource.r /local_disk0/tmp/_rServeScript.r1378094985029289000resource.r 1101 None
25/11/26 07:00:58 INFO RDriverLocal: 8. RDriverLocal.9b90d57f-eee4-4488-b302-fb44a850218d: setting up BufferedStreamThread with bufferSize: 1000.
25/11/26 07:01:00 INFO RDriverLocal: 9. RDriverLocal.9b90d57f-eee4-4488-b302-fb44a850218d: R process started with RServe listening on port 1101.
25/11/26 07:01:00 INFO RDriverLocal: 10. RDriverLocal.9b90d57f-eee4-4488-b302-fb44a850218d: starting interpreter to talk to R process ...
25/11/26 07:01:00 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
25/11/26 07:01:00 INFO ROutputStreamHandler: Successfully connected to stdout in the RShell.
25/11/26 07:01:00 INFO ROutputStreamHandler: Successfully connected to stderr in the RShell.
25/11/26 07:01:00 INFO RDriverLocal: 11. RDriverLocal.9b90d57f-eee4-4488-b302-fb44a850218d: R interpreter is connected.
25/11/26 07:01:00 INFO RDriverWrapper: setupRepl:ReplId-200ef-e9771-0322f-e: finished to load
25/11/26 07:01:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:01:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:02:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:02:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:03:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:03:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:04:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:04:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:05:33 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:3306/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:05:33 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:05:33 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:05:33 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:05:33 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:05:33 INFO MetastoreMonitor: Metastore healthcheck successful (connection duration = 299 milliseconds)
25/11/26 07:05:33 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:9207/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:05:33 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:05:33 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:05:33 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:05:33 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:05:33 INFO MetastoreMonitor: PoPProxy healthcheck successful (connection duration = 255 milliseconds)
25/11/26 07:05:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:05:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:05:46 INFO SecuredHiveExternalCatalog: creating hiveClient from java.lang.Throwable
	at org.apache.spark.sql.hive.HiveExternalCatalog.client$lzycompute(HiveExternalCatalog.scala:81)
	at org.apache.spark.sql.hive.HiveExternalCatalog.client(HiveExternalCatalog.scala:79)
	at org.apache.spark.sql.hive.HiveExternalCatalog.maybeSynchronized(HiveExternalCatalog.scala:115)
	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$withClient$1(HiveExternalCatalog.scala:155)
	at com.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:397)
	at com.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)
	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:154)
	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:326)
	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:309)
	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:299)
	at com.databricks.backend.daemon.driver.DriverCorral.$anonfun$new$5(DriverCorral.scala:485)
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:41)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:100)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:105)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:104)
	at com.databricks.backend.daemon.driver.DriverCorral.$anonfun$new$4(DriverCorral.scala:485)
	at com.databricks.backend.daemon.driver.DriverCorral.$anonfun$new$4$adapted(DriverCorral.scala:484)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.backend.daemon.driver.DriverCorral.$anonfun$new$3(DriverCorral.scala:484)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:657)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:678)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.threading.NamedTimer$$anon$1.withAttributionContext(NamedTimer.scala:95)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)
	at com.databricks.threading.NamedTimer$$anon$1.withAttributionTags(NamedTimer.scala:95)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:652)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:569)
	at com.databricks.threading.NamedTimer$$anon$1.recordOperationWithResultTags(NamedTimer.scala:95)
	at com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:528)
	at com.databricks.threading.NamedTimer$$anon$1.recordOperation(NamedTimer.scala:95)
	at com.databricks.threading.NamedTimer$$anon$1.$anonfun$run$2(NamedTimer.scala:104)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.threading.NamedTimer$$anon$1.withAttributionContext(NamedTimer.scala:95)
	at com.databricks.logging.UsageLogging.disableTracing(UsageLogging.scala:1380)
	at com.databricks.logging.UsageLogging.disableTracing$(UsageLogging.scala:1379)
	at com.databricks.threading.NamedTimer$$anon$1.disableTracing(NamedTimer.scala:95)
	at com.databricks.threading.NamedTimer$$anon$1.$anonfun$run$1(NamedTimer.scala:103)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.UntrustedUtils$.tryLog(UntrustedUtils.scala:109)
	at com.databricks.threading.NamedTimer$$anon$1.run(NamedTimer.scala:102)
	at java.util.TimerThread.mainLoop(Timer.java:555)
	at java.util.TimerThread.run(Timer.java:505)

25/11/26 07:05:46 WARN SQLConf: The SQL config 'spark.sql.hive.convertCTAS' has been deprecated in Spark v3.1 and may be removed in the future. Set 'spark.sql.legacy.createHiveTableByDefault' to false instead.
25/11/26 07:05:46 INFO HiveUtils: Initializing HiveMetastoreConnection version 0.13.0 using file:/databricks/databricks-hive/----ws_3_3--mvn--hadoop3--org.apache.logging.log4j--log4j-slf4j-impl--org.apache.logging.log4j__log4j-slf4j-impl__2.18.0.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.geronimo.specs--geronimo-jaspic_1.0_spec--org.apache.geronimo.specs__geronimo-jaspic_1.0_spec__1.0.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--javax.transaction--transaction-api--javax.transaction__transaction-api__1.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.antlr--ST4--org.antlr__ST4__4.0.4.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.codehaus.groovy--groovy-all--org.codehaus.groovy__groovy-all__2.1.6.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--jline--jline--jline__jline__0.9.94.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--com.esotericsoftware.minlog--minlog--com.esotericsoftware.minlog__minlog__1.2.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--commons-codec--commons-codec--commons-codec__commons-codec__1.8.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive--hive-common--org.apache.hive__hive-common__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--commons-io--commons-io--commons-io__commons-io__2.5.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--oro--oro--oro__oro__2.0.8.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--antlr--antlr--antlr__antlr__2.7.7.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.ant--ant-launcher--org.apache.ant__ant-launcher__1.9.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.eclipse.jetty.aggregate--jetty-all--org.eclipse.jetty.aggregate__jetty-all__7.6.0.v20120127.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.derby--derby--org.apache.derby__derby__10.10.1.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--net.sf.jpam--jpam--net.sf.jpam__jpam__1.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.commons--commons-lang3--org.apache.commons__commons-lang3__3.4.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--commons-collections--commons-collections--commons-collections__commons-collections__3.2.2.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--commons-cli--commons-cli--commons-cli__commons-cli__1.2.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive--hive-metastore--org.apache.hive__hive-metastore__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--stax--stax-api--stax__stax-api__1.0.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--com.zaxxer--HikariCP--com.zaxxer__HikariCP__2.5.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--com.esotericsoftware.reflectasm--reflectasm-shaded--com.esotericsoftware.reflectasm__reflectasm-shaded__1.07.jar:file:/databricks/databricks-hive/----ws_3_3--mvn--hadoop3--org.apache.logging.log4j--log4j-1.2-api--org.apache.logging.log4j__log4j-1.2-api__2.18.0.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive--hive-jdbc--org.apache.hive__hive-jdbc__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive--hive-exec--org.apache.hive__hive-exec__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--javax.transaction--jta--javax.transaction__jta__1.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.ow2.asm--asm--org.ow2.asm__asm__4.0.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.geronimo.specs--geronimo-annotation_1.0_spec--org.apache.geronimo.specs__geronimo-annotation_1.0_spec__1.1.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.objenesis--objenesis--org.objenesis__objenesis__1.2.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.codehaus.jackson--jackson-core-asl--org.codehaus.jackson__jackson-core-asl__1.9.13.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive--hive-beeline--org.apache.hive__hive-beeline__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.velocity--velocity--org.apache.velocity__velocity__1.5.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive--hive-ant--org.apache.hive__hive-ant__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.xerial.snappy--snappy-java--org.xerial.snappy__snappy-java__1.0.5.jar:file:/databricks/databricks-hive/----ws_3_3--mvn--hadoop3--org.slf4j--slf4j-api--org.slf4j__slf4j-api__1.7.36.jar:file:/databricks/databricks-hive/----ws_3_3--mvn--hadoop3--org.apache.logging.log4j--log4j-api--org.apache.logging.log4j__log4j-api__2.18.0.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--javax.activation--activation--javax.activation__activation__1.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.geronimo.specs--geronimo-jta_1.1_spec--org.apache.geronimo.specs__geronimo-jta_1.1_spec__1.1.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.antlr--antlr-runtime--org.antlr__antlr-runtime__3.4.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive.shims--hive-shims-0.23--org.apache.hive.shims__hive-shims-0.23__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.thrift--libthrift--org.apache.thrift__libthrift__0.9.2.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.datanucleus--datanucleus-rdbms--org.datanucleus__datanucleus-rdbms__4.1.19.jar:file:/databricks/databricks-hive/manifest.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--asm--asm--asm__asm__3.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.mortbay.jetty--jetty--org.mortbay.jetty__jetty__6.1.26.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--com.thoughtworks.paranamer--paranamer--com.thoughtworks.paranamer__paranamer__2.8.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive--hive-shims--org.apache.hive__hive-shims__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.avro--avro--org.apache.avro__avro__1.7.5.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.ant--ant--org.apache.ant__ant__1.9.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive.shims--hive-shims-0.20S--org.apache.hive.shims__hive-shims-0.20S__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--com.google.code.findbugs--jsr305--com.google.code.findbugs__jsr305__1.3.9.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--asm--asm-tree--asm__asm-tree__3.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.zookeeper--zookeeper--org.apache.zookeeper__zookeeper__3.4.5.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.datanucleus--javax.jdo--org.datanucleus__javax.jdo__3.2.0-m3.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--commons-lang--commons-lang--commons-lang__commons-lang__2.4.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--commons-httpclient--commons-httpclient--commons-httpclient__commons-httpclient__3.0.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.codehaus.jackson--jackson-mapper-asl--org.codehaus.jackson__jackson-mapper-asl__1.9.13.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.mortbay.jetty--servlet-api--org.mortbay.jetty__servlet-api__2.5-20081211.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--asm--asm-commons--asm__asm-commons__3.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--com.jolbox--bonecp--com.jolbox__bonecp__0.8.0.RELEASE.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--javax.mail--mail--javax.mail__mail__1.4.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--junit--junit--junit__junit__3.8.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive.shims--hive-shims-0.20--org.apache.hive.shims__hive-shims-0.20__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--commons-logging--commons-logging--commons-logging__commons-logging__1.1.3.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.httpcomponents--httpclient--org.apache.httpcomponents__httpclient__4.4.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive--hive-service--org.apache.hive__hive-service__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.datanucleus--datanucleus-core--org.datanucleus__datanucleus-core__4.1.17.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive--hive-serde--org.apache.hive__hive-serde__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--com.google.guava--guava--com.google.guava__guava__11.0.2.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.antlr--stringtemplate--org.antlr__stringtemplate__3.2.1.jar:file:/databricks/databricks-hive/----ws_3_3--mvn--hadoop3--org.apache.logging.log4j--log4j-core--org.apache.logging.log4j__log4j-core__2.18.0.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.commons--commons-compress--org.apache.commons__commons-compress__1.9.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--javax.jdo--jdo-api--javax.jdo__jdo-api__3.0.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--javax.servlet--servlet-api--javax.servlet__servlet-api__2.5.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive--hive-cli--org.apache.hive__hive-cli__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--com.esotericsoftware.kryo--kryo--com.esotericsoftware.kryo__kryo__2.21.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.thrift--libfb303--org.apache.thrift__libfb303__0.9.0.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.datanucleus--datanucleus-api-jdo--org.datanucleus__datanucleus-api-jdo__4.2.4.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive.shims--hive-shims-common-secure--org.apache.hive.shims__hive-shims-common-secure__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.mortbay.jetty--jetty-util--org.mortbay.jetty__jetty-util__6.1.26.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.httpcomponents--httpcore--org.apache.httpcomponents__httpcore__4.2.5.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive.shims--hive-shims-common--org.apache.hive.shims__hive-shims-common__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/bonecp-configs.jar
25/11/26 07:05:46 INFO PoolingHiveClient: Hive metastore connection pool implementation is HikariCP
25/11/26 07:05:46 INFO LocalHiveClientsPool: Create Hive Metastore client pool of size 20
25/11/26 07:05:46 INFO DriverCorral: DBFS health check ok
25/11/26 07:05:46 INFO HiveClientImpl: Warehouse location for Hive client (version 0.13.1) is dbfs:/user/hive/warehouse
25/11/26 07:05:47 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
25/11/26 07:05:47 INFO ObjectStore: ObjectStore, initialize called
25/11/26 07:05:47 INFO Persistence: Property datanucleus.fixedDatastore unknown - will be ignored
25/11/26 07:05:47 INFO Persistence: Property datanucleus.connectionPool.idleTimeout unknown - will be ignored
25/11/26 07:05:47 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
25/11/26 07:05:47 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
25/11/26 07:05:47 INFO HikariDataSource: HikariPool-1 - Started.
25/11/26 07:05:47 INFO HikariDataSource: HikariPool-2 - Started.
25/11/26 07:05:48 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
25/11/26 07:05:49 INFO ObjectStore: Initialized ObjectStore
25/11/26 07:05:49 INFO HiveMetaStore: Added admin role in metastore
25/11/26 07:05:49 INFO HiveMetaStore: Added public role in metastore
25/11/26 07:05:49 INFO HiveMetaStore: No user is added in admin role, since config is empty
25/11/26 07:05:49 INFO HiveMetaStore: 0: get_database: default
25/11/26 07:05:49 INFO audit: ugi=root	ip=unknown-ip-addr	cmd=get_database: default	
25/11/26 07:05:49 INFO HiveMetaStore: 0: get_database: default
25/11/26 07:05:49 INFO audit: ugi=root	ip=unknown-ip-addr	cmd=get_database: default	
25/11/26 07:05:49 INFO DriverCorral: Metastore health check ok
25/11/26 07:06:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:06:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:07:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:07:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:08:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:08:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:09:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:09:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:10:33 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:3306/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:10:33 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:10:33 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:10:33 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:10:33 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:10:33 INFO MetastoreMonitor: Metastore healthcheck successful (connection duration = 212 milliseconds)
25/11/26 07:10:33 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:9207/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:10:33 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:10:33 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:10:34 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:10:34 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:10:34 INFO MetastoreMonitor: PoPProxy healthcheck successful (connection duration = 215 milliseconds)
25/11/26 07:10:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:10:46 INFO DriverCorral: DBFS health check ok
25/11/26 07:10:46 INFO HiveMetaStore: 0: get_database: default
25/11/26 07:10:46 INFO audit: ugi=root	ip=unknown-ip-addr	cmd=get_database: default	
25/11/26 07:10:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:10:46 INFO DriverCorral: Metastore health check ok
25/11/26 07:11:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:11:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:12:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:12:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:13:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:13:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:14:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:14:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:15:34 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:3306/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:15:34 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:15:34 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:15:34 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:15:34 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:15:34 INFO MetastoreMonitor: Metastore healthcheck successful (connection duration = 202 milliseconds)
25/11/26 07:15:34 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:9207/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:15:34 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:15:34 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:15:34 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:15:34 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:15:34 INFO MetastoreMonitor: PoPProxy healthcheck successful (connection duration = 201 milliseconds)
25/11/26 07:15:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:15:46 INFO DriverCorral: DBFS health check ok
25/11/26 07:15:46 INFO HiveMetaStore: 0: get_database: default
25/11/26 07:15:46 INFO audit: ugi=root	ip=unknown-ip-addr	cmd=get_database: default	
25/11/26 07:15:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:15:46 INFO DriverCorral: Metastore health check ok
25/11/26 07:16:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:16:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:17:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:17:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:18:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:18:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:19:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:19:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:20:34 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:3306/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:20:34 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:20:34 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:20:34 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:20:34 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:20:34 INFO MetastoreMonitor: Metastore healthcheck successful (connection duration = 197 milliseconds)
25/11/26 07:20:34 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:9207/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:20:34 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:20:34 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:20:34 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:20:34 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:20:34 INFO MetastoreMonitor: PoPProxy healthcheck successful (connection duration = 207 milliseconds)
25/11/26 07:20:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:20:46 INFO DriverCorral: DBFS health check ok
25/11/26 07:20:46 INFO HiveMetaStore: 0: get_database: default
25/11/26 07:20:46 INFO audit: ugi=root	ip=unknown-ip-addr	cmd=get_database: default	
25/11/26 07:20:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:20:46 INFO DriverCorral: Metastore health check ok
25/11/26 07:21:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:21:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:22:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:22:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:23:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:23:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:24:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:24:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:25:34 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:3306/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:25:34 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:25:34 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:25:35 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:25:35 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:25:35 INFO MetastoreMonitor: Metastore healthcheck successful (connection duration = 196 milliseconds)
25/11/26 07:25:35 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:9207/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:25:35 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:25:35 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:25:35 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:25:35 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:25:35 INFO MetastoreMonitor: PoPProxy healthcheck successful (connection duration = 203 milliseconds)
25/11/26 07:25:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:25:46 INFO DriverCorral: DBFS health check ok
25/11/26 07:25:46 INFO HiveMetaStore: 0: get_database: default
25/11/26 07:25:46 INFO audit: ugi=root	ip=unknown-ip-addr	cmd=get_database: default	
25/11/26 07:25:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:25:46 INFO DriverCorral: Metastore health check ok
25/11/26 07:26:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:26:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:27:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:27:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:28:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:28:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:29:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:29:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:30:35 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:3306/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:30:35 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:30:35 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:30:35 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:30:35 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:30:35 INFO MetastoreMonitor: Metastore healthcheck successful (connection duration = 197 milliseconds)
25/11/26 07:30:35 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:9207/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:30:35 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:30:35 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:30:35 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:30:35 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:30:35 INFO MetastoreMonitor: PoPProxy healthcheck successful (connection duration = 198 milliseconds)
25/11/26 07:30:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:30:46 INFO DriverCorral: DBFS health check ok
25/11/26 07:30:46 INFO HiveMetaStore: 0: get_database: default
25/11/26 07:30:46 INFO audit: ugi=root	ip=unknown-ip-addr	cmd=get_database: default	
25/11/26 07:30:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:30:46 INFO DriverCorral: Metastore health check ok
25/11/26 07:31:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:31:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:32:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:32:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:33:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:33:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:34:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:34:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:35:35 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:3306/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:35:35 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:35:35 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:35:35 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:35:35 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:35:35 INFO MetastoreMonitor: Metastore healthcheck successful (connection duration = 203 milliseconds)
25/11/26 07:35:35 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:9207/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:35:35 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:35:35 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:35:36 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:35:36 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:35:36 INFO MetastoreMonitor: PoPProxy healthcheck successful (connection duration = 199 milliseconds)
25/11/26 07:35:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:35:46 INFO DriverCorral: DBFS health check ok
25/11/26 07:35:46 INFO HiveMetaStore: 0: get_database: default
25/11/26 07:35:46 INFO audit: ugi=root	ip=unknown-ip-addr	cmd=get_database: default	
25/11/26 07:35:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:35:46 INFO DriverCorral: Metastore health check ok
25/11/26 07:36:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:36:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:37:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:37:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:38:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:38:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:39:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:39:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:40:36 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:3306/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:40:36 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:40:36 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:40:36 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:40:36 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:40:36 INFO MetastoreMonitor: Metastore healthcheck successful (connection duration = 197 milliseconds)
25/11/26 07:40:36 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:9207/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:40:36 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:40:36 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:40:36 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:40:36 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:40:36 INFO MetastoreMonitor: PoPProxy healthcheck successful (connection duration = 202 milliseconds)
25/11/26 07:40:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:40:46 INFO DriverCorral: DBFS health check ok
25/11/26 07:40:46 INFO HiveMetaStore: 0: get_database: default
25/11/26 07:40:46 INFO audit: ugi=root	ip=unknown-ip-addr	cmd=get_database: default	
25/11/26 07:40:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:40:46 INFO DriverCorral: Metastore health check ok
25/11/26 07:41:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:41:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:42:37 WARN SQLConf: The SQL config 'spark.sql.hive.convertCTAS' has been deprecated in Spark v3.1 and may be removed in the future. Set 'spark.sql.legacy.createHiveTableByDefault' to false instead.
25/11/26 07:42:37 WARN SQLConf: The SQL config 'spark.sql.hive.convertCTAS' has been deprecated in Spark v3.1 and may be removed in the future. Set 'spark.sql.legacy.createHiveTableByDefault' to false instead.
25/11/26 07:42:37 INFO DriverCorral: Starting python repl ReplId-3524e-e946b-bbd36-7
25/11/26 07:42:37 INFO DynamicTracingConf: Configured feature flag data source LaunchDarkly
25/11/26 07:42:37 INFO DynamicTracingConf: Configured feature flag data source LaunchDarkly
25/11/26 07:42:37 WARN DynamicTracingConf: REGION environment variable is not defined. getConfForCurrentRegion will always return default value
25/11/26 07:42:38 INFO JupyterDriverLocal: Starting gateway server for repl ReplId-3524e-e946b-bbd36-7
25/11/26 07:42:38 INFO PythonPy4JUtil: Using pinned thread mode in Py4J
25/11/26 07:42:38 INFO VirtualenvCloneHelper: Creating notebook-scoped virtualenv for 8bde49c7-6f49-493d-a3b1-c7988d7050c9
25/11/26 07:42:38 INFO Utils: resolved command to be run: List(virtualenv, /local_disk0/.ephemeral_nfs/envs/pythonEnv-8bde49c7-6f49-493d-a3b1-c7988d7050c9, -p, /local_disk0/.ephemeral_nfs/cluster_libraries/python/bin/python, --no-download, --no-setuptools, --no-wheel)
25/11/26 07:42:38 INFO PythonEnvCloneHelper$: Created python virtualenv: /local_disk0/.ephemeral_nfs/envs/pythonEnv-8bde49c7-6f49-493d-a3b1-c7988d7050c9
25/11/26 07:42:38 INFO Utils: resolved command to be run: List(/local_disk0/.ephemeral_nfs/cluster_libraries/python/bin/python, -c, import sys; dirs=[p for p in sys.path if 'package' in p]; print(' '.join(dirs)))
25/11/26 07:42:38 INFO Utils: resolved command to be run: List(/local_disk0/.ephemeral_nfs/envs/pythonEnv-8bde49c7-6f49-493d-a3b1-c7988d7050c9/bin/python, -c, from distutils.sysconfig import get_python_lib; print(get_python_lib()))
25/11/26 07:42:38 INFO PythonEnvCloneHelper$: Created sites.pth at /local_disk0/.ephemeral_nfs/envs/pythonEnv-8bde49c7-6f49-493d-a3b1-c7988d7050c9/lib/python3.9/site-packages/sites.pth
25/11/26 07:42:38 INFO NotebookScopedPythonEnvManager: Time spent to start virtualenv /local_disk0/.ephemeral_nfs/envs/pythonEnv-8bde49c7-6f49-493d-a3b1-c7988d7050c9 is 248(ms)
25/11/26 07:42:38 INFO NotebookScopedPythonEnvManager: Registered /local_disk0/.ephemeral_nfs/envs/pythonEnv-8bde49c7-6f49-493d-a3b1-c7988d7050c9/lib/python3.9/site-packages with the WatchService sun.nio.fs.LinuxWatchService$LinuxWatchKey@7a808252
25/11/26 07:42:38 INFO IpykernelUtils$: Python process builder: [bash, /local_disk0/.ephemeral_nfs/envs/pythonEnv-8bde49c7-6f49-493d-a3b1-c7988d7050c9/python_start_8bde49c7-6f49-493d-a3b1-c7988d7050c9.sh, /databricks/spark/python/pyspark/wrapped_python.py, root, /local_disk0/.ephemeral_nfs/envs/pythonEnv-8bde49c7-6f49-493d-a3b1-c7988d7050c9/bin/python, /databricks/python_shell/scripts/db_ipykernel_launcher.py, -f, /databricks/kernel-connections/bbec436fb25625031b05e45bc6d95912997755788d5e3c355c510172b73fff2a.json]
25/11/26 07:42:38 INFO IpykernelUtils$: Cgroup isolation disabled, not placing python process in repl cgroup
25/11/26 07:42:40 INFO PythonDriverWrapper: setupRepl:ReplId-3524e-e946b-bbd36-7: finished to load
25/11/26 07:42:40 INFO DriverConf: Configured feature flag data source LaunchDarkly
25/11/26 07:42:40 INFO DriverConf: Configured feature flag data source LaunchDarkly
25/11/26 07:42:40 WARN DriverConf: REGION environment variable is not defined. getConfForCurrentRegion will always return default value
25/11/26 07:42:41 INFO ProgressReporter$: Added result fetcher for 3829447904401806183_7598504344085800217_run-1087956387186349-precondition
25/11/26 07:42:41 INFO ProgressReporter$: Reporting progress for running commands: 3829447904401806183_7598504344085800217_run-1087956387186349-precondition
25/11/26 07:42:41 INFO ProgressReporter$: Removed result fetcher for 3829447904401806183_7598504344085800217_run-1087956387186349-precondition
25/11/26 07:42:41 WARN SQLConf: The SQL config 'spark.sql.hive.convertCTAS' has been deprecated in Spark v3.1 and may be removed in the future. Set 'spark.sql.legacy.createHiveTableByDefault' to false instead.
25/11/26 07:42:41 WARN SQLConf: The SQL config 'spark.sql.hive.convertCTAS' has been deprecated in Spark v3.1 and may be removed in the future. Set 'spark.sql.legacy.createHiveTableByDefault' to false instead.
25/11/26 07:42:41 INFO DriverCorral: Starting python repl ReplId-6bf59-6462b-f0c94-6
25/11/26 07:42:41 INFO JupyterDriverLocal: Starting gateway server for repl ReplId-6bf59-6462b-f0c94-6
25/11/26 07:42:41 INFO PythonPy4JUtil: Using pinned thread mode in Py4J
25/11/26 07:42:42 INFO VirtualenvCloneHelper: Creating notebook-scoped virtualenv for 3d14f00c-6b84-4644-acae-9b9522029cb4
25/11/26 07:42:42 INFO Utils: resolved command to be run: List(virtualenv, /local_disk0/.ephemeral_nfs/envs/pythonEnv-3d14f00c-6b84-4644-acae-9b9522029cb4, -p, /local_disk0/.ephemeral_nfs/cluster_libraries/python/bin/python, --no-download, --no-setuptools, --no-wheel)
25/11/26 07:42:42 INFO PythonEnvCloneHelper$: Created python virtualenv: /local_disk0/.ephemeral_nfs/envs/pythonEnv-3d14f00c-6b84-4644-acae-9b9522029cb4
25/11/26 07:42:42 INFO Utils: resolved command to be run: List(/local_disk0/.ephemeral_nfs/cluster_libraries/python/bin/python, -c, import sys; dirs=[p for p in sys.path if 'package' in p]; print(' '.join(dirs)))
25/11/26 07:42:42 INFO Utils: resolved command to be run: List(/local_disk0/.ephemeral_nfs/envs/pythonEnv-3d14f00c-6b84-4644-acae-9b9522029cb4/bin/python, -c, from distutils.sysconfig import get_python_lib; print(get_python_lib()))
25/11/26 07:42:42 INFO PythonEnvCloneHelper$: Created sites.pth at /local_disk0/.ephemeral_nfs/envs/pythonEnv-3d14f00c-6b84-4644-acae-9b9522029cb4/lib/python3.9/site-packages/sites.pth
25/11/26 07:42:42 INFO NotebookScopedPythonEnvManager: Time spent to start virtualenv /local_disk0/.ephemeral_nfs/envs/pythonEnv-3d14f00c-6b84-4644-acae-9b9522029cb4 is 253(ms)
25/11/26 07:42:42 INFO NotebookScopedPythonEnvManager: Registered /local_disk0/.ephemeral_nfs/envs/pythonEnv-3d14f00c-6b84-4644-acae-9b9522029cb4/lib/python3.9/site-packages with the WatchService sun.nio.fs.LinuxWatchService$LinuxWatchKey@70c8c3d1
25/11/26 07:42:42 INFO IpykernelUtils$: Python process builder: [bash, /local_disk0/.ephemeral_nfs/envs/pythonEnv-3d14f00c-6b84-4644-acae-9b9522029cb4/python_start_3d14f00c-6b84-4644-acae-9b9522029cb4.sh, /databricks/spark/python/pyspark/wrapped_python.py, root, /local_disk0/.ephemeral_nfs/envs/pythonEnv-3d14f00c-6b84-4644-acae-9b9522029cb4/bin/python, /databricks/python_shell/scripts/db_ipykernel_launcher.py, -f, /databricks/kernel-connections/0e3c8db196ce0d3132d0fccfe966aecf67e595380915eecab2d69b4c9700f1f5.json]
25/11/26 07:42:42 INFO IpykernelUtils$: Cgroup isolation disabled, not placing python process in repl cgroup
25/11/26 07:42:44 INFO PythonDriverWrapper: setupRepl:ReplId-6bf59-6462b-f0c94-6: finished to load
25/11/26 07:42:44 INFO ProgressReporter$: Added result fetcher for 7779289159481477446_4613314583346715124_608b6809-5526-4b90-9227-f36e91c57387
25/11/26 07:42:44 INFO ProgressReporter$: Removed result fetcher for 7779289159481477446_4613314583346715124_608b6809-5526-4b90-9227-f36e91c57387
25/11/26 07:42:44 INFO ProgressReporter$: Added result fetcher for 7779289159481477446_6431207694236545823_job-1062320909976339-run-1087956387186349-action-643456424335716
25/11/26 07:42:44 INFO ProgressReporter$: Reporting partial results for running commands: 7779289159481477446_6431207694236545823_job-1062320909976339-run-1087956387186349-action-643456424335716
25/11/26 07:42:45 INFO HiveUnityCatalogCheckRule: Collecting SQL actions took 0.007363 ms.
25/11/26 07:42:45 INFO HiveUnityCatalogCheckRule: Collecting SQL actions took 0.046908 ms.
25/11/26 07:42:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:42:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:42:46 INFO DriverConf: Configured feature flag data source LaunchDarkly
25/11/26 07:42:46 INFO DriverConf: Configured feature flag data source LaunchDarkly
25/11/26 07:42:46 WARN DriverConf: REGION environment variable is not defined. getConfForCurrentRegion will always return default value
25/11/26 07:42:47 ERROR AbfsClient: HttpRequest: 403,err=,appendpos=,cid=1125-113639-ndjs76hq------:9d003b84-021f-46bc-9cce-9246bac00900:494bc108-eb93-4de6-b0de-4f2a50735182:::GF:0,rid=4f980368-301f-001b-71a8-5e7dd0000000,connMs=0,sendMs=0,recvMs=17,sent=0,recv=0,method=HEAD,https://tarhonemetastore.dfs.core.chinacloudapi.cn/uctarhone/_encryption_meta/manifest.json?upn=false&action=getStatus&timeout=90&st=2025-11-26T07:32:47Z&sv=2020-02-10&ske=2025-11-26T09:32:47Z&sig=XXXXX&sktid=073e223d-89a0-4197-b5c0-096aced1ef02&se=2025-11-26T08:42:47Z&sdd=4&skoid=b6eba1ca-db96-49f9XXXXXXXXXXXXXXXXXX&spr=https&sks=b&skt=2025-11-26T07:32:47Z&sp=racwdxlm&skv=2025-01-05&sr=d
25/11/26 07:42:47 WARN FallbackEncryptionContextProvider: Accessing the manifest file failed with 403.
25/11/26 07:42:47 INFO AzureBlobFileSystem:V3: Initializing AzureBlobFileSystem for abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1 with credential = CredentialScopeADLSTokenProvider with jvmId = 1714
25/11/26 07:42:47 ERROR AbfsClient: HttpRequest: 409,err=PathAlreadyExists,appendpos=,cid=1125-113639-ndjs76hq------:bf92a91a-3b06-47d1-a6e8-cf176b954243:494bc108-eb93-4de6-b0de-4f2a50735182:::MK:0,rid=4f980369-301f-001b-72a8-5e7dd0000000,connMs=0,sendMs=0,recvMs=276,sent=0,recv=168,method=PUT,https://tarhonemetastore.dfs.core.chinacloudapi.cn/uctarhone/tarhoneroot1/bronze/test/vwtable1?resource=directory&timeout=90&st=2025-11-26T07:32:47Z&sv=2020-02-10&ske=2025-11-26T09:32:47Z&sig=XXXXX&sktid=073e223d-89a0-4197-b5c0-096aced1ef02&se=2025-11-26T08:42:47Z&sdd=4&skoid=b6eba1ca-db96-49f9XXXXXXXXXXXXXXXXXX&spr=https&sks=b&skt=2025-11-26T07:32:47Z&sp=racwdxlm&skv=2025-01-05&sr=d
25/11/26 07:42:48 INFO AzureBlobFileSystem:V3: Initializing AzureBlobFileSystem for abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1 with credential = CredentialScopeADLSTokenProvider with jvmId = 1714
25/11/26 07:42:48 INFO HiveUnityCatalogCheckRule: Collecting SQL actions took 0.009555 ms.
25/11/26 07:42:48 INFO ClusterLoadMonitor: Added query with execution ID:0. Current active queries:1
25/11/26 07:42:48 INFO LogicalPlanStats: Setting LogicalPlanStats visitor to com.databricks.sql.optimizer.statsEstimation.DatabricksLogicalPlanStatsVisitor$
25/11/26 07:42:48 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 0.0, New Ema: 1.0 
25/11/26 07:42:50 INFO DBCEventLoggingListener: Rolling event log; numTimesRolledOver = 1
25/11/26 07:42:50 INFO DBCEventLoggingListener: Rolled active log file /databricks/driver/eventlogs/1151128536340376051/eventlog to /databricks/driver/eventlogs/1151128536340376051/eventlog-2025-11-26--07-10, size = 272499
25/11/26 07:42:50 INFO DBCEventLoggingListener: Logging events to eventlogs/1151128536340376051/eventlog
25/11/26 07:42:50 INFO DBCEventLoggingListener: Compressed rolled file /databricks/driver/eventlogs/1151128536340376051/eventlog-2025-11-26--07-10 to /databricks/driver/eventlogs/1151128536340376051/eventlog-2025-11-26--07-10.gz in 26ms, size = 44995
25/11/26 07:42:50 INFO DBCEventLoggingListener: Deleted rolled file eventlogs/1151128536340376051/eventlog-2025-11-26--07-10
25/11/26 07:42:51 INFO DeltaLog: Loading version 11 starting from checkpoint version 10.
25/11/26 07:42:51 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:42:52 INFO SnapshotEdge: [tableId=e18daebc-2ede-4a02-bc5e-ec2ef421cf69] Created snapshot SnapshotEdge(path=abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log, version=11, metadata=Metadata(62bed5a3-0999-4586-90cd-7b6af6e36be7,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"id","type":"integer","nullable":true,"metadata":{"scale":0}},{"name":"name","type":"string","nullable":true,"metadata":{"scale":0}},{"name":"age","type":"integer","nullable":true,"metadata":{"scale":0}},{"name":"grade","type":"decimal(4,2)","nullable":true,"metadata":{"scale":2}},{"name":"birthday","type":"date","nullable":true,"metadata":{"scale":0}},{"name":"logintime","type":"timestamp","nullable":true,"metadata":{"scale":6}}]},List(),Map(),Some(1764131452056)), logSegment=LogSegment(abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log,11,WrappedArray(VersionedFileStatus{VersionedFileStatus{path=abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/00000000000000000011.json; isDirectory=false; length=1518; replication=1; blocksize=268435456; modification_time=1764140376000; access_time=0; owner=b6eba1ca-db96-49f9-b19f-f309bce4121d; group=$superuser; permission=rw-r--r--; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false}; version='0x8DE2CB95C7EAE99'}),WrappedArray(VersionedFileStatus{VersionedFileStatus{path=abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/00000000000000000010.checkpoint.parquet; isDirectory=false; length=25741; replication=1; blocksize=268435456; modification_time=1764139674000; access_time=0; owner=b6eba1ca-db96-49f9-b19f-f309bce4121d; group=$superuser; permission=rw-r--r--; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false}; version='0x8DE2CB7B9F4F209'}),Some(10),1764140376000), checksumOpt=Some(VersionChecksum(Some(aaff2d93-039a-4b90-a437-7eed51e8281c),3646547568,9,None,None,1,1,Some(List()),None,Metadata(62bed5a3-0999-4586-90cd-7b6af6e36be7,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"id","type":"integer","nullable":true,"metadata":{"scale":0}},{"name":"name","type":"string","nullable":true,"metadata":{"scale":0}},{"name":"age","type":"integer","nullable":true,"metadata":{"scale":0}},{"name":"grade","type":"decimal(4,2)","nullable":true,"metadata":{"scale":2}},{"name":"birthday","type":"date","nullable":true,"metadata":{"scale":0}},{"name":"logintime","type":"timestamp","nullable":true,"metadata":{"scale":6}}]},List(),Map(),Some(1764131452056)),Protocol(1,2),Some(FileSizeHistogram(Vector(0, 8192, 16384, 32768, 65536, 131072, 262144, 524288, 1048576, 2097152, 4194304, 8388608, 12582912, 16777216, 20971520, 25165824, 29360128, 33554432, 37748736, 41943040, 50331648, 58720256, 67108864, 75497472, 83886080, 92274688, 100663296, 109051904, 117440512, 125829120, 130023424, 134217728, 138412032, 142606336, 146800640, 150994944, 167772160, 184549376, 201326592, 218103808, 234881024, 251658240, 268435456, 285212672, 301989888, 318767104, 335544320, 352321536, 369098752, 385875968, 402653184, 419430400, 436207616, 452984832, 469762048, 486539264, 503316480, 520093696, 536870912, 553648128, 570425344, 587202560, 603979776, 671088640, 738197504, 805306368, 872415232, 939524096, 1006632960, 1073741824, 1140850688, 1207959552, 1275068416, 1342177280, 1409286144, 1476395008, 1610612736, 1744830464, 1879048192, 2013265920, 2147483648, 2415919104, 2684354560, 2952790016, 3221225472, 3489660928, 3758096384, 4026531840, 4294967296, 8589934592, 17179869184, 34359738368, 68719476736, 137438953472, 274877906944),[J@7db787e3,[J@32e8429c)),None,Some(List(AddFile(part-00000-884d449d-510d-499b-86b0-788d47e58357-c000.snappy.parquet,Map(),405171952,1764136774000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764136774000000, MIN_INSERTION_TIME -> 1764136774000000, MAX_INSERTION_TIME -> 1764136774000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-5e1c2199-b033-4e49-8d2e-d75a95e4871f-c000.snappy.parquet,Map(),405171952,1764135958000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764135958000000, MIN_INSERTION_TIME -> 1764135958000000, MAX_INSERTION_TIME -> 1764135958000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-c07e2cc6-f2ac-44bd-a972-b2db6f803a6e-c000.snappy.parquet,Map(),405171952,1764135057000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764135057000000, MIN_INSERTION_TIME -> 1764135057000000, MAX_INSERTION_TIME -> 1764135057000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-a650ea24-1236-4c21-a4f9-d04923945b4c-c000.snappy.parquet,Map(),405171952,1764140375000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764140375000000, MIN_INSERTION_TIME -> 1764140375000000, MAX_INSERTION_TIME -> 1764140375000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-e5f2304d-bad7-491d-ad4c-0e85916c37a6-c000.snappy.parquet,Map(),405171952,1764137105000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764137105000000, MIN_INSERTION_TIME -> 1764137105000000, MAX_INSERTION_TIME -> 1764137105000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-9bcc8d32-27ed-44cf-b137-a1cee0b2926e-c000.snappy.parquet,Map(),405171952,1764137553000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764137553000000, MIN_INSERTION_TIME -> 1764137553000000, MAX_INSERTION_TIME -> 1764137553000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-4a2e5635-bd9b-4892-9e39-c53414c85b07-c000.snappy.parquet,Map(),405171952,1764135429000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764135429000000, MIN_INSERTION_TIME -> 1764135429000000, MAX_INSERTION_TIME -> 1764135429000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-c15fd30b-8147-4e96-a419-0a7fe6f8953a-c000.snappy.parquet,Map(),405171952,1764136406000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764136406000000, MIN_INSERTION_TIME -> 1764136406000000, MAX_INSERTION_TIME -> 1764136406000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-93ed7c89-5969-4fcc-bc14-6c931e8bceaa-c000.snappy.parquet,Map(),405171952,1764139669000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764139669000000, MIN_INSERTION_TIME -> 1764139669000000, MAX_INSERTION_TIME -> 1764139669000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None))))))
25/11/26 07:42:53 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 436.5 KiB, free 4.4 GiB)
25/11/26 07:42:53 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 156.7 KiB, free 4.4 GiB)
25/11/26 07:42:53 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 18.5 KiB, free 4.4 GiB)
25/11/26 07:42:53 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.139.64.5:43879 (size: 18.5 KiB, free: 4.4 GiB)
25/11/26 07:42:53 INFO SparkContext: Created broadcast 1 from writeExternal at ObjectOutputStream.java:1459
25/11/26 07:42:53 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 4.4 GiB)
25/11/26 07:42:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.139.64.5:43879 (size: 15.8 KiB, free: 4.4 GiB)
25/11/26 07:42:53 INFO SparkContext: Created broadcast 0 from broadcast at DeltaLog.scala:718
25/11/26 07:42:53 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(Parquet, numFilesInSegment: 1, totalFileSize: 25741)
25/11/26 07:42:53 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 1, totalFileSize: 1518)
25/11/26 07:42:54 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:42:55 INFO CodeGenerator: Code generated in 356.385063 ms
25/11/26 07:42:55 INFO CodeGenerator: Code generated in 35.083945 ms
25/11/26 07:42:55 INFO CodeGenerator: Code generated in 252.565346 ms
25/11/26 07:42:55 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 32.7 KiB, free 4.4 GiB)
25/11/26 07:42:55 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.5 KiB, free 4.4 GiB)
25/11/26 07:42:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.139.64.5:43879 (size: 14.5 KiB, free: 4.4 GiB)
25/11/26 07:42:55 INFO SparkContext: Created broadcast 2 from $anonfun$executePhase$2 at LexicalThreadLocal.scala:63
25/11/26 07:42:55 INFO CodeGenerator: Code generated in 125.11638 ms
25/11/26 07:42:55 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 40.2 KiB, free 4.4 GiB)
25/11/26 07:42:56 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 12.5 KiB, free 4.4 GiB)
25/11/26 07:42:56 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.139.64.5:43879 (size: 12.5 KiB, free: 4.4 GiB)
25/11/26 07:42:56 INFO SparkContext: Created broadcast 3 from $anonfun$executePhase$2 at LexicalThreadLocal.scala:63
25/11/26 07:42:56 INFO FileSourceStrategy: Pushed Filters: 
25/11/26 07:42:56 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/26 07:42:56 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
25/11/26 07:42:56 INFO CodeGenerator: Code generated in 127.981353 ms
25/11/26 07:42:57 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 537.7 KiB, free 4.4 GiB)
25/11/26 07:42:57 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 19.5 KiB, free 4.4 GiB)
25/11/26 07:42:57 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.139.64.5:43879 (size: 19.5 KiB, free: 4.4 GiB)
25/11/26 07:42:57 INFO SparkContext: Created broadcast 4 from $anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63
25/11/26 07:42:57 INFO FileSourceScanExec: Planning scan with bin packing, max split size: 134217728 bytes, max partition size: 4194304, open cost is considered as scanning 4194304 bytes.
25/11/26 07:42:57 INFO RocksDBLoader: RocksDB library loading thread started
25/11/26 07:42:57 INFO RocksDBLoader: RocksDB library loading thread finished successfully
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] RocksDB version: 6.28.2

25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] Compile date 2022-02-04 22:23:17
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] DB SUMMARY

25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] DB Session ID:  BBDMBGHDGDBA9EO34TOV

25/11/26 07:42:57 ERROR RocksDBExternalMap: [Native-3] Error when reading /local_disk0/dbio_cache_root_1714-066bb9ed-387e-4588-be2d-22366c253126/locality_assignments-fc4b64a7-2021-478c-b9d9-80a4bb22be79/15901167646643 dir

25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] SST files in /local_disk0/dbio_cache_root_1714-066bb9ed-387e-4588-be2d-22366c253126/locality_assignments-fc4b64a7-2021-478c-b9d9-80a4bb22be79/15901167646643 dir, Total Num: 0, files: 

25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] Write Ahead Log file in /local_disk0/dbio_cache_root_1714-066bb9ed-387e-4588-be2d-22366c253126/locality_assignments-fc4b64a7-2021-478c-b9d9-80a4bb22be79/15901167646643: 

25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                         Options.error_if_exists: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                       Options.create_if_missing: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                         Options.paranoid_checks: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]             Options.flush_verify_memtable_count: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                               Options.track_and_verify_wals_in_manifest: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                                     Options.env: 0x7f23430c6780
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                                      Options.fs: PosixFileSystem
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                                Options.info_log: 0x7f23881f5ba8
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                Options.max_file_opening_threads: 16
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                              Options.statistics: (nil)
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                               Options.use_fsync: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                       Options.max_log_file_size: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                  Options.max_manifest_file_size: 1073741824
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                   Options.log_file_time_to_roll: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                       Options.keep_log_file_num: 1000
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                    Options.recycle_log_file_num: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                         Options.allow_fallocate: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                        Options.allow_mmap_reads: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                       Options.allow_mmap_writes: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                        Options.use_direct_reads: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                        Options.use_direct_io_for_flush_and_compaction: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]          Options.create_missing_column_families: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                              Options.db_log_dir: 
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                                 Options.wal_dir: 
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                Options.table_cache_numshardbits: 6
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                         Options.WAL_ttl_seconds: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                       Options.WAL_size_limit_MB: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                        Options.max_write_batch_group_size_bytes: 1048576
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]             Options.manifest_preallocation_size: 4194304
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                     Options.is_fd_close_on_exec: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                   Options.advise_random_on_open: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                   Options.experimental_mempurge_threshold: 0.000000
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                    Options.db_write_buffer_size: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                    Options.write_buffer_manager: 0x7f23881e4c90
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]         Options.access_hint_on_compaction_start: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]  Options.new_table_reader_for_compaction_inputs: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]           Options.random_access_max_buffer_size: 1048576
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                      Options.use_adaptive_mutex: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                            Options.rate_limiter: (nil)
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]     Options.sst_file_manager.rate_bytes_per_sec: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                       Options.wal_recovery_mode: 2
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                  Options.enable_thread_tracking: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                  Options.enable_pipelined_write: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                  Options.unordered_write: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]         Options.allow_concurrent_memtable_write: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]      Options.enable_write_thread_adaptive_yield: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]             Options.write_thread_max_yield_usec: 100
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]            Options.write_thread_slow_yield_usec: 3
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                               Options.row_cache: None
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                              Options.wal_filter: None
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]             Options.avoid_flush_during_recovery: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]             Options.allow_ingest_behind: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]             Options.preserve_deletes: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]             Options.two_write_queues: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]             Options.manual_wal_flush: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]             Options.atomic_flush: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]             Options.avoid_unnecessary_blocking_io: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                 Options.persist_stats_to_disk: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                 Options.write_dbid_to_manifest: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                 Options.log_readahead_size: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                 Options.file_checksum_gen_factory: Unknown
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                 Options.best_efforts_recovery: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                Options.max_bgerror_resume_count: 2147483647
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]            Options.bgerror_resume_retry_interval: 1000000
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]             Options.allow_data_in_errors: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]             Options.db_host_id: __hostname__
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]             Options.max_background_jobs: 2
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]             Options.max_background_compactions: -1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]             Options.max_subcompactions: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]             Options.avoid_flush_during_shutdown: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]           Options.writable_file_max_buffer_size: 1048576
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]             Options.delayed_write_rate : 16777216
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]             Options.max_total_wal_size: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]             Options.delete_obsolete_files_period_micros: 21600000000
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                   Options.stats_dump_period_sec: 600
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                 Options.stats_persist_period_sec: 600
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                 Options.stats_history_buffer_size: 1048576
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                          Options.max_open_files: -1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                          Options.bytes_per_sync: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                      Options.wal_bytes_per_sync: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                   Options.strict_bytes_per_sync: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]       Options.compaction_readahead_size: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                  Options.max_background_flushes: -1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] Compression algorithms supported:
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] 	kZSTDNotFinalCompression supported: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] 	kZSTD supported: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] 	kXpressCompression supported: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] 	kLZ4HCCompression supported: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] 	kLZ4Compression supported: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] 	kBZip2Compression supported: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] 	kZlibCompression supported: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] 	kSnappyCompression supported: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] Fast CRC32 supported: Not supported on x86
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] [/db_impl/db_impl_open.cc:307] Creating manifest 1 

25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] [/version_set.cc:4847] Recovering from manifest file: /local_disk0/dbio_cache_root_1714-066bb9ed-387e-4588-be2d-22366c253126/locality_assignments-fc4b64a7-2021-478c-b9d9-80a4bb22be79/15901167646643/MANIFEST-000001

25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] [/column_family.cc:607] --------------- Options for column family [default]:

25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]               Options.comparator: leveldb.BytewiseComparator
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]           Options.merge_operator: None
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]        Options.compaction_filter: None
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]        Options.compaction_filter_factory: None
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]  Options.sst_partitioner_factory: None
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]         Options.memtable_factory: SkipListFactory
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]            Options.table_factory: BlockBasedTable
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]            table_factory options:   flush_block_policy_factory: FlushBlockBySizePolicyFactory (0x7f23881f72a0)
  cache_index_and_filter_blocks: 0
  cache_index_and_filter_blocks_with_high_priority: 1
  pin_l0_filter_and_index_blocks_in_cache: 0
  pin_top_level_index_and_filter: 1
  index_type: 0
  data_block_index_type: 0
  index_shortening: 1
  data_block_hash_table_util_ratio: 0.750000
  hash_index_allow_collision: 1
  checksum: 1
  no_block_cache: 0
  block_cache: 0x7f23881f5e90
  block_cache_name: LRUCache
  block_cache_options:
    capacity : 8388608
    num_shard_bits : 4
    strict_capacity_limit : 0
    memory_allocator : None
    high_pri_pool_ratio: 0.000
  block_cache_compressed: (nil)
  persistent_cache: (nil)
  block_size: 4096
  block_size_deviation: 10
  block_restart_interval: 16
  index_block_restart_interval: 1
  metadata_block_size: 4096
  partition_filters: 0
  use_delta_encoding: 1
  filter_policy: nullptr
  whole_key_filtering: 1
  verify_compression: 0
  read_amp_bytes_per_bit: 0
  format_version: 5
  enable_index_compression: 1
  block_align: 0
  max_auto_readahead_size: 262144
  prepopulate_block_cache: 0

25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]        Options.write_buffer_size: 67108864
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]  Options.max_write_buffer_number: 2
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]          Options.compression: Snappy
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                  Options.bottommost_compression: Disabled
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]       Options.prefix_extractor: nullptr
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]   Options.memtable_insert_with_hint_prefix_extractor: nullptr
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]             Options.num_levels: 7
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]        Options.min_write_buffer_number_to_merge: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]     Options.max_write_buffer_number_to_maintain: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]     Options.max_write_buffer_size_to_maintain: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]            Options.bottommost_compression_opts.window_bits: -14
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                  Options.bottommost_compression_opts.level: 32767
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]               Options.bottommost_compression_opts.strategy: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]         Options.bottommost_compression_opts.max_dict_bytes: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]         Options.bottommost_compression_opts.zstd_max_train_bytes: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]         Options.bottommost_compression_opts.parallel_threads: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                  Options.bottommost_compression_opts.enabled: false
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]         Options.bottommost_compression_opts.max_dict_buffer_bytes: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]            Options.compression_opts.window_bits: -14
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                  Options.compression_opts.level: 32767
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]               Options.compression_opts.strategy: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]         Options.compression_opts.max_dict_bytes: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]         Options.compression_opts.zstd_max_train_bytes: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]         Options.compression_opts.parallel_threads: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                  Options.compression_opts.enabled: false
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]         Options.compression_opts.max_dict_buffer_bytes: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]      Options.level0_file_num_compaction_trigger: 4
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]          Options.level0_slowdown_writes_trigger: 20
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]              Options.level0_stop_writes_trigger: 36
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                   Options.target_file_size_base: 67108864
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]             Options.target_file_size_multiplier: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                Options.max_bytes_for_level_base: 268435456
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] Options.level_compaction_dynamic_level_bytes: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]          Options.max_bytes_for_level_multiplier: 10.000000
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] Options.max_bytes_for_level_multiplier_addtl[0]: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] Options.max_bytes_for_level_multiplier_addtl[1]: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] Options.max_bytes_for_level_multiplier_addtl[2]: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] Options.max_bytes_for_level_multiplier_addtl[3]: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] Options.max_bytes_for_level_multiplier_addtl[4]: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] Options.max_bytes_for_level_multiplier_addtl[5]: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] Options.max_bytes_for_level_multiplier_addtl[6]: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]       Options.max_sequential_skip_in_iterations: 8
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                    Options.max_compaction_bytes: 1677721600
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                        Options.arena_block_size: 1048576
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]   Options.soft_pending_compaction_bytes_limit: 68719476736
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]   Options.hard_pending_compaction_bytes_limit: 274877906944
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]       Options.rate_limit_delay_max_milliseconds: 100
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                Options.disable_auto_compactions: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                        Options.compaction_style: kCompactionStyleLevel
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                          Options.compaction_pri: kMinOverlappingRatio
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] Options.compaction_options_universal.size_ratio: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] Options.compaction_options_universal.min_merge_width: 2
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] Options.compaction_options_universal.max_merge_width: 4294967295
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] Options.compaction_options_universal.max_size_amplification_percent: 200
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] Options.compaction_options_universal.compression_size_percent: -1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] Options.compaction_options_universal.stop_style: kCompactionStopStyleTotalSize
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] Options.compaction_options_fifo.max_table_files_size: 1073741824
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] Options.compaction_options_fifo.allow_compaction: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                   Options.table_properties_collectors: 
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                   Options.inplace_update_support: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                 Options.inplace_update_num_locks: 10000
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]               Options.memtable_prefix_bloom_size_ratio: 0.000000
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]               Options.memtable_whole_key_filtering: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]   Options.memtable_huge_page_size: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                           Options.bloom_locality: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                    Options.max_successive_merges: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                Options.optimize_filters_for_hits: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                Options.paranoid_file_checks: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                Options.force_consistency_checks: 1
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                Options.report_bg_io_stats: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                               Options.ttl: 2592000
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]          Options.periodic_compaction_seconds: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                       Options.enable_blob_files: false
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                           Options.min_blob_size: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                          Options.blob_file_size: 268435456
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]                   Options.blob_compression_type: NoCompression
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]          Options.enable_blob_garbage_collection: false
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]      Options.blob_garbage_collection_age_cutoff: 0.250000
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] Options.blob_garbage_collection_force_threshold: 1.000000
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1]          Options.blob_compaction_readahead_size: 0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] [/version_set.cc:4895] Recovered from manifest file:/local_disk0/dbio_cache_root_1714-066bb9ed-387e-4588-be2d-22366c253126/locality_assignments-fc4b64a7-2021-478c-b9d9-80a4bb22be79/15901167646643/MANIFEST-000001 succeeded,manifest_file_number is 1, next_file_number is 3, last_sequence is 0, log_number is 0,prev_log_number is 0,max_column_family is 0,min_log_number_to_keep is 0

25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] [/version_set.cc:4904] Column family [default] (ID 0), log number is 0

25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] [/version_set.cc:4385] Creating manifest 4

25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] [/db_impl/db_impl_open.cc:1793] SstFileManager instance 0x7f238801d340
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] DB pointer 0x7f23881e51b0
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] [/db_impl/db_impl.cc:1005] ------- DUMPING STATS -------
25/11/26 07:42:57 INFO RocksDBExternalMap: [Native-1] [/db_impl/db_impl.cc:1006] 
** DB Stats **
Uptime(secs): 0.0 total, 0.0 interval
Cumulative writes: 0 writes, 0 keys, 0 commit groups, 0.0 writes per commit group, ingest: 0.00 GB, 0.00 MB/s
Cumulative WAL: 0 writes, 0 syncs, 0.00 writes per sync, written: 0.00 GB, 0.00 MB/s
Cumulative stall: 00:00:0.000 H:M:S, 0.0 percent
Interval writes: 0 writes, 0 keys, 0 commit groups, 0.0 writes per commit group, ingest: 0.00 MB, 0.00 MB/s
Interval WAL: 0 writes, 0 syncs, 0.00 writes per sync, written: 0.00 GB, 0.00 MB/s
Interval stall: 00:00:0.000 H:M:S, 0.0 percent

** Compaction Stats [default] **
Level    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop Rblob(GB) Wblob(GB)
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Sum      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0       0.0       0.0
 Int      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0       0.0       0.0

** Compaction Stats [default] **
Priority    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop Rblob(GB) Wblob(GB)
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Blob file count: 0, total size: 0.0 GB

Uptime(secs): 0.0 total, 0.0 interval
Flush(GB): cumulative 0.000, interval 0.000
AddFile(GB): cumulative 0.000, interval 0.000
AddFile(Total Files): cumulative 0, interval 0
AddFile(L0 Files): cumulative 0, interval 0
AddFile(Keys): cumulative 0, interval 0
Cumulative compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Interval compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Stalls(count): 0 level0_slowdown, 0 level0_slowdown_with_compaction, 0 level0_numfiles, 0 level0_numfiles_with_compaction, 0 stop for pending_compaction_bytes, 0 slowdown for pending_compaction_bytes, 0 memtable_compaction, 0 memtable_slowdown, interval 0 total count
Block cache LRUCache@0x7f23881f5e90#1714 capacity: 8.00 MB collections: 1 last_copies: 0 last_secs: 3.6e-05 secs_since: 0
Block cache entry stats(count,size,portion): Misc(1,0.00 KB,0%)

** File Read Latency Histogram By Level [default] **

25/11/26 07:42:57 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:42:57 INFO CodeGenerator: Code generated in 59.005188 ms
25/11/26 07:42:57 INFO DAGScheduler: Registering RDD 6 ($anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63) as input to shuffle 0
25/11/26 07:42:57 INFO DAGScheduler: Got map stage job 0 ($anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63) with 3 output partitions
25/11/26 07:42:57 INFO DAGScheduler: Final stage: ShuffleMapStage 0 ($anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63)
25/11/26 07:42:57 INFO DAGScheduler: Parents of final stage: List()
25/11/26 07:42:57 INFO DAGScheduler: Missing parents: List()
25/11/26 07:42:57 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[6] at $anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63), which has no missing parents
25/11/26 07:42:58 INFO DAGScheduler: Jars for session None: Map()
25/11/26 07:42:58 INFO DAGScheduler: Files for session None: Map()
25/11/26 07:42:58 INFO DAGScheduler: Archives for session None: Map()
25/11/26 07:42:58 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[6] at $anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63) (first 15 tasks are for partitions Vector(0, 1, 2))
25/11/26 07:42:58 INFO TaskSchedulerImpl: Adding task set 0.0 with 3 tasks resource profile 0
25/11/26 07:42:58 WARN FairSchedulableBuilder: A job was submitted with scheduler pool 7779289159481477446, which has not been configured. This can happen when the file that pools are read from isn't set, or when that file doesn't contain 7779289159481477446. Created 7779289159481477446 with default configuration (schedulingMode: FIFO, minShare: 0, weight: 1)
25/11/26 07:42:58 INFO FairSchedulableBuilder: Added task set TaskSet_0.0 tasks to pool 7779289159481477446
25/11/26 07:42:58 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.139.64.4, executor 0, partition 0, NODE_LOCAL, taskResourceAssignments Map())
25/11/26 07:42:58 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (10.139.64.4, executor 0, partition 1, PROCESS_LOCAL, taskResourceAssignments Map())
25/11/26 07:42:58 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2) (10.139.64.4, executor 0, partition 2, PROCESS_LOCAL, taskResourceAssignments Map())
25/11/26 07:42:58 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 294.1 KiB, free 4.4 GiB)
25/11/26 07:42:58 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 86.3 KiB, free 4.4 GiB)
25/11/26 07:42:58 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.139.64.5:43879 (size: 86.3 KiB, free: 4.4 GiB)
25/11/26 07:42:58 INFO SparkContext: Created broadcast 5 from broadcast at TaskSetManager.scala:638
25/11/26 07:42:58 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.139.64.4:38905 (size: 86.3 KiB, free: 4.4 GiB)
25/11/26 07:42:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.139.64.4:38905 (size: 18.5 KiB, free: 4.4 GiB)
25/11/26 07:43:00 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.139.64.4:38905 (size: 19.5 KiB, free: 4.4 GiB)
25/11/26 07:43:00 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:43:00 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2316 ms on 10.139.64.4 (executor 0) (1/3)
25/11/26 07:43:00 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 2317 ms on 10.139.64.4 (executor 0) (2/3)
25/11/26 07:43:03 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:43:06 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:43:09 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 11064 ms on 10.139.64.4 (executor 0) (3/3)
25/11/26 07:43:09 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 7779289159481477446
25/11/26 07:43:09 INFO DAGScheduler: ShuffleMapStage 0 ($anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63) finished in 11.322 s
25/11/26 07:43:09 INFO DAGScheduler: looking for newly runnable stages
25/11/26 07:43:09 INFO DAGScheduler: running: Set()
25/11/26 07:43:09 INFO DAGScheduler: waiting: Set()
25/11/26 07:43:09 INFO DAGScheduler: failed: Set()
25/11/26 07:43:09 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:43:09 INFO CodeGenerator: Code generated in 126.335415 ms
25/11/26 07:43:09 INFO SQLAppStatusListener: Recording cache-related metrics in usage logs:
ioCacheWorkersDiskUsage={"10.139.64.4":{"diskUsage":4007,"lifetime":2542542}}, ioCacheNumScanTasks={"numLocalScanTasks":1,"numNonLocalScanTasks":0}, ioCacheDiskUsageLimit=78696390656
25/11/26 07:43:10 INFO CodeGenerator: Code generated in 50.499943 ms
25/11/26 07:43:10 INFO DAGScheduler: Registering RDD 16 ($anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63) as input to shuffle 1
25/11/26 07:43:10 INFO DAGScheduler: Got map stage job 1 ($anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63) with 1 output partitions
25/11/26 07:43:10 INFO DAGScheduler: Final stage: ShuffleMapStage 2 ($anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63)
25/11/26 07:43:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
25/11/26 07:43:10 INFO DAGScheduler: Missing parents: List()
25/11/26 07:43:10 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at $anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63), which has no missing parents
25/11/26 07:43:10 INFO QueryProfileListener: Query profile sent to logger, seq number: 0, app id: app-20251126070036-0001
25/11/26 07:43:10 INFO DAGScheduler: Jars for session None: Map()
25/11/26 07:43:10 INFO DAGScheduler: Files for session None: Map()
25/11/26 07:43:10 INFO DAGScheduler: Archives for session None: Map()
25/11/26 07:43:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at $anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63) (first 15 tasks are for partitions Vector(0))
25/11/26 07:43:10 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/11/26 07:43:10 INFO FairSchedulableBuilder: Added task set TaskSet_2.0 tasks to pool 7779289159481477446
25/11/26 07:43:10 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 3) (10.139.64.4, executor 0, partition 0, PROCESS_LOCAL, taskResourceAssignments Map())
25/11/26 07:43:10 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 448.4 KiB, free 4.4 GiB)
25/11/26 07:43:10 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 129.5 KiB, free 4.4 GiB)
25/11/26 07:43:10 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.139.64.5:43879 (size: 129.5 KiB, free: 4.4 GiB)
25/11/26 07:43:10 INFO SparkContext: Created broadcast 6 from broadcast at TaskSetManager.scala:638
25/11/26 07:43:10 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.139.64.4:38905 (size: 129.5 KiB, free: 4.4 GiB)
25/11/26 07:43:10 INFO AsyncEventQueue: Process of event SparkListenerQueryProfileParamsReady(executionId=1, ...) by listener QueryProfileListener took 1.276753567s.
25/11/26 07:43:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.139.64.4:46196
25/11/26 07:43:11 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.139.64.4:38905 (size: 12.5 KiB, free: 4.4 GiB)
25/11/26 07:43:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.139.64.4:38905 (size: 14.5 KiB, free: 4.4 GiB)
25/11/26 07:43:11 INFO BlockManagerInfo: Added rdd_13_0 in memory on 10.139.64.4:38905 (size: 1870.0 B, free: 4.4 GiB)
25/11/26 07:43:12 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:43:12 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 3) in 2102 ms on 10.139.64.4 (executor 0) (1/1)
25/11/26 07:43:12 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 7779289159481477446
25/11/26 07:43:12 INFO DAGScheduler: ShuffleMapStage 2 ($anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63) finished in 2.406 s
25/11/26 07:43:12 INFO DAGScheduler: looking for newly runnable stages
25/11/26 07:43:12 INFO DAGScheduler: running: Set()
25/11/26 07:43:12 INFO DAGScheduler: waiting: Set()
25/11/26 07:43:12 INFO DAGScheduler: failed: Set()
25/11/26 07:43:13 INFO SparkContext: Starting job: first at Snapshot.scala:271
25/11/26 07:43:13 INFO DAGScheduler: Got job 2 (first at Snapshot.scala:271) with 1 output partitions
25/11/26 07:43:13 INFO DAGScheduler: Final stage: ResultStage 5 (first at Snapshot.scala:271)
25/11/26 07:43:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/11/26 07:43:13 INFO DAGScheduler: Missing parents: List()
25/11/26 07:43:13 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[18] at first at Snapshot.scala:271), which has no missing parents
25/11/26 07:43:13 INFO DAGScheduler: Jars for session None: Map()
25/11/26 07:43:13 INFO DAGScheduler: Files for session None: Map()
25/11/26 07:43:13 INFO DAGScheduler: Archives for session None: Map()
25/11/26 07:43:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[18] at first at Snapshot.scala:271) (first 15 tasks are for partitions Vector(0))
25/11/26 07:43:13 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/11/26 07:43:13 INFO FairSchedulableBuilder: Added task set TaskSet_5.0 tasks to pool 7779289159481477446
25/11/26 07:43:13 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (10.139.64.4, executor 0, partition 0, PROCESS_LOCAL, taskResourceAssignments Map())
25/11/26 07:43:13 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 393.2 KiB, free 4.4 GiB)
25/11/26 07:43:13 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 119.9 KiB, free 4.4 GiB)
25/11/26 07:43:13 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.139.64.5:43879 (size: 119.9 KiB, free: 4.4 GiB)
25/11/26 07:43:13 INFO SparkContext: Created broadcast 7 from broadcast at TaskSetManager.scala:638
25/11/26 07:43:13 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.139.64.4:38905 (size: 119.9 KiB, free: 4.4 GiB)
25/11/26 07:43:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.139.64.4:46196
25/11/26 07:43:13 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 307 ms on 10.139.64.4 (executor 0) (1/1)
25/11/26 07:43:13 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 7779289159481477446
25/11/26 07:43:13 INFO DAGScheduler: ResultStage 5 (first at Snapshot.scala:271) finished in 0.384 s
25/11/26 07:43:13 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/26 07:43:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/11/26 07:43:13 INFO DAGScheduler: Job 2 finished: first at Snapshot.scala:271, took 0.426908 s
25/11/26 07:43:13 INFO CodeGenerator: Code generated in 49.461084 ms
25/11/26 07:43:13 INFO QueryProfileListener: Query profile sent to logger, seq number: 1, app id: app-20251126070036-0001
25/11/26 07:43:14 INFO ParquetUtils: Using user defined output committer for Parquet: org.apache.spark.sql.parquet.DirectParquetOutputCommitter
25/11/26 07:43:14 INFO CodeGenerator: Code generated in 8.700721 ms
25/11/26 07:43:14 INFO SparkContext: Starting job: write at WriteIntoDeltaCommand.scala:92
25/11/26 07:43:14 INFO DAGScheduler: Got job 3 (write at WriteIntoDeltaCommand.scala:92) with 1 output partitions
25/11/26 07:43:14 INFO DAGScheduler: Final stage: ResultStage 6 (write at WriteIntoDeltaCommand.scala:92)
25/11/26 07:43:14 INFO DAGScheduler: Parents of final stage: List()
25/11/26 07:43:14 INFO DAGScheduler: Missing parents: List()
25/11/26 07:43:14 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[20] at write at WriteIntoDeltaCommand.scala:92), which has no missing parents
25/11/26 07:43:14 INFO DAGScheduler: Jars for session None: Map()
25/11/26 07:43:14 INFO DAGScheduler: Files for session None: Map()
25/11/26 07:43:14 INFO DAGScheduler: Archives for session None: Map()
25/11/26 07:43:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[20] at write at WriteIntoDeltaCommand.scala:92) (first 15 tasks are for partitions Vector(0))
25/11/26 07:43:14 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/11/26 07:43:14 INFO FairSchedulableBuilder: Added task set TaskSet_6.0 tasks to pool 7779289159481477446
25/11/26 07:43:14 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (10.139.64.4, executor 0, partition 0, PROCESS_LOCAL, taskResourceAssignments Map())
25/11/26 07:43:14 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 248.3 KiB, free 4.4 GiB)
25/11/26 07:43:14 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 4.4 GiB)
25/11/26 07:43:14 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.139.64.5:43879 (size: 95.0 KiB, free: 4.4 GiB)
25/11/26 07:43:14 INFO SparkContext: Created broadcast 8 from broadcast at TaskSetManager.scala:638
25/11/26 07:43:14 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.139.64.4:38905 (size: 95.0 KiB, free: 4.4 GiB)
25/11/26 07:43:15 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:43:18 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:43:21 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:43:24 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:43:27 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:43:30 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:43:33 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:43:36 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:43:39 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:43:42 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:43:45 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:43:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:43:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:43:48 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:43:51 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:43:54 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:43:57 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:44:00 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:44:03 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:44:06 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:44:07 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 53648 ms on 10.139.64.4 (executor 0) (1/1)
25/11/26 07:44:07 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 7779289159481477446
25/11/26 07:44:07 INFO DAGScheduler: ResultStage 6 (write at WriteIntoDeltaCommand.scala:92) finished in 53.685 s
25/11/26 07:44:07 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/26 07:44:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/11/26 07:44:07 INFO DAGScheduler: Job 3 finished: write at WriteIntoDeltaCommand.scala:92, took 53.691995 s
25/11/26 07:44:07 INFO FileFormatWriter: Start to commit write Job 61a5c307-1bce-4def-b771-90dec46be4a6.
25/11/26 07:44:07 INFO FileSizeAutoTuner: File size tuning result: {"tuningType":"autoTuned","tunedConfs":{"spark.databricks.delta.optimize.minFileSize":"268435456","spark.databricks.delta.autoCompact.maxFileSize":"16777216","spark.databricks.delta.optimize.maxFileSize":"268435456","spark.databricks.delta.autoCompact.minFileSize":"8388608"}}
25/11/26 07:44:07 INFO FileFormatWriter: Write Job 61a5c307-1bce-4def-b771-90dec46be4a6 committed. Elapsed time: 119 ms.
25/11/26 07:44:07 INFO FileFormatWriter: Finished processing stats for write job 61a5c307-1bce-4def-b771-90dec46be4a6.
25/11/26 07:44:07 INFO SparkContext: Starting job: collect at TransactionalWriteEdge.scala:587
25/11/26 07:44:07 INFO DAGScheduler: Got job 4 (collect at TransactionalWriteEdge.scala:587) with 1 output partitions
25/11/26 07:44:07 INFO DAGScheduler: Final stage: ResultStage 7 (collect at TransactionalWriteEdge.scala:587)
25/11/26 07:44:07 INFO DAGScheduler: Parents of final stage: List()
25/11/26 07:44:07 INFO DAGScheduler: Missing parents: List()
25/11/26 07:44:07 INFO DAGScheduler: Submitting ResultStage 7 (SQLExecutionRDD[22] at toRdd at TransactionalWriteEdge.scala:587), which has no missing parents
25/11/26 07:44:07 INFO DAGScheduler: Jars for session None: Map()
25/11/26 07:44:07 INFO DAGScheduler: Files for session None: Map()
25/11/26 07:44:07 INFO DAGScheduler: Archives for session None: Map()
25/11/26 07:44:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (SQLExecutionRDD[22] at toRdd at TransactionalWriteEdge.scala:587) (first 15 tasks are for partitions Vector(0))
25/11/26 07:44:07 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/11/26 07:44:07 INFO FairSchedulableBuilder: Added task set TaskSet_7.0 tasks to pool 7779289159481477446
25/11/26 07:44:07 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 6) (10.139.64.4, executor 0, partition 0, PROCESS_LOCAL, taskResourceAssignments Map())
25/11/26 07:44:07 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 112.4 KiB, free 4.4 GiB)
25/11/26 07:44:07 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 4.4 GiB)
25/11/26 07:44:07 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.139.64.5:43879 (size: 35.6 KiB, free: 4.4 GiB)
25/11/26 07:44:07 INFO SparkContext: Created broadcast 9 from broadcast at TaskSetManager.scala:638
25/11/26 07:44:07 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.139.64.4:38905 (size: 35.6 KiB, free: 4.4 GiB)
25/11/26 07:44:07 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 6) in 23 ms on 10.139.64.4 (executor 0) (1/1)
25/11/26 07:44:07 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 7779289159481477446
25/11/26 07:44:08 INFO DAGScheduler: ResultStage 7 (collect at TransactionalWriteEdge.scala:587) finished in 0.035 s
25/11/26 07:44:08 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/26 07:44:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/11/26 07:44:08 INFO DAGScheduler: Job 4 finished: collect at TransactionalWriteEdge.scala:587, took 0.045079 s
25/11/26 07:44:08 INFO QueryProfileListener: Query profile sent to logger, seq number: 2, app id: app-20251126070036-0001
25/11/26 07:44:08 INFO OptimisticTransaction: [tableId=62bed5a3,txnId=7b5e1137] Attempting to commit version 12 with 2 actions with WriteSerializable isolation level
25/11/26 07:44:08 INFO AzureBlobFileSystem:V3: FS_OP_CREATE FILE[abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/__tmp_path_dir/.00000000000000000012.json.35c8d062-285b-4836-9919-15caac5df190.tmp] Creating output stream; permission: { masked: rw-r--r--, unmasked: rw-rw-rw- }, overwrite: false, bufferSize: 65536
25/11/26 07:44:08 INFO RetryTolerableRenameFSDataOutputStream: Writing atomically to abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/00000000000000000012.json using temp file abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/__tmp_path_dir/.00000000000000000012.json.35c8d062-285b-4836-9919-15caac5df190.tmp
25/11/26 07:44:08 INFO AbfsOutputStream: FS_OP_CREATE FILE[abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/__tmp_path_dir/.00000000000000000012.json.35c8d062-285b-4836-9919-15caac5df190.tmp] Closing stream; size: 0
25/11/26 07:44:08 INFO AbfsOutputStream: FS_OP_CREATE FILE[abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/__tmp_path_dir/.00000000000000000012.json.35c8d062-285b-4836-9919-15caac5df190.tmp] Upload complete; size: 1519. Sent 3 requests: (1125-113639-ndjs76hq------:6b7d01c3-ba6a-458c-847b-116b43e76226:494bc108-eb93-4de6-b0de-4f2a50735182:::CR:0, 4836107d-f01f-0049-3ca8-5e0138000000), (1125-113639-ndjs76hq------:0d2357bd-67fc-413c-b031-1d65dccf567a:494bc108-eb93-4de6-b0de-4f2a50735182::77377d545d2c:WR:0, 4836107e-f01f-0049-3da8-5e0138000000), (1125-113639-ndjs76hq------:882ff0c9-746a-48fc-8ea8-51aca740c3cc:494bc108-eb93-4de6-b0de-4f2a50735182::77377d545d2c:WR:0, 4836107f-f01f-0049-3ea8-5e0138000000)
25/11/26 07:44:08 INFO AzureBlobFileSystem:V3: FS_OP_RENAME SRC[abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/__tmp_path_dir/.00000000000000000012.json.35c8d062-285b-4836-9919-15caac5df190.tmp] DST[abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/00000000000000000012.json] Starting rename. Issuing rename operation.
25/11/26 07:44:08 INFO AzureBlobFileSystem:V3: FS_OP_RENAME SRC[abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/__tmp_path_dir/.00000000000000000012.json.35c8d062-285b-4836-9919-15caac5df190.tmp] DST[abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/00000000000000000012.json] Rename successful. Sent 1 requests: (1125-113639-ndjs76hq------:63aa72cd-52d9-4930-a648-028f7b0685e7:494bc108-eb93-4de6-b0de-4f2a50735182:8d56f50d-1bb1-4aad-814a-8887e2f4ff6b::RN:0, 48361080-f01f-0049-3fa8-5e0138000000)
25/11/26 07:44:08 INFO RetryTolerableRenameFSDataOutputStream: Renamed temp file abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/__tmp_path_dir/.00000000000000000012.json.35c8d062-285b-4836-9919-15caac5df190.tmp to abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/00000000000000000012.json
25/11/26 07:44:08 INFO OptimisticTransaction: [tableId=62bed5a3,txnId=7b5e1137] Incremental commit: starting with snapshot version 11
25/11/26 07:44:08 INFO DeltaLog: Loading version 12 starting from checkpoint version 10.
25/11/26 07:44:08 INFO SnapshotEdge: [tableId=62bed5a3-0999-4586-90cd-7b6af6e36be7] Created snapshot SnapshotEdge(path=abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log, version=12, metadata=Metadata(62bed5a3-0999-4586-90cd-7b6af6e36be7,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"id","type":"integer","nullable":true,"metadata":{"scale":0}},{"name":"name","type":"string","nullable":true,"metadata":{"scale":0}},{"name":"age","type":"integer","nullable":true,"metadata":{"scale":0}},{"name":"grade","type":"decimal(4,2)","nullable":true,"metadata":{"scale":2}},{"name":"birthday","type":"date","nullable":true,"metadata":{"scale":0}},{"name":"logintime","type":"timestamp","nullable":true,"metadata":{"scale":6}}]},List(),Map(),Some(1764131452056)), logSegment=LogSegment(abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log,12,ArrayBuffer(VersionedFileStatus{VersionedFileStatus{path=abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/00000000000000000011.json; isDirectory=false; length=1518; replication=1; blocksize=268435456; modification_time=1764140376000; access_time=0; owner=b6eba1ca-db96-49f9-b19f-f309bce4121d; group=$superuser; permission=rw-r--r--; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false}; version='0x8DE2CB95C7EAE99'}, VersionedFileStatus{VersionedFileStatus{path=abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/00000000000000000012.json; isDirectory=false; length=1519; replication=1; blocksize=268435456; modification_time=1764143048000; access_time=0; owner=b6eba1ca-db96-49f9-b19f-f309bce4121d; group=root; permission=rw-r--r--; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false}; version='"0x8DE2CBF94F7E975"'}),WrappedArray(VersionedFileStatus{VersionedFileStatus{path=abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/00000000000000000010.checkpoint.parquet; isDirectory=false; length=25741; replication=1; blocksize=268435456; modification_time=1764139674000; access_time=0; owner=b6eba1ca-db96-49f9-b19f-f309bce4121d; group=$superuser; permission=rw-r--r--; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false}; version='0x8DE2CB7B9F4F209'}),Some(10),1764143048000), checksumOpt=Some(VersionChecksum(Some(7b5e1137-7276-49ed-bd9a-e7787dfdc67d),4051719520,10,None,None,1,1,Some(Stream()),None,Metadata(62bed5a3-0999-4586-90cd-7b6af6e36be7,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"id","type":"integer","nullable":true,"metadata":{"scale":0}},{"name":"name","type":"string","nullable":true,"metadata":{"scale":0}},{"name":"age","type":"integer","nullable":true,"metadata":{"scale":0}},{"name":"grade","type":"decimal(4,2)","nullable":true,"metadata":{"scale":2}},{"name":"birthday","type":"date","nullable":true,"metadata":{"scale":0}},{"name":"logintime","type":"timestamp","nullable":true,"metadata":{"scale":6}}]},List(),Map(),Some(1764131452056)),Protocol(1,2),Some(FileSizeHistogram(Vector(0, 8192, 16384, 32768, 65536, 131072, 262144, 524288, 1048576, 2097152, 4194304, 8388608, 12582912, 16777216, 20971520, 25165824, 29360128, 33554432, 37748736, 41943040, 50331648, 58720256, 67108864, 75497472, 83886080, 92274688, 100663296, 109051904, 117440512, 125829120, 130023424, 134217728, 138412032, 142606336, 146800640, 150994944, 167772160, 184549376, 201326592, 218103808, 234881024, 251658240, 268435456, 285212672, 301989888, 318767104, 335544320, 352321536, 369098752, 385875968, 402653184, 419430400, 436207616, 452984832, 469762048, 486539264, 503316480, 520093696, 536870912, 553648128, 570425344, 587202560, 603979776, 671088640, 738197504, 805306368, 872415232, 939524096, 1006632960, 1073741824, 1140850688, 1207959552, 1275068416, 1342177280, 1409286144, 1476395008, 1610612736, 1744830464, 1879048192, 2013265920, 2147483648, 2415919104, 2684354560, 2952790016, 3221225472, 3489660928, 3758096384, 4026531840, 4294967296, 8589934592, 17179869184, 34359738368, 68719476736, 137438953472, 274877906944),[J@3123ca52,[J@7c0fd6a8)),None,Some(Stream(AddFile(part-00000-5e1c2199-b033-4e49-8d2e-d75a95e4871f-c000.snappy.parquet,Map(),405171952,1764135958000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764135958000000, MIN_INSERTION_TIME -> 1764135958000000, MAX_INSERTION_TIME -> 1764135958000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-884d449d-510d-499b-86b0-788d47e58357-c000.snappy.parquet,Map(),405171952,1764136774000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764136774000000, MIN_INSERTION_TIME -> 1764136774000000, MAX_INSERTION_TIME -> 1764136774000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-c07e2cc6-f2ac-44bd-a972-b2db6f803a6e-c000.snappy.parquet,Map(),405171952,1764135057000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764135057000000, MIN_INSERTION_TIME -> 1764135057000000, MAX_INSERTION_TIME -> 1764135057000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-a650ea24-1236-4c21-a4f9-d04923945b4c-c000.snappy.parquet,Map(),405171952,1764140375000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764140375000000, MIN_INSERTION_TIME -> 1764140375000000, MAX_INSERTION_TIME -> 1764140375000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-e5f2304d-bad7-491d-ad4c-0e85916c37a6-c000.snappy.parquet,Map(),405171952,1764137105000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764137105000000, MIN_INSERTION_TIME -> 1764137105000000, MAX_INSERTION_TIME -> 1764137105000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-d4b1d9f7-bbc6-44bb-ad24-55e5dfa1f43d-c000.snappy.parquet,Map(),405171952,1764143047000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764143047000000, MIN_INSERTION_TIME -> 1764143047000000, MAX_INSERTION_TIME -> 1764143047000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-93ed7c89-5969-4fcc-bc14-6c931e8bceaa-c000.snappy.parquet,Map(),405171952,1764139669000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764139669000000, MIN_INSERTION_TIME -> 1764139669000000, MAX_INSERTION_TIME -> 1764139669000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-c15fd30b-8147-4e96-a419-0a7fe6f8953a-c000.snappy.parquet,Map(),405171952,1764136406000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764136406000000, MIN_INSERTION_TIME -> 1764136406000000, MAX_INSERTION_TIME -> 1764136406000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-4a2e5635-bd9b-4892-9e39-c53414c85b07-c000.snappy.parquet,Map(),405171952,1764135429000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764135429000000, MIN_INSERTION_TIME -> 1764135429000000, MAX_INSERTION_TIME -> 1764135429000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-9bcc8d32-27ed-44cf-b137-a1cee0b2926e-c000.snappy.parquet,Map(),405171952,1764137553000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764137553000000, MIN_INSERTION_TIME -> 1764137553000000, MAX_INSERTION_TIME -> 1764137553000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None))))))
25/11/26 07:44:08 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 436.7 KiB, free 4.4 GiB)
25/11/26 07:44:08 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 4.4 GiB)
25/11/26 07:44:08 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.139.64.5:43879 (size: 15.8 KiB, free: 4.4 GiB)
25/11/26 07:44:08 INFO SparkContext: Created broadcast 10 from broadcast at DeltaLog.scala:718
25/11/26 07:44:08 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(Parquet, numFilesInSegment: 1, totalFileSize: 25741)
25/11/26 07:44:08 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 2, totalFileSize: 3037)
25/11/26 07:44:08 INFO CodeGenerator: Code generated in 10.533552 ms
25/11/26 07:44:08 INFO CodeGenerator: Code generated in 21.319507 ms
25/11/26 07:44:08 INFO FileSourceStrategy: Pushed Filters: 
25/11/26 07:44:08 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/26 07:44:08 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 539.6 KiB, free 4.4 GiB)
25/11/26 07:44:08 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 19.5 KiB, free 4.4 GiB)
25/11/26 07:44:08 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.139.64.5:43879 (size: 19.5 KiB, free: 4.4 GiB)
25/11/26 07:44:08 INFO SparkContext: Created broadcast 11 from $anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63
25/11/26 07:44:08 INFO FileSourceScanExec: Planning scan with bin packing, max split size: 134217728 bytes, max partition size: 4194304, open cost is considered as scanning 4194304 bytes.
25/11/26 07:44:08 INFO DAGScheduler: Registering RDD 29 ($anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63) as input to shuffle 2
25/11/26 07:44:08 INFO DAGScheduler: Got map stage job 5 ($anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63) with 5 output partitions
25/11/26 07:44:08 INFO DAGScheduler: Final stage: ShuffleMapStage 8 ($anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63)
25/11/26 07:44:08 INFO DAGScheduler: Parents of final stage: List()
25/11/26 07:44:08 INFO DAGScheduler: Missing parents: List()
25/11/26 07:44:08 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[29] at $anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63), which has no missing parents
25/11/26 07:44:08 INFO DAGScheduler: Jars for session None: Map()
25/11/26 07:44:08 INFO DAGScheduler: Files for session None: Map()
25/11/26 07:44:08 INFO DAGScheduler: Archives for session None: Map()
25/11/26 07:44:08 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[29] at $anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/11/26 07:44:08 INFO TaskSchedulerImpl: Adding task set 8.0 with 5 tasks resource profile 0
25/11/26 07:44:08 INFO FairSchedulableBuilder: Added task set TaskSet_8.0 tasks to pool 7779289159481477446
25/11/26 07:44:08 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 7) (10.139.64.4, executor 0, partition 0, NODE_LOCAL, taskResourceAssignments Map())
25/11/26 07:44:08 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 8) (10.139.64.4, executor 0, partition 1, PROCESS_LOCAL, taskResourceAssignments Map())
25/11/26 07:44:08 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 9) (10.139.64.4, executor 0, partition 2, PROCESS_LOCAL, taskResourceAssignments Map())
25/11/26 07:44:08 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 10) (10.139.64.4, executor 0, partition 3, PROCESS_LOCAL, taskResourceAssignments Map())
25/11/26 07:44:08 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 294.2 KiB, free 4.4 GiB)
25/11/26 07:44:08 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 86.5 KiB, free 4.4 GiB)
25/11/26 07:44:08 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.139.64.5:43879 (size: 86.5 KiB, free: 4.4 GiB)
25/11/26 07:44:08 INFO SparkContext: Created broadcast 12 from broadcast at TaskSetManager.scala:638
25/11/26 07:44:08 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.139.64.4:38905 (size: 86.5 KiB, free: 4.4 GiB)
25/11/26 07:44:09 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 11) (10.139.64.4, executor 0, partition 4, PROCESS_LOCAL, taskResourceAssignments Map())
25/11/26 07:44:09 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 9) in 41 ms on 10.139.64.4 (executor 0) (1/5)
25/11/26 07:44:09 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 10) in 48 ms on 10.139.64.4 (executor 0) (2/5)
25/11/26 07:44:09 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 8) in 50 ms on 10.139.64.4 (executor 0) (3/5)
25/11/26 07:44:09 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.139.64.4:38905 (size: 19.5 KiB, free: 4.4 GiB)
25/11/26 07:44:09 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 11) in 21 ms on 10.139.64.4 (executor 0) (4/5)
25/11/26 07:44:09 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 7) in 137 ms on 10.139.64.4 (executor 0) (5/5)
25/11/26 07:44:09 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 7779289159481477446
25/11/26 07:44:09 INFO DAGScheduler: ShuffleMapStage 8 ($anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63) finished in 0.164 s
25/11/26 07:44:09 INFO DAGScheduler: looking for newly runnable stages
25/11/26 07:44:09 INFO DAGScheduler: running: Set()
25/11/26 07:44:09 INFO DAGScheduler: waiting: Set()
25/11/26 07:44:09 INFO DAGScheduler: failed: Set()
25/11/26 07:44:09 INFO SQLAppStatusListener: Recording cache-related metrics in usage logs:
ioCacheWorkersDiskUsage={"10.139.64.4":{"diskUsage":4007,"lifetime":2602059}}, ioCacheNumScanTasks={"numLocalScanTasks":2,"numNonLocalScanTasks":0}, ioCacheDiskUsageLimit=78696390656
25/11/26 07:44:09 INFO QueryProfileListener: Query profile sent to logger, seq number: 3, app id: app-20251126070036-0001
25/11/26 07:44:09 INFO ClusterLoadAvgHelper: Current cluster load: 1, Old Ema: 1.0, New Ema: 1.0 
25/11/26 07:44:09 INFO CodeGenerator: Code generated in 43.443513 ms
25/11/26 07:44:09 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 8.8 KiB, free 4.4 GiB)
25/11/26 07:44:09 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 4.4 GiB)
25/11/26 07:44:09 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.139.64.5:43879 (size: 4.6 KiB, free: 4.4 GiB)
25/11/26 07:44:09 INFO SparkContext: Created broadcast 13 from $anonfun$executePhase$2 at LexicalThreadLocal.scala:63
25/11/26 07:44:09 INFO CodeGenerator: Code generated in 72.282443 ms
25/11/26 07:44:09 INFO SparkContext: Starting job: collect at Checksum.scala:578
25/11/26 07:44:09 INFO DAGScheduler: Got job 6 (collect at Checksum.scala:578) with 1 output partitions
25/11/26 07:44:09 INFO DAGScheduler: Final stage: ResultStage 10 (collect at Checksum.scala:578)
25/11/26 07:44:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
25/11/26 07:44:09 INFO DAGScheduler: Missing parents: List()
25/11/26 07:44:09 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[40] at collect at Checksum.scala:578), which has no missing parents
25/11/26 07:44:09 INFO DAGScheduler: Jars for session None: Map()
25/11/26 07:44:09 INFO DAGScheduler: Files for session None: Map()
25/11/26 07:44:09 INFO DAGScheduler: Archives for session None: Map()
25/11/26 07:44:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[40] at collect at Checksum.scala:578) (first 15 tasks are for partitions Vector(0))
25/11/26 07:44:09 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
25/11/26 07:44:09 INFO FairSchedulableBuilder: Added task set TaskSet_10.0 tasks to pool 7779289159481477446
25/11/26 07:44:09 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 12) (10.139.64.4, executor 0, partition 0, PROCESS_LOCAL, taskResourceAssignments Map())
25/11/26 07:44:09 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 477.4 KiB, free 4.4 GiB)
25/11/26 07:44:09 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 134.8 KiB, free 4.4 GiB)
25/11/26 07:44:09 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.139.64.5:43879 (size: 134.8 KiB, free: 4.4 GiB)
25/11/26 07:44:09 INFO SparkContext: Created broadcast 14 from broadcast at TaskSetManager.scala:638
25/11/26 07:44:09 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.139.64.4:38905 (size: 134.8 KiB, free: 4.4 GiB)
25/11/26 07:44:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.139.64.4:46196
25/11/26 07:44:10 INFO BlockManagerInfo: Added rdd_36_0 in memory on 10.139.64.4:38905 (size: 1950.0 B, free: 4.4 GiB)
25/11/26 07:44:10 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.139.64.4:38905 (size: 4.6 KiB, free: 4.4 GiB)
25/11/26 07:44:10 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 12) in 352 ms on 10.139.64.4 (executor 0) (1/1)
25/11/26 07:44:10 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 7779289159481477446
25/11/26 07:44:10 INFO DAGScheduler: ResultStage 10 (collect at Checksum.scala:578) finished in 0.560 s
25/11/26 07:44:10 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/26 07:44:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
25/11/26 07:44:10 INFO DAGScheduler: Job 6 finished: collect at Checksum.scala:578, took 0.578632 s
25/11/26 07:44:10 INFO CodeGenerator: Code generated in 27.380305 ms
25/11/26 07:44:10 INFO QueryProfileListener: Query profile sent to logger, seq number: 4, app id: app-20251126070036-0001
25/11/26 07:44:10 INFO DAGScheduler: Registering RDD 43 ($anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63) as input to shuffle 3
25/11/26 07:44:10 INFO DAGScheduler: Got map stage job 7 ($anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63) with 1 output partitions
25/11/26 07:44:10 INFO DAGScheduler: Final stage: ShuffleMapStage 12 ($anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63)
25/11/26 07:44:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
25/11/26 07:44:10 INFO DAGScheduler: Missing parents: List()
25/11/26 07:44:10 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[43] at $anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63), which has no missing parents
25/11/26 07:44:10 INFO DAGScheduler: Jars for session None: Map()
25/11/26 07:44:10 INFO DAGScheduler: Files for session None: Map()
25/11/26 07:44:10 INFO DAGScheduler: Archives for session None: Map()
25/11/26 07:44:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[43] at $anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63) (first 15 tasks are for partitions Vector(0))
25/11/26 07:44:10 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
25/11/26 07:44:10 INFO FairSchedulableBuilder: Added task set TaskSet_12.0 tasks to pool 7779289159481477446
25/11/26 07:44:10 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 13) (10.139.64.4, executor 0, partition 0, PROCESS_LOCAL, taskResourceAssignments Map())
25/11/26 07:44:10 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 448.4 KiB, free 4.4 GiB)
25/11/26 07:44:10 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 129.6 KiB, free 4.4 GiB)
25/11/26 07:44:10 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.139.64.5:43879 (size: 129.6 KiB, free: 4.4 GiB)
25/11/26 07:44:10 INFO SparkContext: Created broadcast 15 from broadcast at TaskSetManager.scala:638
25/11/26 07:44:10 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.139.64.4:38905 (size: 129.6 KiB, free: 4.4 GiB)
25/11/26 07:44:10 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 13) in 78 ms on 10.139.64.4 (executor 0) (1/1)
25/11/26 07:44:10 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 7779289159481477446
25/11/26 07:44:10 INFO DAGScheduler: ShuffleMapStage 12 ($anonfun$withThreadLocalCaptured$5 at LexicalThreadLocal.scala:63) finished in 0.127 s
25/11/26 07:44:10 INFO DAGScheduler: looking for newly runnable stages
25/11/26 07:44:10 INFO DAGScheduler: running: Set()
25/11/26 07:44:10 INFO DAGScheduler: waiting: Set()
25/11/26 07:44:10 INFO DAGScheduler: failed: Set()
25/11/26 07:44:10 INFO SparkContext: Starting job: first at Snapshot.scala:271
25/11/26 07:44:10 INFO DAGScheduler: Got job 8 (first at Snapshot.scala:271) with 1 output partitions
25/11/26 07:44:10 INFO DAGScheduler: Final stage: ResultStage 15 (first at Snapshot.scala:271)
25/11/26 07:44:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
25/11/26 07:44:10 INFO DAGScheduler: Missing parents: List()
25/11/26 07:44:10 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[45] at first at Snapshot.scala:271), which has no missing parents
25/11/26 07:44:10 INFO DAGScheduler: Jars for session None: Map()
25/11/26 07:44:10 INFO DAGScheduler: Files for session None: Map()
25/11/26 07:44:10 INFO DAGScheduler: Archives for session None: Map()
25/11/26 07:44:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[45] at first at Snapshot.scala:271) (first 15 tasks are for partitions Vector(0))
25/11/26 07:44:10 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
25/11/26 07:44:10 INFO FairSchedulableBuilder: Added task set TaskSet_15.0 tasks to pool 7779289159481477446
25/11/26 07:44:10 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 14) (10.139.64.4, executor 0, partition 0, PROCESS_LOCAL, taskResourceAssignments Map())
25/11/26 07:44:10 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 393.3 KiB, free 4.4 GiB)
25/11/26 07:44:10 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 120.4 KiB, free 4.4 GiB)
25/11/26 07:44:10 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.139.64.5:43879 (size: 120.4 KiB, free: 4.4 GiB)
25/11/26 07:44:10 INFO SparkContext: Created broadcast 16 from broadcast at TaskSetManager.scala:638
25/11/26 07:44:10 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.139.64.4:38905 (size: 120.4 KiB, free: 4.4 GiB)
25/11/26 07:44:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 10.139.64.4:46196
25/11/26 07:44:10 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 14) in 83 ms on 10.139.64.4 (executor 0) (1/1)
25/11/26 07:44:10 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 7779289159481477446
25/11/26 07:44:10 INFO DAGScheduler: ResultStage 15 (first at Snapshot.scala:271) finished in 0.139 s
25/11/26 07:44:10 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/26 07:44:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
25/11/26 07:44:10 INFO DAGScheduler: Job 8 finished: first at Snapshot.scala:271, took 0.145730 s
25/11/26 07:44:10 INFO DeltaLog: Updated snapshot to SnapshotEdge(path=abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log, version=12, metadata=Metadata(62bed5a3-0999-4586-90cd-7b6af6e36be7,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"id","type":"integer","nullable":true,"metadata":{"scale":0}},{"name":"name","type":"string","nullable":true,"metadata":{"scale":0}},{"name":"age","type":"integer","nullable":true,"metadata":{"scale":0}},{"name":"grade","type":"decimal(4,2)","nullable":true,"metadata":{"scale":2}},{"name":"birthday","type":"date","nullable":true,"metadata":{"scale":0}},{"name":"logintime","type":"timestamp","nullable":true,"metadata":{"scale":6}}]},List(),Map(),Some(1764131452056)), logSegment=LogSegment(abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log,12,ArrayBuffer(VersionedFileStatus{VersionedFileStatus{path=abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/00000000000000000011.json; isDirectory=false; length=1518; replication=1; blocksize=268435456; modification_time=1764140376000; access_time=0; owner=b6eba1ca-db96-49f9-b19f-f309bce4121d; group=$superuser; permission=rw-r--r--; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false}; version='0x8DE2CB95C7EAE99'}, VersionedFileStatus{VersionedFileStatus{path=abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/00000000000000000012.json; isDirectory=false; length=1519; replication=1; blocksize=268435456; modification_time=1764143048000; access_time=0; owner=b6eba1ca-db96-49f9-b19f-f309bce4121d; group=root; permission=rw-r--r--; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false}; version='"0x8DE2CBF94F7E975"'}),WrappedArray(VersionedFileStatus{VersionedFileStatus{path=abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/00000000000000000010.checkpoint.parquet; isDirectory=false; length=25741; replication=1; blocksize=268435456; modification_time=1764139674000; access_time=0; owner=b6eba1ca-db96-49f9-b19f-f309bce4121d; group=$superuser; permission=rw-r--r--; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false}; version='0x8DE2CB7B9F4F209'}),Some(10),1764143048000), checksumOpt=Some(VersionChecksum(Some(7b5e1137-7276-49ed-bd9a-e7787dfdc67d),4051719520,10,None,None,1,1,Some(Stream()),None,Metadata(62bed5a3-0999-4586-90cd-7b6af6e36be7,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"id","type":"integer","nullable":true,"metadata":{"scale":0}},{"name":"name","type":"string","nullable":true,"metadata":{"scale":0}},{"name":"age","type":"integer","nullable":true,"metadata":{"scale":0}},{"name":"grade","type":"decimal(4,2)","nullable":true,"metadata":{"scale":2}},{"name":"birthday","type":"date","nullable":true,"metadata":{"scale":0}},{"name":"logintime","type":"timestamp","nullable":true,"metadata":{"scale":6}}]},List(),Map(),Some(1764131452056)),Protocol(1,2),Some(FileSizeHistogram(Vector(0, 8192, 16384, 32768, 65536, 131072, 262144, 524288, 1048576, 2097152, 4194304, 8388608, 12582912, 16777216, 20971520, 25165824, 29360128, 33554432, 37748736, 41943040, 50331648, 58720256, 67108864, 75497472, 83886080, 92274688, 100663296, 109051904, 117440512, 125829120, 130023424, 134217728, 138412032, 142606336, 146800640, 150994944, 167772160, 184549376, 201326592, 218103808, 234881024, 251658240, 268435456, 285212672, 301989888, 318767104, 335544320, 352321536, 369098752, 385875968, 402653184, 419430400, 436207616, 452984832, 469762048, 486539264, 503316480, 520093696, 536870912, 553648128, 570425344, 587202560, 603979776, 671088640, 738197504, 805306368, 872415232, 939524096, 1006632960, 1073741824, 1140850688, 1207959552, 1275068416, 1342177280, 1409286144, 1476395008, 1610612736, 1744830464, 1879048192, 2013265920, 2147483648, 2415919104, 2684354560, 2952790016, 3221225472, 3489660928, 3758096384, 4026531840, 4294967296, 8589934592, 17179869184, 34359738368, 68719476736, 137438953472, 274877906944),[J@3123ca52,[J@7c0fd6a8)),None,Some(Stream(AddFile(part-00000-5e1c2199-b033-4e49-8d2e-d75a95e4871f-c000.snappy.parquet,Map(),405171952,1764135958000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764135958000000, MIN_INSERTION_TIME -> 1764135958000000, MAX_INSERTION_TIME -> 1764135958000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-884d449d-510d-499b-86b0-788d47e58357-c000.snappy.parquet,Map(),405171952,1764136774000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764136774000000, MIN_INSERTION_TIME -> 1764136774000000, MAX_INSERTION_TIME -> 1764136774000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-c07e2cc6-f2ac-44bd-a972-b2db6f803a6e-c000.snappy.parquet,Map(),405171952,1764135057000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764135057000000, MIN_INSERTION_TIME -> 1764135057000000, MAX_INSERTION_TIME -> 1764135057000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-a650ea24-1236-4c21-a4f9-d04923945b4c-c000.snappy.parquet,Map(),405171952,1764140375000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764140375000000, MIN_INSERTION_TIME -> 1764140375000000, MAX_INSERTION_TIME -> 1764140375000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-e5f2304d-bad7-491d-ad4c-0e85916c37a6-c000.snappy.parquet,Map(),405171952,1764137105000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764137105000000, MIN_INSERTION_TIME -> 1764137105000000, MAX_INSERTION_TIME -> 1764137105000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-d4b1d9f7-bbc6-44bb-ad24-55e5dfa1f43d-c000.snappy.parquet,Map(),405171952,1764143047000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764143047000000, MIN_INSERTION_TIME -> 1764143047000000, MAX_INSERTION_TIME -> 1764143047000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-93ed7c89-5969-4fcc-bc14-6c931e8bceaa-c000.snappy.parquet,Map(),405171952,1764139669000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764139669000000, MIN_INSERTION_TIME -> 1764139669000000, MAX_INSERTION_TIME -> 1764139669000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-c15fd30b-8147-4e96-a419-0a7fe6f8953a-c000.snappy.parquet,Map(),405171952,1764136406000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764136406000000, MIN_INSERTION_TIME -> 1764136406000000, MAX_INSERTION_TIME -> 1764136406000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-4a2e5635-bd9b-4892-9e39-c53414c85b07-c000.snappy.parquet,Map(),405171952,1764135429000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764135429000000, MIN_INSERTION_TIME -> 1764135429000000, MAX_INSERTION_TIME -> 1764135429000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None), AddFile(part-00000-9bcc8d32-27ed-44cf-b137-a1cee0b2926e-c000.snappy.parquet,Map(),405171952,1764137553000,false,{"numRecords":10000473,"minValues":{"id":1,"name":"0000012a96324ac00214c0d142e80c73","age":0,"grade":0.00,"birthday":"2019-02-11","logintime":"2021-11-07T12:22:09.626Z"},"maxValues":{"id":10000370,"name":"ffffff6bb2702654c32939c89b135071","age":100,"grade":99.00,"birthday":"2022-01-18","logintime":"2022-01-20T16:07:50.220Z"},"nullCount":{"id":0,"name":0,"age":0,"grade":0,"birthday":0,"logintime":0}},Map(INSERTION_TIME -> 1764137553000000, MIN_INSERTION_TIME -> 1764137553000000, MAX_INSERTION_TIME -> 1764137553000000, OPTIMIZE_TARGET_SIZE -> 268435456),null,None))))))
25/11/26 07:44:10 INFO MapPartitionsRDD: Removing RDD 13 from persistence list
25/11/26 07:44:10 INFO QueryProfileListener: Query profile sent to logger, seq number: 5, app id: app-20251126070036-0001
25/11/26 07:44:10 INFO BlockManager: Removing RDD 13
25/11/26 07:44:10 INFO FileSizeAutoTuner: File size tuning result: {"tuningType":"autoTuned","tunedConfs":{"spark.databricks.delta.optimize.minFileSize":"268435456","spark.databricks.delta.autoCompact.maxFileSize":"16777216","spark.databricks.delta.optimize.maxFileSize":"268435456","spark.databricks.delta.autoCompact.minFileSize":"8388608"}}
25/11/26 07:44:10 INFO OptimisticTransaction: [tableId=62bed5a3,txnId=7b5e1137] Committed delta #12 to abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log
25/11/26 07:44:10 INFO ChecksumHook: Writing checksum file for table path abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log version 12
25/11/26 07:44:10 INFO AzureBlobFileSystem:V3: FS_OP_CREATE FILE[abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/__tmp_path_dir/.00000000000000000012.crc.f51fef36-c40c-4162-9abf-d15e51469bce.tmp] Creating output stream; permission: { masked: rw-r--r--, unmasked: rw-rw-rw- }, overwrite: false, bufferSize: 65536
25/11/26 07:44:10 INFO RetryTolerableRenameFSDataOutputStream: Writing atomically to abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/00000000000000000012.crc using temp file abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/__tmp_path_dir/.00000000000000000012.crc.f51fef36-c40c-4162-9abf-d15e51469bce.tmp
25/11/26 07:44:10 INFO AbfsOutputStream: FS_OP_CREATE FILE[abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/__tmp_path_dir/.00000000000000000012.crc.f51fef36-c40c-4162-9abf-d15e51469bce.tmp] Closing stream; size: 0
25/11/26 07:44:10 INFO AbfsOutputStream: FS_OP_CREATE FILE[abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/__tmp_path_dir/.00000000000000000012.crc.f51fef36-c40c-4162-9abf-d15e51469bce.tmp] Upload complete; size: 10330. Sent 3 requests: (1125-113639-ndjs76hq------:8da5675d-a539-4eca-8adc-695c5d4f6b0b:494bc108-eb93-4de6-b0de-4f2a50735182:::CR:0, e6eb2a9f-b01f-003a-5ba8-5e59ab000000), (1125-113639-ndjs76hq------:610f1df7-d038-4546-af06-edb665ac4757:494bc108-eb93-4de6-b0de-4f2a50735182::e522a5cd0d8b:WR:0, e6eb2aa0-b01f-003a-5ca8-5e59ab000000), (1125-113639-ndjs76hq------:d26cd246-7e77-4a52-8218-c711c6f6e937:494bc108-eb93-4de6-b0de-4f2a50735182::e522a5cd0d8b:WR:0, e6eb2aa1-b01f-003a-5da8-5e59ab000000)
25/11/26 07:44:10 INFO AzureBlobFileSystem:V3: FS_OP_RENAME SRC[abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/__tmp_path_dir/.00000000000000000012.crc.f51fef36-c40c-4162-9abf-d15e51469bce.tmp] DST[abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/00000000000000000012.crc] Starting rename. Issuing rename operation.
25/11/26 07:44:10 INFO AzureBlobFileSystem:V3: FS_OP_RENAME SRC[abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/__tmp_path_dir/.00000000000000000012.crc.f51fef36-c40c-4162-9abf-d15e51469bce.tmp] DST[abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/00000000000000000012.crc] Rename successful. Sent 1 requests: (1125-113639-ndjs76hq------:2d7661b0-694c-4701-880e-effbdad7fbc3:494bc108-eb93-4de6-b0de-4f2a50735182:bb042f09-53ab-47db-b69b-72a8894cefe6::RN:0, e6eb2aa2-b01f-003a-5ea8-5e59ab000000)
25/11/26 07:44:10 INFO RetryTolerableRenameFSDataOutputStream: Renamed temp file abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/__tmp_path_dir/.00000000000000000012.crc.f51fef36-c40c-4162-9abf-d15e51469bce.tmp to abfss://uctarhone@tarhonemetastore.dfs.core.chinacloudapi.cn/tarhoneroot1/bronze/test/vwtable1/_delta_log/00000000000000000012.crc
25/11/26 07:44:11 INFO ClusterLoadMonitor: Removed query with execution ID:0. Current active queries:0
25/11/26 07:44:11 INFO QueryProfileListener: Query profile sent to logger, seq number: 6, app id: app-20251126070036-0001
25/11/26 07:44:11 INFO SparkContext: SparkContext is stopping from stop at NativeMethodAccessorImpl.java:0.
25/11/26 07:44:11 INFO HiveServer2: Shutting down HiveServer2
25/11/26 07:44:11 INFO ThriftCLIService: Caught InterruptedException. Shutting down thrift server.
25/11/26 07:44:11 INFO AbstractConnector: Stopped ServerConnector@71b2a743{SSL, (ssl, http/1.1)}{0.0.0.0:10000}
25/11/26 07:44:11 INFO session: node0 Stopped scavenging
25/11/26 07:44:11 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@466b5ed5{/,null,STOPPED}
25/11/26 07:44:11 INFO AbstractConnector: Stopped Spark@71ea9a0d{HTTP/1.1, (http/1.1)}{10.139.64.5:40001}
25/11/26 07:44:11 INFO ThriftCLIService: Thrift HTTP server has been stopped
25/11/26 07:44:11 INFO AbstractService: Service:ThriftHttpCLIService is stopped.
25/11/26 07:44:11 INFO AbstractService: Service:OperationManager is stopped.
25/11/26 07:44:11 INFO AbstractService: Service:SessionManager is stopped.
25/11/26 07:44:11 INFO AbstractService: Service:CLIService is stopped.
25/11/26 07:44:11 INFO AbstractService: Service:HiveServer2 is stopped.
25/11/26 07:44:11 INFO SparkUI: Stopped Spark web UI at http://10.139.64.5:40001
25/11/26 07:44:11 INFO StandaloneSchedulerBackend: Shutting down all executors
25/11/26 07:44:11 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
25/11/26 07:44:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/11/26 07:44:11 INFO MemoryStore: MemoryStore cleared
25/11/26 07:44:11 INFO BlockManager: BlockManager stopped
25/11/26 07:44:11 INFO BlockManagerMaster: BlockManagerMaster stopped
25/11/26 07:44:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/11/26 07:44:11 INFO SparkContext: Successfully stopped SparkContext
25/11/26 07:44:12 INFO ClusterLoadAvgHelper: Current cluster load: 0, Old Ema: 1.0, New Ema: 0.85 
25/11/26 07:44:15 INFO ClusterLoadAvgHelper: Current cluster load: 0, Old Ema: 0.85, New Ema: 0.0 
25/11/26 07:44:15 WARN DriverDaemon: Unexpected exception: java.lang.NullPointerException
java.lang.NullPointerException
	at org.apache.spark.sql.internal.SharedState.getSchedulerStats(SharedState.scala:416)
	at org.apache.spark.sql.SQLContext.getSchedulerStats(SQLContext.scala:768)
	at com.databricks.backend.daemon.driver.DriverCorral$.getAutoscalingInfo(DriverCorral.scala:1712)
	at com.databricks.backend.daemon.driver.DriverCorral.com$databricks$backend$daemon$driver$DriverCorral$$handleRPCRequest(DriverCorral.scala:1079)
	at com.databricks.backend.daemon.driver.DriverCorral$$anonfun$receive$1.applyOrElse(DriverCorral.scala:1128)
	at com.databricks.backend.daemon.driver.DriverCorral$$anonfun$receive$1.applyOrElse(DriverCorral.scala:1126)
	at com.databricks.rpc.ServerBackend.$anonfun$internalReceive$2(ServerBackend.scala:119)
	at com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)
	at com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)
	at com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:116)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:657)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:678)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)
	at com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:652)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:569)
	at com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:528)
	at com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:24)
	at com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:115)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleRPC$2(JettyServer.scala:958)
	at scala.util.Try$.apply(Try.scala:213)
	at com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:958)
	at com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:874)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2(JettyServer.scala:503)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2$adapted(JettyServer.scala:478)
	at com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:387)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:53)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)
	at com.databricks.logging.activity.ActivityContextFactory$.withAttributionTags(ActivityContextFactory.scala:53)
	at com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:381)
	at com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:164)
	at com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:478)
	at com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:375)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:523)
	at com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:550)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:80)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.lang.Thread.run(Thread.java:750)
25/11/26 07:44:20 WARN DriverDaemon: Unexpected exception: java.lang.NullPointerException
java.lang.NullPointerException
	at org.apache.spark.sql.internal.SharedState.getSchedulerStats(SharedState.scala:416)
	at org.apache.spark.sql.SQLContext.getSchedulerStats(SQLContext.scala:768)
	at com.databricks.backend.daemon.driver.DriverCorral$.getAutoscalingInfo(DriverCorral.scala:1712)
	at com.databricks.backend.daemon.driver.DriverCorral.com$databricks$backend$daemon$driver$DriverCorral$$handleRPCRequest(DriverCorral.scala:1079)
	at com.databricks.backend.daemon.driver.DriverCorral$$anonfun$receive$1.applyOrElse(DriverCorral.scala:1128)
	at com.databricks.backend.daemon.driver.DriverCorral$$anonfun$receive$1.applyOrElse(DriverCorral.scala:1126)
	at com.databricks.rpc.ServerBackend.$anonfun$internalReceive$2(ServerBackend.scala:119)
	at com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)
	at com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)
	at com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:116)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:657)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:678)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)
	at com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:652)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:569)
	at com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:528)
	at com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:24)
	at com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:115)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleRPC$2(JettyServer.scala:958)
	at scala.util.Try$.apply(Try.scala:213)
	at com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:958)
	at com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:874)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2(JettyServer.scala:503)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2$adapted(JettyServer.scala:478)
	at com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:387)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:53)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)
	at com.databricks.logging.activity.ActivityContextFactory$.withAttributionTags(ActivityContextFactory.scala:53)
	at com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:381)
	at com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:164)
	at com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:478)
	at com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:375)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:523)
	at com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:550)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:80)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.lang.Thread.run(Thread.java:750)
25/11/26 07:44:25 WARN DriverDaemon: Unexpected exception: java.lang.NullPointerException
java.lang.NullPointerException
	at org.apache.spark.sql.internal.SharedState.getSchedulerStats(SharedState.scala:416)
	at org.apache.spark.sql.SQLContext.getSchedulerStats(SQLContext.scala:768)
	at com.databricks.backend.daemon.driver.DriverCorral$.getAutoscalingInfo(DriverCorral.scala:1712)
	at com.databricks.backend.daemon.driver.DriverCorral.com$databricks$backend$daemon$driver$DriverCorral$$handleRPCRequest(DriverCorral.scala:1079)
	at com.databricks.backend.daemon.driver.DriverCorral$$anonfun$receive$1.applyOrElse(DriverCorral.scala:1128)
	at com.databricks.backend.daemon.driver.DriverCorral$$anonfun$receive$1.applyOrElse(DriverCorral.scala:1126)
	at com.databricks.rpc.ServerBackend.$anonfun$internalReceive$2(ServerBackend.scala:119)
	at com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)
	at com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)
	at com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:116)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:657)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:678)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)
	at com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:652)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:569)
	at com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:528)
	at com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:24)
	at com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:115)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleRPC$2(JettyServer.scala:958)
	at scala.util.Try$.apply(Try.scala:213)
	at com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:958)
	at com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:874)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2(JettyServer.scala:503)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2$adapted(JettyServer.scala:478)
	at com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:387)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:53)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)
	at com.databricks.logging.activity.ActivityContextFactory$.withAttributionTags(ActivityContextFactory.scala:53)
	at com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:381)
	at com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:164)
	at com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:478)
	at com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:375)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:523)
	at com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:550)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:80)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.lang.Thread.run(Thread.java:750)
25/11/26 07:44:30 WARN DriverDaemon: Unexpected exception: java.lang.NullPointerException
java.lang.NullPointerException
	at org.apache.spark.sql.internal.SharedState.getSchedulerStats(SharedState.scala:416)
	at org.apache.spark.sql.SQLContext.getSchedulerStats(SQLContext.scala:768)
	at com.databricks.backend.daemon.driver.DriverCorral$.getAutoscalingInfo(DriverCorral.scala:1712)
	at com.databricks.backend.daemon.driver.DriverCorral.com$databricks$backend$daemon$driver$DriverCorral$$handleRPCRequest(DriverCorral.scala:1079)
	at com.databricks.backend.daemon.driver.DriverCorral$$anonfun$receive$1.applyOrElse(DriverCorral.scala:1128)
	at com.databricks.backend.daemon.driver.DriverCorral$$anonfun$receive$1.applyOrElse(DriverCorral.scala:1126)
	at com.databricks.rpc.ServerBackend.$anonfun$internalReceive$2(ServerBackend.scala:119)
	at com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)
	at com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)
	at com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:116)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:657)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:678)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)
	at com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:652)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:569)
	at com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:528)
	at com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:24)
	at com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:115)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleRPC$2(JettyServer.scala:958)
	at scala.util.Try$.apply(Try.scala:213)
	at com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:958)
	at com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:874)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2(JettyServer.scala:503)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2$adapted(JettyServer.scala:478)
	at com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:387)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:53)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)
	at com.databricks.logging.activity.ActivityContextFactory$.withAttributionTags(ActivityContextFactory.scala:53)
	at com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:381)
	at com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:164)
	at com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:478)
	at com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:375)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:523)
	at com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:550)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:80)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.lang.Thread.run(Thread.java:750)
25/11/26 07:44:35 WARN DriverDaemon: Unexpected exception: java.lang.NullPointerException
java.lang.NullPointerException
	at org.apache.spark.sql.internal.SharedState.getSchedulerStats(SharedState.scala:416)
	at org.apache.spark.sql.SQLContext.getSchedulerStats(SQLContext.scala:768)
	at com.databricks.backend.daemon.driver.DriverCorral$.getAutoscalingInfo(DriverCorral.scala:1712)
	at com.databricks.backend.daemon.driver.DriverCorral.com$databricks$backend$daemon$driver$DriverCorral$$handleRPCRequest(DriverCorral.scala:1079)
	at com.databricks.backend.daemon.driver.DriverCorral$$anonfun$receive$1.applyOrElse(DriverCorral.scala:1128)
	at com.databricks.backend.daemon.driver.DriverCorral$$anonfun$receive$1.applyOrElse(DriverCorral.scala:1126)
	at com.databricks.rpc.ServerBackend.$anonfun$internalReceive$2(ServerBackend.scala:119)
	at com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)
	at com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)
	at com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:116)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:657)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:678)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)
	at com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:652)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:569)
	at com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:528)
	at com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:24)
	at com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:115)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleRPC$2(JettyServer.scala:958)
	at scala.util.Try$.apply(Try.scala:213)
	at com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:958)
	at com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:874)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2(JettyServer.scala:503)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2$adapted(JettyServer.scala:478)
	at com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:387)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:53)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)
	at com.databricks.logging.activity.ActivityContextFactory$.withAttributionTags(ActivityContextFactory.scala:53)
	at com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:381)
	at com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:164)
	at com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:478)
	at com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:375)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:523)
	at com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:550)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:80)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.lang.Thread.run(Thread.java:750)
25/11/26 07:44:40 WARN DriverDaemon: Unexpected exception: java.lang.NullPointerException
java.lang.NullPointerException
	at org.apache.spark.sql.internal.SharedState.getSchedulerStats(SharedState.scala:416)
	at org.apache.spark.sql.SQLContext.getSchedulerStats(SQLContext.scala:768)
	at com.databricks.backend.daemon.driver.DriverCorral$.getAutoscalingInfo(DriverCorral.scala:1712)
	at com.databricks.backend.daemon.driver.DriverCorral.com$databricks$backend$daemon$driver$DriverCorral$$handleRPCRequest(DriverCorral.scala:1079)
	at com.databricks.backend.daemon.driver.DriverCorral$$anonfun$receive$1.applyOrElse(DriverCorral.scala:1128)
	at com.databricks.backend.daemon.driver.DriverCorral$$anonfun$receive$1.applyOrElse(DriverCorral.scala:1126)
	at com.databricks.rpc.ServerBackend.$anonfun$internalReceive$2(ServerBackend.scala:119)
	at com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)
	at com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)
	at com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:116)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:657)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:678)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)
	at com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:652)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:569)
	at com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:528)
	at com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:24)
	at com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:115)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleRPC$2(JettyServer.scala:958)
	at scala.util.Try$.apply(Try.scala:213)
	at com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:958)
	at com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:874)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2(JettyServer.scala:503)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2$adapted(JettyServer.scala:478)
	at com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:387)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:53)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)
	at com.databricks.logging.activity.ActivityContextFactory$.withAttributionTags(ActivityContextFactory.scala:53)
	at com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:381)
	at com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:164)
	at com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:478)
	at com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:375)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:523)
	at com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:550)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:80)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.lang.Thread.run(Thread.java:750)
25/11/26 07:44:42 INFO ProgressReporter$: Removed result fetcher for 7779289159481477446_6431207694236545823_job-1062320909976339-run-1087956387186349-action-643456424335716
25/11/26 07:44:42 WARN PythonDriverWrapper: Spark is detected to be down after running a command
25/11/26 07:44:42 WARN PythonDriverWrapper: Fatal exception (spark down) in ReplId-6bf59-6462b-f0c94-6
com.databricks.backend.common.rpc.SparkStoppedException: Spark down: 
	at com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:636)
	at com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:663)
	at com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$runInnerLoop$1(DriverWrapper.scala:503)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:70)
	at com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:503)
	at com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:438)
	at com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:262)
	at java.lang.Thread.run(Thread.java:750)
25/11/26 07:44:42 INFO PythonDriverLocalBase$RedirectThread: Python RedirectThread exit
25/11/26 07:44:42 INFO PythonDriverLocalBase$RedirectThread: Python RedirectThread exit
25/11/26 07:44:42 INFO ReplCrashUtils$: python shell exit code: 143
25/11/26 07:44:42 INFO ReplCrashUtils$: strace is not enabled. To turn it on, set the Spark conf `spark.databricks.driver.strace.enabled` to true.
25/11/26 07:44:44 INFO DrainingState: Started draining: min wait 10000, grace period 5000, max wait 15000.
25/11/26 07:44:45 WARN DriverDaemon: Unexpected exception: java.lang.NullPointerException
java.lang.NullPointerException
	at org.apache.spark.sql.internal.SharedState.getSchedulerStats(SharedState.scala:416)
	at org.apache.spark.sql.SQLContext.getSchedulerStats(SQLContext.scala:768)
	at com.databricks.backend.daemon.driver.DriverCorral$.getAutoscalingInfo(DriverCorral.scala:1712)
	at com.databricks.backend.daemon.driver.DriverCorral.com$databricks$backend$daemon$driver$DriverCorral$$handleRPCRequest(DriverCorral.scala:1079)
	at com.databricks.backend.daemon.driver.DriverCorral$$anonfun$receive$1.applyOrElse(DriverCorral.scala:1128)
	at com.databricks.backend.daemon.driver.DriverCorral$$anonfun$receive$1.applyOrElse(DriverCorral.scala:1126)
	at com.databricks.rpc.ServerBackend.$anonfun$internalReceive$2(ServerBackend.scala:119)
	at com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)
	at com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)
	at com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:116)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:657)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:678)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)
	at com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:652)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:569)
	at com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:24)
	at com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:528)
	at com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:24)
	at com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:115)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleRPC$2(JettyServer.scala:958)
	at scala.util.Try$.apply(Try.scala:213)
	at com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:958)
	at com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:874)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2(JettyServer.scala:503)
	at com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2$adapted(JettyServer.scala:478)
	at com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:387)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:53)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)
	at com.databricks.logging.activity.ActivityContextFactory$.withAttributionTags(ActivityContextFactory.scala:53)
	at com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:381)
	at com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:164)
	at com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:478)
	at com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:375)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:523)
	at com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:550)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:80)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.lang.Thread.run(Thread.java:750)
25/11/26 07:44:46 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:44:46 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:44:49 INFO DrainingState: Grace period finished
25/11/26 07:44:49 INFO DrainingState: starting shutdown for com.databricks.rpc.JettyServer$$anon$2@4dc0c152
25/11/26 07:44:49 INFO JettyServer$$anon$2: shutting down JettyServer
25/11/26 07:44:49 INFO DrainingState: finished shutdown for com.databricks.rpc.JettyServer$$anon$2@4dc0c152
25/11/26 07:44:49 INFO DrainingState: Drain complete, exiting now.
25/11/26 07:44:50 INFO ShutdownHookManager: Shutdown hook called
25/11/26 07:44:50 INFO ShutdownHookManager: Deleting directory /local_disk0/tmp/spark-f2457ba7-70c3-4cbf-8d13-2e347b0c530d
25/11/26 07:44:50 INFO ShutdownHookManager: Deleting directory /local_disk0/spark-91a862c2-8730-4774-8c91-646405229d0c
25/11/26 07:44:50 INFO ShutdownHookManager: Deleting directory /local_disk0/tmp/spark-cec58feb-d686-49a8-b80e-442452766698
25/11/26 07:44:50 INFO ShutdownHookManager: Deleting directory /local_disk0/spark-91a862c2-8730-4774-8c91-646405229d0c/pyspark-7ee9a980-8768-4f10-9211-e0409ac7bc46
25/11/26 07:44:50 INFO ShutdownHookManager: Deleting directory /local_disk0/tmp/spark-c04576ae-0ee2-4bb7-aa8c-5cdf8a672e97
25/11/26 07:44:50 INFO ShutdownHookManager: Deleting directory /local_disk0/dbio_cache_root_1714-066bb9ed-387e-4588-be2d-22366c253126
25/11/26 07:44:50 INFO ShutdownHookManager: Deleting directory /local_disk0/spark-91a862c2-8730-4774-8c91-646405229d0c/pyspark-aa3b28eb-58af-45a9-b895-1b690c9a3db4
25/11/26 07:44:50 INFO DriverDaemon$: Stopping Log4j2...
25/11/26 07:45:00 INFO DriverDaemon$: Started Log4j2
25/11/26 07:45:02 INFO DriverDaemon$: Current JVM Version 1.8.0_462
25/11/26 07:45:02 INFO DriverDaemon$: ========== driver starting up ==========
25/11/26 07:45:02 INFO DriverDaemon$: Java: Azul Systems, Inc. 1.8.0_462
25/11/26 07:45:02 INFO DriverDaemon$: OS: Linux/amd64 5.15.0-1091-azure
25/11/26 07:45:02 INFO DriverDaemon$: CWD: /databricks/driver
25/11/26 07:45:02 INFO DriverDaemon$: Mem: Max: 7.9G loaded GCs: PS Scavenge, PS MarkSweep
25/11/26 07:45:02 INFO DriverDaemon$: Logging multibyte characters: âœ“
25/11/26 07:45:02 INFO DriverDaemon$: 'publicFile.rolling.rewrite' appender in root logger: class org.apache.logging.log4j.core.appender.rewrite.RewriteAppender
25/11/26 07:45:02 INFO DriverDaemon$: == Modules:
25/11/26 07:45:03 INFO DriverDaemon$: Starting prometheus metrics log export timer
25/11/26 07:45:04 INFO DriverConf: Configured feature flag data source LaunchDarkly
25/11/26 07:45:04 INFO DriverConf: Configured feature flag data source LaunchDarkly
25/11/26 07:45:04 WARN DriverConf: REGION environment variable is not defined. getConfForCurrentRegion will always return default value
25/11/26 07:45:04 INFO DriverDaemon$: Loaded JDBC drivers in 61 ms
25/11/26 07:45:04 INFO DriverDaemon$: Universe Git Hash: f574797ba68fce84d3a50e05c13993f77f57aea0
25/11/26 07:45:04 INFO DriverDaemon$: Spark Git Hash: d0b1371a97d80366f49e5e050bac9e7922e31fd0
25/11/26 07:45:04 WARN SparkConfUtils$: Setting the same key twice for spark.hadoop.hive.server2.keystore.password
25/11/26 07:45:04 WARN SparkConfUtils$: Setting the same key twice for spark.databricks.io.directoryCommit.enableLogicalDelete
25/11/26 07:45:04 WARN SparkConfUtils$: Setting the same key twice for spark.hadoop.hive.server2.keystore.path
25/11/26 07:45:04 INFO SparkConfUtils$: Customize spark config according to file /tmp/custom-spark.conf
25/11/26 07:45:04 WARN RunHelpers$: Missing tag isolation client: java.util.NoSuchElementException: key not found: TagDefinition(clientType,The client type for a request, used for isolating resources for the request.,DATA_LABEL_SYSTEM_NOT_SENSITIVE,false,false,List(),UsageLogRedactionConfig(List()))
25/11/26 07:45:04 INFO DatabricksILoop$: Creating throwaway interpreter
25/11/26 07:45:04 INFO MetastoreMonitor$: Internal metastore configured
25/11/26 07:45:04 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:3306/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:45:04 INFO DriverCorral: Creating the driver context
25/11/26 07:45:04 INFO DatabricksILoop$: Class Server Dir: /local_disk0/tmp/repl/spark-5930641157652079495-ab452427-ec28-457b-b730-657e195ed792
25/11/26 07:45:04 INFO NestedConnectionMonitor$$anon$1: Configured feature flag data source LaunchDarkly
25/11/26 07:45:04 INFO NestedConnectionMonitor$$anon$1: Configured feature flag data source LaunchDarkly
25/11/26 07:45:04 WARN NestedConnectionMonitor$$anon$1: REGION environment variable is not defined. getConfForCurrentRegion will always return default value
25/11/26 07:45:04 INFO FeatureFlagRegisterConf: Configured feature flag data source LaunchDarkly
25/11/26 07:45:04 INFO FeatureFlagRegisterConf: Configured feature flag data source LaunchDarkly
25/11/26 07:45:04 WARN FeatureFlagRegisterConf: REGION environment variable is not defined. getConfForCurrentRegion will always return default value
25/11/26 07:45:04 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:45:04 WARN SparkConfUtils$: Setting the same key twice for spark.hadoop.hive.server2.keystore.password
25/11/26 07:45:04 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:45:04 WARN SparkConfUtils$: Setting the same key twice for spark.databricks.io.directoryCommit.enableLogicalDelete
25/11/26 07:45:04 WARN SparkConfUtils$: Setting the same key twice for spark.hadoop.hive.server2.keystore.path
25/11/26 07:45:04 INFO SparkConfUtils$: Customize spark config according to file /tmp/custom-spark.conf
25/11/26 07:45:04 WARN SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
25/11/26 07:45:04 INFO DynamicRpcConf: Configured feature flag data source LaunchDarkly
25/11/26 07:45:04 INFO DynamicRpcConf: Configured feature flag data source LaunchDarkly
25/11/26 07:45:04 WARN DynamicRpcConf: REGION environment variable is not defined. getConfForCurrentRegion will always return default value
25/11/26 07:45:05 INFO DatabricksILoop$: Cleaning expired driver directory pythonEnv-8bde49c7-6f49-493d-a3b1-c7988d7050c9
25/11/26 07:45:05 INFO DatabricksILoop$: Cleaning expired driver directory pythonEnv-3d14f00c-6b84-4644-acae-9b9522029cb4
25/11/26 07:45:05 INFO SparkContext: Running Spark version 3.3.2
25/11/26 07:45:05 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:45:05 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:45:05 INFO MetastoreMonitor: Metastore healthcheck successful (connection duration = 1411 milliseconds)
25/11/26 07:45:05 INFO ResourceUtils: ==============================================================
25/11/26 07:45:05 INFO ResourceUtils: No custom resources configured for spark.driver.
25/11/26 07:45:05 INFO ResourceUtils: ==============================================================
25/11/26 07:45:05 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:9207/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:45:05 INFO SparkContext: Submitted application: Databricks Shell
25/11/26 07:45:05 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:45:05 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:45:05 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 8874, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/11/26 07:45:05 INFO ResourceProfile: Limiting resource is cpu
25/11/26 07:45:05 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/11/26 07:45:05 INFO SecurityManager: Changing view acls to: root
25/11/26 07:45:05 INFO SecurityManager: Changing modify acls to: root
25/11/26 07:45:05 INFO SecurityManager: Changing view acls groups to: 
25/11/26 07:45:05 INFO SecurityManager: Changing modify acls groups to: 
25/11/26 07:45:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set(); RPC SSL disabled
25/11/26 07:45:06 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:45:06 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:45:06 INFO MetastoreMonitor: PoPProxy healthcheck successful (connection duration = 443 milliseconds)
25/11/26 07:45:06 INFO Utils: Successfully started service 'sparkDriver' on port 42943.
25/11/26 07:45:06 INFO SparkEnv: Registering MapOutputTracker
25/11/26 07:45:06 INFO SecurityManager: Changing view acls to: root
25/11/26 07:45:06 INFO SecurityManager: Changing modify acls to: root
25/11/26 07:45:06 INFO SecurityManager: Changing view acls groups to: 
25/11/26 07:45:06 INFO SecurityManager: Changing modify acls groups to: 
25/11/26 07:45:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set(); RPC SSL disabled
25/11/26 07:45:06 INFO SparkEnv: Registering BlockManagerMaster
25/11/26 07:45:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/11/26 07:45:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/11/26 07:45:06 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/11/26 07:45:06 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-65eb4134-0879-424e-b78c-1ed247d2d518
25/11/26 07:45:06 INFO MemoryStore: MemoryStore started with capacity 4.4 GiB
25/11/26 07:45:06 INFO SparkEnv: Registering OutputCommitCoordinator
25/11/26 07:45:06 INFO SparkContext: Spark configuration:
libraryDownload.sleepIntervalSeconds=5
libraryDownload.timeoutSeconds=180
spark.akka.frameSize=256
spark.app.name=Databricks Shell
spark.app.startTime=1764143105465
spark.cleaner.referenceTracking.blocking=false
spark.databricks.SC200982.blockBuiltInFunctionOverride=true
spark.databricks.acl.client=com.databricks.spark.sql.acl.client.SparkSqlAclClient
spark.databricks.acl.provider=com.databricks.sql.acl.ReflectionBackedAclProvider
spark.databricks.acl.scim.client=com.databricks.spark.sql.acl.client.DriverToWebappScimClient
spark.databricks.automl.serviceEnabled=true
spark.databricks.autotune.maintenance.client.classname=com.databricks.maintenanceautocompute.MACClientImpl
spark.databricks.cloudProvider=Azure
spark.databricks.cloudfetch.hasRegionSupport=true
spark.databricks.cloudfetch.requestDownloadUrlsWithHeaders=*********(redacted)
spark.databricks.cloudfetch.requesterClassName=*********(redacted)
spark.databricks.clusterSource=UI
spark.databricks.clusterUsageTags.attribute_tag_budget=
spark.databricks.clusterUsageTags.attribute_tag_dust_bazel_path=
spark.databricks.clusterUsageTags.attribute_tag_dust_execution_env=
spark.databricks.clusterUsageTags.attribute_tag_dust_maintainer=
spark.databricks.clusterUsageTags.attribute_tag_dust_resource_class=
spark.databricks.clusterUsageTags.attribute_tag_dust_runbot_id=
spark.databricks.clusterUsageTags.attribute_tag_dust_runner=
spark.databricks.clusterUsageTags.attribute_tag_dust_suite=
spark.databricks.clusterUsageTags.attribute_tag_platform_name=
spark.databricks.clusterUsageTags.attribute_tag_service=
spark.databricks.clusterUsageTags.autoTerminationMinutes=60
spark.databricks.clusterUsageTags.azureSubscriptionId=8cf1045d-f235-4fd3-beff-c67785d438b1
spark.databricks.clusterUsageTags.cloudProvider=Azure
spark.databricks.clusterUsageTags.clusterAllTags=[{"key":"Vendor","value":"Databricks"},{"key":"Creator","value":"fantian@tianfan.partner.onmschina.cn"},{"key":"ClusterName","value":"ai_pipeline"},{"key":"ClusterId","value":"1125-113639-ndjs76hq"},{"key":"DatabricksEnvironment","value":"workerenv-2559323315997869"}]
spark.databricks.clusterUsageTags.clusterAvailability=ON_DEMAND_AZURE
spark.databricks.clusterUsageTags.clusterCreator=Webapp
spark.databricks.clusterUsageTags.clusterFirstOnDemand=1
spark.databricks.clusterUsageTags.clusterGeneration=4
spark.databricks.clusterUsageTags.clusterId=1125-113639-ndjs76hq
spark.databricks.clusterUsageTags.clusterLastActivityTime=1764139715713
spark.databricks.clusterUsageTags.clusterLogDeliveryEnabled=false
spark.databricks.clusterUsageTags.clusterLogDestination=
spark.databricks.clusterUsageTags.clusterLogDestinationType=
spark.databricks.clusterUsageTags.clusterMaxWorkers=8
spark.databricks.clusterUsageTags.clusterMetastoreAccessType=RDS_DIRECT
spark.databricks.clusterUsageTags.clusterMinWorkers=1
spark.databricks.clusterUsageTags.clusterName=ai_pipeline
spark.databricks.clusterUsageTags.clusterNoDriverDaemon=false
spark.databricks.clusterUsageTags.clusterNodeType=Standard_D4ds_v5
spark.databricks.clusterUsageTags.clusterNodeTypeFlexibilityEnabled=false
spark.databricks.clusterUsageTags.clusterNumCustomTags=0
spark.databricks.clusterUsageTags.clusterNumSshKeys=0
spark.databricks.clusterUsageTags.clusterOwnerOrgId=2559323315997869
spark.databricks.clusterUsageTags.clusterOwnerUserId=*********(redacted)
spark.databricks.clusterUsageTags.clusterPinned=false
spark.databricks.clusterUsageTags.clusterPythonVersion=3
spark.databricks.clusterUsageTags.clusterResourceClass=default
spark.databricks.clusterUsageTags.clusterScalingType=autoscaling
spark.databricks.clusterUsageTags.clusterSizeType=VM_CONTAINER
spark.databricks.clusterUsageTags.clusterSku=STANDARD_SKU
spark.databricks.clusterUsageTags.clusterSpotBidMaxPrice=-1.0
spark.databricks.clusterUsageTags.clusterState=Restarting
spark.databricks.clusterUsageTags.clusterStateMessage=Starting Spark
spark.databricks.clusterUsageTags.clusterTargetWorkers=1
spark.databricks.clusterUsageTags.clusterUnityCatalogMode=*********(redacted)
spark.databricks.clusterUsageTags.clusterWorkers=1
spark.databricks.clusterUsageTags.computeKind=CLASSIC_PREVIEW
spark.databricks.clusterUsageTags.containerType=LXC
spark.databricks.clusterUsageTags.dataPlaneRegion=chinanorth3
spark.databricks.clusterUsageTags.driverContainerId=44e2732adecc4b9b93ef1e2854e94c28
spark.databricks.clusterUsageTags.driverContainerPrivateIp=10.139.64.5
spark.databricks.clusterUsageTags.driverInstanceId=2a145075d1af445bb31ad568cbdafffe
spark.databricks.clusterUsageTags.driverInstancePrivateIp=10.139.0.4
spark.databricks.clusterUsageTags.driverNodeType=Standard_D4ds_v5
spark.databricks.clusterUsageTags.driverPublicDns=52.130.161.173
spark.databricks.clusterUsageTags.effectiveSparkVersion=12.2.x-scala2.12
spark.databricks.clusterUsageTags.enableCredentialPassthrough=*********(redacted)
spark.databricks.clusterUsageTags.enableDfAcls=false
spark.databricks.clusterUsageTags.enableElasticDisk=true
spark.databricks.clusterUsageTags.enableGlueCatalogCredentialPassthrough=*********(redacted)
spark.databricks.clusterUsageTags.enableJdbcAutoStart=true
spark.databricks.clusterUsageTags.enableJobsAutostart=true
spark.databricks.clusterUsageTags.enableLocalDiskEncryption=false
spark.databricks.clusterUsageTags.enableSqlAclsOnly=false
spark.databricks.clusterUsageTags.hailEnabled=false
spark.databricks.clusterUsageTags.ignoreTerminationEventInAlerting=false
spark.databricks.clusterUsageTags.instanceWorkerEnvId=workerenv-2559323315997869
spark.databricks.clusterUsageTags.instanceWorkerEnvNetworkType=default
spark.databricks.clusterUsageTags.isDpCpPrivateLinkEnabled=false
spark.databricks.clusterUsageTags.isGroupCluster=false
spark.databricks.clusterUsageTags.isIMv2Enabled=true
spark.databricks.clusterUsageTags.isServicePrincipalCluster=false
spark.databricks.clusterUsageTags.isSingleNode=false
spark.databricks.clusterUsageTags.isSingleUserCluster=*********(redacted)
spark.databricks.clusterUsageTags.managedResourceGroup=databricks-rg-Databricks-cn3-prod-52ba56scwuu2k
spark.databricks.clusterUsageTags.ngrokNpipEnabled=false
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2=0
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Abfss=0
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Dbfs=0
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2File=0
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Gcs=0
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2S3=0
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Volumes=0
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Workspace=0
spark.databricks.clusterUsageTags.numPerGlobalInitScriptsV2=0
spark.databricks.clusterUsageTags.orgId=2559323315997869
spark.databricks.clusterUsageTags.privateLinkEnabled=false
spark.databricks.clusterUsageTags.region=chinanorth3
spark.databricks.clusterUsageTags.runtimeEngine=STANDARD
spark.databricks.clusterUsageTags.shardName=az-chinanorth2
spark.databricks.clusterUsageTags.sparkEnvVarContainsBacktick=false
spark.databricks.clusterUsageTags.sparkEnvVarContainsDollarSign=false
spark.databricks.clusterUsageTags.sparkEnvVarContainsDoubleQuotes=false
spark.databricks.clusterUsageTags.sparkEnvVarContainsEscape=false
spark.databricks.clusterUsageTags.sparkEnvVarContainsNewline=false
spark.databricks.clusterUsageTags.sparkEnvVarContainsSingleQuotes=false
spark.databricks.clusterUsageTags.sparkImageLabel=release__12.2.x-snapshot-scala2.12__databricks__12.2.62__f574797__d0b1371__jenkins__b6e50ce__format-3
spark.databricks.clusterUsageTags.sparkMasterUrlType=*********(redacted)
spark.databricks.clusterUsageTags.sparkVersion=12.2.x-scala2.12
spark.databricks.clusterUsageTags.userId=*********(redacted)
spark.databricks.clusterUsageTags.userProvidedRemoteVolumeCount=*********(redacted)
spark.databricks.clusterUsageTags.userProvidedRemoteVolumeSizeGb=*********(redacted)
spark.databricks.clusterUsageTags.userProvidedRemoteVolumeType=*********(redacted)
spark.databricks.clusterUsageTags.userProvidedSparkVersion=*********(redacted)
spark.databricks.clusterUsageTags.workerEnvironmentId=workerenv-2559323315997869
spark.databricks.credential.aws.secretKey.redactor=*********(redacted)
spark.databricks.credential.redactor=*********(redacted)
spark.databricks.credential.scope.fs.adls.gen2.tokenProviderClassName=*********(redacted)
spark.databricks.credential.scope.fs.gs.auth.access.tokenProviderClassName=*********(redacted)
spark.databricks.credential.scope.fs.impl=*********(redacted)
spark.databricks.credential.scope.fs.s3a.tokenProviderClassName=*********(redacted)
spark.databricks.delta.logStore.crossCloud.fatal=true
spark.databricks.delta.multiClusterWrites.enabled=true
spark.databricks.deltaSharing.clientClassName=com.databricks.deltasharing.DataSharingClientImpl
spark.databricks.driver.cleanUpSparkSessionsOnUCSharedClusters=true
spark.databricks.driver.enableDncOomMessage=false
spark.databricks.driver.preferredMavenCentralMirrorUrl=*********(redacted)
spark.databricks.driverNfs.clusterWidePythonLibsEnabled=true
spark.databricks.driverNfs.enabled=true
spark.databricks.driverNfs.pathSuffix=.ephemeral_nfs
spark.databricks.driverNodeTypeId=Standard_D4ds_v5
spark.databricks.enablePublicDbfsFuse=false
spark.databricks.eventLog.dir=eventlogs
spark.databricks.eventLog.enabled=true
spark.databricks.eventLog.listenerClassName=com.databricks.backend.daemon.driver.DBCEventLoggingListener
spark.databricks.instanceId=2a145075d1af445bb31ad568cbdafffe
spark.databricks.io.cache.initialDiskSize=161061273600
spark.databricks.io.directoryCommit.enableLogicalDelete=false
spark.databricks.isShieldWorkspace=false
spark.databricks.managedCatalog.clientClassName=com.databricks.managedcatalog.ManagedCatalogClientImpl
spark.databricks.metrics.filesystem_io_metrics=true
spark.databricks.mlflow.autologging.enableGenAIFlavors=true
spark.databricks.mlflow.autologging.enabled=true
spark.databricks.overrideDefaultCommitProtocol=org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol
spark.databricks.passthrough.adls.gen2.tokenProviderClassName=*********(redacted)
spark.databricks.passthrough.adls.tokenProviderClassName=*********(redacted)
spark.databricks.passthrough.glue.credentialsProviderFactoryClassName=*********(redacted)
spark.databricks.passthrough.glue.executorServiceFactoryClassName=*********(redacted)
spark.databricks.passthrough.oauth.refresher.impl=*********(redacted)
spark.databricks.passthrough.s3a.threadPoolExecutor.factory.class=com.databricks.backend.daemon.driver.aws.S3APassthroughThreadPoolExecutorFactory
spark.databricks.passthrough.s3a.tokenProviderClassName=*********(redacted)
spark.databricks.preemption.enabled=true
spark.databricks.privateLinkEnabled=false
spark.databricks.proxyHadoopTraffic.host=storage-proxy.databricks.com
spark.databricks.proxyHadoopTraffic.port=9210
spark.databricks.python.defaultPythonRepl=ipykernel
spark.databricks.redactor=com.databricks.spark.util.DatabricksSparkLogRedactorProxy
spark.databricks.repl.enableClassFileCleanup=true
spark.databricks.safer.unifiedPath.applyFlag.enabled=true
spark.databricks.secret.envVar.keys.toRedact=*********(redacted)
spark.databricks.secret.sparkConf.keys.toRedact=*********(redacted)
spark.databricks.service.dbutils.repl.backend=com.databricks.dbconnect.ReplDBUtils
spark.databricks.service.dbutils.server.backend=com.databricks.dbconnect.SparkServerDBUtils
spark.databricks.session.share=false
spark.databricks.sparkContextId=5930641157652079495
spark.databricks.sql.configMapperClass=com.databricks.dbsql.config.SqlConfigMapperBridge
spark.databricks.tahoe.logStore.aws.class=com.databricks.tahoe.store.MultiClusterLogStore
spark.databricks.tahoe.logStore.azure.class=com.databricks.tahoe.store.AzureLogStore
spark.databricks.tahoe.logStore.class=com.databricks.tahoe.store.DelegatingLogStore
spark.databricks.tahoe.logStore.gcp.class=com.databricks.tahoe.store.GCPLogStore
spark.databricks.telemetry.prometheus.samplingRate=100
spark.databricks.unityCatalog.credentialManager.apiTokenProviderClassName=*********(redacted)
spark.databricks.unityCatalog.credentialManager.tokenRefreshEnabled=*********(redacted)
spark.databricks.unityCatalog.enabled=true
spark.databricks.unityCatalog.enforce.permissions=false
spark.databricks.unityCatalog.externalLocationFallbackMode.enabled=false
spark.databricks.unityCatalog.volumes.enabled=true
spark.databricks.workerNodeTypeId=Standard_D4ds_v5
spark.databricks.workspaceUrl=*********(redacted)
spark.databricks.wsfs.workspacePrivatePreview=true
spark.databricks.wsfsPublicPreview=true
spark.delta.sharing.profile.provider.class=*********(redacted)
spark.driver.allowMultipleContexts=false
spark.driver.extraJavaOptions=-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED
spark.driver.host=10.139.64.5
spark.driver.maxResultSize=4g
spark.driver.port=42943
spark.driver.tempDirectory=/local_disk0/tmp
spark.eventLog.enabled=false
spark.executor.extraClassPath=/databricks/spark/dbconf/log4j/executor:/databricks/spark/dbconf/jets3t/:/databricks/spark/dbconf/hadoop:/databricks/hive/conf:/databricks/jars/*
spark.executor.extraJavaOptions=-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djava.io.tmpdir=/local_disk0/tmp -XX:ReservedCodeCacheSize=512m -XX:+UseCodeCacheFlushing -XX:PerMethodRecompilationCutoff=-1 -XX:PerBytecodeRecompilationCutoff=-1 -Djava.security.properties=/databricks/spark/dbconf/java/extra.security -XX:-UseContainerSupport -XX:+PrintFlagsFinal -XX:+PrintGCDateStamps -XX:+PrintGCDetails -verbose:gc -Xss4m -Djava.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni -Djavax.xml.datatype.DatatypeFactory=com.sun.org.apache.xerces.internal.jaxp.datatype.DatatypeFactoryImpl -Djavax.xml.parsers.DocumentBuilderFactory=com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -Djavax.xml.validation.SchemaFactory:http://www.w3.org/2001/XMLSchema=com.sun.org.apache.xerces.internal.jaxp.validation.XMLSchemaFactory -Dorg.xml.sax.driver=com.sun.org.apache.xerces.internal.parsers.SAXParser -Dorg.w3c.dom.DOMImplementationSourceList=com.sun.org.apache.xerces.internal.dom.DOMXSImplementationSourceImpl -Djavax.net.ssl.sessionCacheSize=10000 -Dscala.reflect.runtime.disable.typetag.cache=true -Dcom.google.cloud.spark.bigquery.repackaged.io.netty.tryReflectionSetAccessible=true -Dlog4j2.formatMsgNoLookups=true -Ddatabricks.serviceName=spark-executor-1
spark.executor.id=driver
spark.executor.memory=8874m
spark.executor.tempDirectory=/local_disk0/tmp
spark.extraListeners=com.databricks.backend.daemon.driver.DBCEventLoggingListener
spark.files.fetchFailure.unRegisterOutputOnHost=true
spark.files.overwrite=true
spark.files.useFetchCache=false
spark.hadoop.databricks.dbfs.client.version=v2
spark.hadoop.databricks.fs.perfMetrics.enable=true
spark.hadoop.databricks.loki.fileStatusCache.abfs.enabled=false
spark.hadoop.databricks.loki.fileStatusCache.gcs.enabled=false
spark.hadoop.databricks.loki.fileStatusCache.s3a.enabled=false
spark.hadoop.databricks.loki.fileSystemCache.enabled=true
spark.hadoop.databricks.s3.create.deleteUnnecessaryFakeDirectories=false
spark.hadoop.databricks.s3.verifyBucketExists.enabled=false
spark.hadoop.databricks.s3commit.client.sslTrustAll=false
spark.hadoop.fs.AbstractFileSystem.gs.impl=shaded.databricks.com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS
spark.hadoop.fs.abfs.impl=com.databricks.common.filesystem.LokiFileSystem
spark.hadoop.fs.abfs.impl.disable.cache=true
spark.hadoop.fs.abfss.impl=com.databricks.common.filesystem.LokiFileSystem
spark.hadoop.fs.abfss.impl.disable.cache=true
spark.hadoop.fs.adl.impl=com.databricks.adl.AdlFileSystem
spark.hadoop.fs.adl.impl.disable.cache=true
spark.hadoop.fs.azure.authorization.caching.enable=false
spark.hadoop.fs.azure.cache.invalidator.type=com.databricks.encryption.utils.CacheInvalidatorImpl
spark.hadoop.fs.azure.skip.metrics=true
spark.hadoop.fs.azure.user.agent.prefix=*********(redacted)
spark.hadoop.fs.cpfs-abfss.impl=*********(redacted)
spark.hadoop.fs.cpfs-abfss.impl.disable.cache=true
spark.hadoop.fs.cpfs-adl.impl=*********(redacted)
spark.hadoop.fs.cpfs-adl.impl.disable.cache=true
spark.hadoop.fs.cpfs-s3.impl=*********(redacted)
spark.hadoop.fs.cpfs-s3a.impl=*********(redacted)
spark.hadoop.fs.cpfs-s3n.impl=*********(redacted)
spark.hadoop.fs.dbfs.impl=com.databricks.backend.daemon.data.client.DbfsHadoop3
spark.hadoop.fs.dbfsartifacts.impl=com.databricks.backend.daemon.data.client.DBFSV1
spark.hadoop.fs.fcfs-abfs.impl=*********(redacted)
spark.hadoop.fs.fcfs-abfs.impl.disable.cache=true
spark.hadoop.fs.fcfs-abfss.impl=*********(redacted)
spark.hadoop.fs.fcfs-abfss.impl.disable.cache=true
spark.hadoop.fs.fcfs-s3.impl=*********(redacted)
spark.hadoop.fs.fcfs-s3.impl.disable.cache=true
spark.hadoop.fs.fcfs-s3a.impl=*********(redacted)
spark.hadoop.fs.fcfs-s3a.impl.disable.cache=true
spark.hadoop.fs.fcfs-s3n.impl=*********(redacted)
spark.hadoop.fs.fcfs-s3n.impl.disable.cache=true
spark.hadoop.fs.fcfs-wasb.impl=*********(redacted)
spark.hadoop.fs.fcfs-wasb.impl.disable.cache=true
spark.hadoop.fs.fcfs-wasbs.impl=*********(redacted)
spark.hadoop.fs.fcfs-wasbs.impl.disable.cache=true
spark.hadoop.fs.file.impl=com.databricks.backend.daemon.driver.WorkspaceLocalFileSystem
spark.hadoop.fs.gs.impl=com.databricks.common.filesystem.LokiFileSystem
spark.hadoop.fs.gs.impl.disable.cache=true
spark.hadoop.fs.gs.outputstream.upload.chunk.size=16777216
spark.hadoop.fs.idbfs.impl=com.databricks.io.idbfs.IdbfsFileSystem
spark.hadoop.fs.mlflowdbfs.impl=com.databricks.mlflowdbfs.MlflowdbfsFileSystem
spark.hadoop.fs.s3.impl=com.databricks.common.filesystem.LokiFileSystem
spark.hadoop.fs.s3.impl.disable.cache=true
spark.hadoop.fs.s3a.assumed.role.credentials.provider=*********(redacted)
spark.hadoop.fs.s3a.attempts.maximum=10
spark.hadoop.fs.s3a.block.size=67108864
spark.hadoop.fs.s3a.connection.maximum=200
spark.hadoop.fs.s3a.connection.timeout=50000
spark.hadoop.fs.s3a.fast.upload=true
spark.hadoop.fs.s3a.fast.upload.active.blocks=32
spark.hadoop.fs.s3a.fast.upload.default=true
spark.hadoop.fs.s3a.impl=com.databricks.common.filesystem.LokiFileSystem
spark.hadoop.fs.s3a.impl.disable.cache=true
spark.hadoop.fs.s3a.max.total.tasks=1000
spark.hadoop.fs.s3a.multipart.size=10485760
spark.hadoop.fs.s3a.multipart.threshold=104857600
spark.hadoop.fs.s3a.retry.interval=250ms
spark.hadoop.fs.s3a.retry.limit=6
spark.hadoop.fs.s3a.retry.throttle.interval=500ms
spark.hadoop.fs.s3a.threads.max=136
spark.hadoop.fs.s3n.impl=com.databricks.common.filesystem.LokiFileSystem
spark.hadoop.fs.s3n.impl.disable.cache=true
spark.hadoop.fs.stage.impl=com.databricks.backend.daemon.driver.managedcatalog.PersonalStagingFileSystem
spark.hadoop.fs.stage.impl.disable.cache=true
spark.hadoop.fs.wasb.impl=shaded.databricks.org.apache.hadoop.fs.azure.NativeAzureFileSystem
spark.hadoop.fs.wasb.impl.disable.cache=true
spark.hadoop.fs.wasbs.impl=shaded.databricks.org.apache.hadoop.fs.azure.NativeAzureFileSystem
spark.hadoop.fs.wasbs.impl.disable.cache=true
spark.hadoop.hive.hmshandler.retry.attempts=10
spark.hadoop.hive.hmshandler.retry.interval=2000
spark.hadoop.hive.server2.enable.doAs=false
spark.hadoop.hive.server2.idle.operation.timeout=7200000
spark.hadoop.hive.server2.idle.session.timeout=900000
spark.hadoop.hive.server2.keystore.password=*********(redacted)
spark.hadoop.hive.server2.keystore.path=/databricks/keys/jetty-ssl-driver-keystore.jks
spark.hadoop.hive.server2.session.check.interval=60000
spark.hadoop.hive.server2.thrift.http.cookie.auth.enabled=false
spark.hadoop.hive.server2.thrift.http.port=10000
spark.hadoop.hive.server2.transport.mode=http
spark.hadoop.hive.server2.use.SSL=true
spark.hadoop.hive.warehouse.subdir.inherit.perms=false
spark.hadoop.mapred.output.committer.class=com.databricks.backend.daemon.data.client.DirectOutputCommitter
spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version=2
spark.hadoop.parquet.abfs.readahead.optimization.enabled=true
spark.hadoop.parquet.block.size.row.check.max=10
spark.hadoop.parquet.block.size.row.check.min=10
spark.hadoop.parquet.filter.columnindex.enabled=false
spark.hadoop.parquet.memory.pool.ratio=0.5
spark.hadoop.parquet.page.metadata.validation.enabled=true
spark.hadoop.parquet.page.size.check.estimate=false
spark.hadoop.parquet.page.verify-checksum.enabled=true
spark.hadoop.parquet.page.write-checksum.enabled=true
spark.hadoop.spark.databricks.io.parquet.verifyChecksumOnWrite.enabled=false
spark.hadoop.spark.databricks.io.parquet.verifyChecksumOnWrite.throwsException=false
spark.hadoop.spark.driverproxy.customHeadersToProperties=*********(redacted)
spark.hadoop.spark.hadoop.aws.glue.cache.db.size=1000
spark.hadoop.spark.hadoop.aws.glue.cache.db.ttl-mins=30
spark.hadoop.spark.hadoop.aws.glue.cache.table.size=1000
spark.hadoop.spark.hadoop.aws.glue.cache.table.ttl-mins=30
spark.hadoop.spark.sql.parquet.output.committer.class=org.apache.spark.sql.parquet.DirectParquetOutputCommitter
spark.hadoop.spark.sql.sources.outputCommitterClass=com.databricks.backend.daemon.data.client.MapReduceDirectOutputCommitter
spark.home=/databricks/spark
spark.logConf=true
spark.master=spark://10.139.64.5:7077
spark.metrics.conf=/databricks/spark/conf/metrics.properties
spark.r.backendConnectionTimeout=604800
spark.r.numRBackendThreads=1
spark.rdd.compress=true
spark.repl.class.outputDir=/local_disk0/tmp/repl/spark-5930641157652079495-ab452427-ec28-457b-b730-657e195ed792
spark.rpc.message.maxSize=256
spark.scheduler.listenerbus.eventqueue.capacity=20000
spark.scheduler.mode=FAIR
spark.serializer.objectStreamReset=100
spark.shuffle.manager=SORT
spark.shuffle.memoryFraction=0.2
spark.shuffle.reduceLocality.enabled=false
spark.shuffle.service.enabled=true
spark.shuffle.service.port=4048
spark.sparklyr-backend.threads=1
spark.sparkr.use.daemon=false
spark.speculation=false
spark.speculation.multiplier=3
spark.speculation.quantile=0.9
spark.sql.allowMultipleContexts=false
spark.sql.hive.convertCTAS=true
spark.sql.hive.convertMetastoreParquet=true
spark.sql.hive.metastore.jars=/databricks/databricks-hive/*
spark.sql.hive.metastore.sharedPrefixes=org.mariadb.jdbc,com.mysql.jdbc,org.postgresql,com.microsoft.sqlserver,microsoft.sql.DateTimeOffset,microsoft.sql.Types,com.databricks,com.codahale,com.fasterxml.jackson,shaded.databricks
spark.sql.hive.metastore.version=0.13.0
spark.sql.legacy.createHiveTableByDefault=false
spark.sql.parquet.cacheMetadata=true
spark.sql.parquet.compression.codec=snappy
spark.sql.sources.commitProtocolClass=com.databricks.sql.transaction.directory.DirectoryAtomicCommitProtocol
spark.sql.sources.default=delta
spark.sql.streaming.checkpointFileManagerClass=com.databricks.spark.sql.streaming.DatabricksCheckpointFileManager
spark.sql.streaming.stopTimeout=15s
spark.sql.warehouse.dir=*********(redacted)
spark.storage.blockManagerTimeoutIntervalMs=300000
spark.storage.memoryFraction=0.5
spark.streaming.driver.writeAheadLog.allowBatching=true
spark.streaming.driver.writeAheadLog.closeFileAfterWrite=true
spark.task.reaper.enabled=true
spark.task.reaper.killTimeout=60s
spark.ui.port=40001
spark.ui.prometheus.enabled=true
spark.worker.aioaLazyConfig.dbfsReadinessCheckClientClass=com.databricks.backend.daemon.driver.NephosDbfsReadinessCheckClient
spark.worker.aioaLazyConfig.iamReadinessCheckClientClass=com.databricks.backend.daemon.driver.NephosIamRoleCheckClient
spark.worker.cleanup.enabled=false
25/11/26 07:45:06 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/11/26 07:45:06 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme s3. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:45:06 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme s3a. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:45:06 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme s3n. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:45:06 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme abfs. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:45:06 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme abfss. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:45:06 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme gs. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:45:07 INFO log: Logging initialized @13945ms to org.eclipse.jetty.util.log.Slf4jLog
25/11/26 07:45:07 INFO Server: jetty-9.4.46.v20220331; built: 2022-03-31T16:38:08.030Z; git: bc17a0369a11ecf40bb92c839b9ef0a8ac50ea18; jvm 1.8.0_462-b08
25/11/26 07:45:07 INFO Server: Started @14171ms
25/11/26 07:45:07 INFO AbstractConnector: Started ServerConnector@71ea9a0d{HTTP/1.1, (http/1.1)}{10.139.64.5:40001}
25/11/26 07:45:07 INFO Utils: Successfully started service 'SparkUI' on port 40001.
25/11/26 07:45:07 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4b50ebea{/,null,AVAILABLE,@Spark}
25/11/26 07:45:08 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/11/26 07:45:08 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/11/26 07:45:08 WARN DBRDebuggerEventReporter: Driver/10.139.64.5 got terminated abnormally due to OTHER.
25/11/26 07:45:08 WARN DBRDebuggerEventReporter: 
25/11/26 07:45:08 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/11/26 07:45:09 INFO FairSchedulableBuilder: Fair scheduler configuration not found, created default pool: default, schedulingMode: FAIR, minShare: 0, weight: 1
25/11/26 07:45:09 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/11/26 07:45:09 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/11/26 07:45:09 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/11/26 07:45:09 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.139.64.5:7077...
25/11/26 07:45:09 INFO TransportClientFactory: Successfully created connection to /10.139.64.5:7077 after 82 ms (0 ms spent in bootstraps)
25/11/26 07:45:09 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251126074509-0002
25/11/26 07:45:09 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251126074509-0002/0 on worker-20251126065325-10.139.64.4-44021 (10.139.64.4:44021) with 4 core(s)
25/11/26 07:45:09 INFO StandaloneSchedulerBackend: Granted executor ID app-20251126074509-0002/0 on hostPort 10.139.64.4:44021 with 4 core(s), 8.7 GiB RAM
25/11/26 07:45:09 INFO TaskSchedulerImpl: Task preemption enabled.
25/11/26 07:45:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36197.
25/11/26 07:45:09 INFO NettyBlockTransferService: Server created on 10.139.64.5:36197
25/11/26 07:45:09 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/11/26 07:45:09 INFO BlockManager: external shuffle service port = 4048
25/11/26 07:45:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.5, 36197, None)
25/11/26 07:45:09 INFO DatabricksILoop$: Finished creating throwaway interpreter
25/11/26 07:45:09 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.5:36197 with 4.4 GiB RAM, BlockManagerId(driver, 10.139.64.5, 36197, None)
25/11/26 07:45:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.5, 36197, None)
25/11/26 07:45:09 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.5, 36197, None)
25/11/26 07:45:09 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251126074509-0002/0 is now RUNNING
25/11/26 07:45:10 INFO DBCEventLoggingListener: Initializing DBCEventLoggingListener (compressionEnabled=true)
25/11/26 07:45:10 INFO DBCEventLoggingListener: Logging events to eventlogs/5930641157652079495/eventlog
25/11/26 07:45:10 INFO SparkContext: Registered listener com.databricks.backend.daemon.driver.DBCEventLoggingListener
25/11/26 07:45:10 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme s3. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:45:10 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme s3a. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:45:10 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme s3n. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:45:10 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme abfs. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:45:10 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme abfss. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:45:10 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme gs. Previous value: com.databricks.common.filesystem.LokiFileSystem
25/11/26 07:45:10 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@4b50ebea{/,null,STOPPED,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@751df26c{/jobs,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4bbc9862{/jobs/json,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@8cc1bac{/jobs/job,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@20f1e26{/jobs/job/json,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@75c90ec5{/stages,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4f7bb581{/stages/json,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3087b35f{/stages/stage,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@19324eab{/stages/stage/json,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@20bd3082{/stages/pool,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@664f1c53{/stages/pool/json,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@69cd4267{/storage,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@85420{/storage/json,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@49dce561{/storage/rdd,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4e38b4ea{/storage/rdd/json,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@20e1ce62{/environment,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3df05c40{/environment/json,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5b1505c3{/executors,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@73c71083{/executors/json,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3f2731e5{/executors/threadDump,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6a636c62{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5863ef93{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@519f6adb{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@22938166{/static,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6e16fcaf{/,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4de3a1ca{/api,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4b0a6c53{/metrics,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2d95c3ef{/jobs/job/kill,null,AVAILABLE,@Spark}
25/11/26 07:45:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@559baea1{/stages/stage/kill,null,AVAILABLE,@Spark}
25/11/26 07:45:11 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@df80af2{/metrics/json,null,AVAILABLE,@Spark}
25/11/26 07:45:11 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/11/26 07:45:11 INFO SparkContext: Loading Spark Service RPC Server. Classloader stack:List(com.databricks.backend.daemon.driver.ClassLoaders$MultiReplClassLoader@24710e61, com.databricks.backend.daemon.driver.ClassLoaders$LibraryClassLoader@385ff04e, sun.misc.Launcher$AppClassLoader@5aaa6d82, sun.misc.Launcher$ExtClassLoader@42b64ab8)
25/11/26 07:45:11 INFO SparkServiceRPCServer: Initializing Spark Service RPC Server. Classloader stack: List(com.databricks.backend.daemon.driver.ClassLoaders$MultiReplClassLoader@24710e61, com.databricks.backend.daemon.driver.ClassLoaders$LibraryClassLoader@385ff04e, sun.misc.Launcher$AppClassLoader@5aaa6d82, sun.misc.Launcher$ExtClassLoader@42b64ab8)
25/11/26 07:45:11 INFO SparkServiceRPCServer: Starting Spark Service RPC Server
25/11/26 07:45:11 INFO SparkServiceRPCServer: Starting Spark Service RPC Server. Classloader stack: List(com.databricks.backend.daemon.driver.ClassLoaders$MultiReplClassLoader@24710e61, com.databricks.backend.daemon.driver.ClassLoaders$LibraryClassLoader@385ff04e, sun.misc.Launcher$AppClassLoader@5aaa6d82, sun.misc.Launcher$ExtClassLoader@42b64ab8)
25/11/26 07:45:11 INFO Server: jetty-9.4.46.v20220331; built: 2022-03-31T16:38:08.030Z; git: bc17a0369a11ecf40bb92c839b9ef0a8ac50ea18; jvm 1.8.0_462-b08
25/11/26 07:45:11 INFO AbstractConnector: Started ServerConnector@ad7d724{HTTP/1.1, (http/1.1)}{0.0.0.0:15001}
25/11/26 07:45:11 INFO Server: Started @18185ms
25/11/26 07:45:11 INFO DatabricksILoop$: Successfully registered spark metrics in Prometheus registry
25/11/26 07:45:11 INFO DatabricksILoop$: Successfully initialized SparkContext
25/11/26 07:45:11 INFO SharedState: Scheduler stats enabled.
25/11/26 07:45:11 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/11/26 07:45:11 INFO SharedState: Warehouse path is 'dbfs:/user/hive/warehouse'.
25/11/26 07:45:11 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2b45ede{/storage/iocache,null,AVAILABLE,@Spark}
25/11/26 07:45:11 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@51b22f06{/storage/iocache/json,null,AVAILABLE,@Spark}
25/11/26 07:45:11 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@256edef4{/SQL,null,AVAILABLE,@Spark}
25/11/26 07:45:11 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@52a42e0f{/SQL/json,null,AVAILABLE,@Spark}
25/11/26 07:45:11 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@321b2469{/SQL/execution,null,AVAILABLE,@Spark}
25/11/26 07:45:11 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5b60accd{/SQL/execution/json,null,AVAILABLE,@Spark}
25/11/26 07:45:11 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@19b8bcb5{/static/sql,null,AVAILABLE,@Spark}
25/11/26 07:45:12 WARN SQLConf: The SQL config 'spark.sql.hive.convertCTAS' has been deprecated in Spark v3.1 and may be removed in the future. Set 'spark.sql.legacy.createHiveTableByDefault' to false instead.
25/11/26 07:45:12 WARN SQLConf: The SQL config 'spark.sql.hive.convertCTAS' has been deprecated in Spark v3.1 and may be removed in the future. Set 'spark.sql.legacy.createHiveTableByDefault' to false instead.
25/11/26 07:45:15 INFO DriverConf: Configured feature flag data source LaunchDarkly
25/11/26 07:45:15 INFO DriverConf: Configured feature flag data source LaunchDarkly
25/11/26 07:45:15 WARN DriverConf: REGION environment variable is not defined. getConfForCurrentRegion will always return default value
25/11/26 07:45:15 INFO DriverConf: Configured feature flag data source LaunchDarkly
25/11/26 07:45:15 INFO DriverConf: Configured feature flag data source LaunchDarkly
25/11/26 07:45:15 WARN DriverConf: REGION environment variable is not defined. getConfForCurrentRegion will always return default value
25/11/26 07:45:16 INFO HiveUnityCatalogCheckRule: Collecting SQL actions took 157.863386 ms.
25/11/26 07:45:16 INFO DataClientConf: Configured feature flag data source LaunchDarkly
25/11/26 07:45:16 INFO DataClientConf: Configured feature flag data source LaunchDarkly
25/11/26 07:45:16 WARN DataClientConf: REGION environment variable is not defined. getConfForCurrentRegion will always return default value
25/11/26 07:45:16 INFO DataClientConf: Configured feature flag data source LaunchDarkly
25/11/26 07:45:16 INFO DataClientConf: Configured feature flag data source LaunchDarkly
25/11/26 07:45:16 WARN DataClientConf: REGION environment variable is not defined. getConfForCurrentRegion will always return default value
25/11/26 07:45:16 INFO DatabricksMountsStore: Mount store initialization: Attempting to get the list of mounts from metadata manager of DBFS
25/11/26 07:45:17 INFO log: Logging initialized @23933ms to shaded.v9_4.org.eclipse.jetty.util.log.Slf4jLog
25/11/26 07:45:17 INFO TypeUtil: JVM Runtime does not support Modules
25/11/26 07:45:17 INFO DatabricksMountsStore: Mount store initialization: Received a list of 9 mounts accessible from metadata manager of DBFS
25/11/26 07:45:17 INFO DatabricksMountsStore: Updated mounts cache. Changes: List((+,DbfsMountPoint(s3a://databricks-datasets-seoul/, /databricks-datasets)), (+,DbfsMountPoint(uc-volumes:/Volumes, /Volumes)), (+,DbfsMountPoint(unsupported-access-mechanism-for-path--use-mlflow-client:/, /databricks/mlflow-tracking)), (+,DbfsMountPoint(wasbs://dbstoragedyxwjqklqf7me.blob.core.chinacloudapi.cn/2559323315997869, /databricks-results)), (+,DbfsMountPoint(unsupported-access-mechanism-for-path--use-mlflow-client:/, /databricks/mlflow-registry)), (+,DbfsMountPoint(dbfs-reserved-path:/uc-volumes-reserved, /Volume)), (+,DbfsMountPoint(dbfs-reserved-path:/uc-volumes-reserved, /volumes)), (+,DbfsMountPoint(wasbs://dbstoragedyxwjqklqf7me.blob.core.chinacloudapi.cn/2559323315997869, /)), (+,DbfsMountPoint(dbfs-reserved-path:/uc-volumes-reserved, /volume)))
25/11/26 07:45:18 INFO HadoopFSUtil$: Installing the old filesystem implementation for scheme s3n. Current value: com.databricks.sql.acl.fs.CredentialScopeFileSystem. Old value to be restored: com.databricks.common.filesystem.LokiFileSystem.
25/11/26 07:45:18 INFO HadoopFSUtil$: Installing the old filesystem implementation for scheme s3a. Current value: com.databricks.sql.acl.fs.CredentialScopeFileSystem. Old value to be restored: com.databricks.common.filesystem.LokiFileSystem.
25/11/26 07:45:18 INFO HadoopFSUtil$: Installing the old filesystem implementation for scheme abfss. Current value: com.databricks.sql.acl.fs.CredentialScopeFileSystem. Old value to be restored: com.databricks.common.filesystem.LokiFileSystem.
25/11/26 07:45:18 INFO HadoopFSUtil$: Installing the old filesystem implementation for scheme gs. Current value: com.databricks.sql.acl.fs.CredentialScopeFileSystem. Old value to be restored: com.databricks.common.filesystem.LokiFileSystem.
25/11/26 07:45:18 INFO HadoopFSUtil$: Installing the old filesystem implementation for scheme s3. Current value: com.databricks.sql.acl.fs.CredentialScopeFileSystem. Old value to be restored: com.databricks.common.filesystem.LokiFileSystem.
25/11/26 07:45:18 INFO HadoopFSUtil$: Installing the old filesystem implementation for scheme abfs. Current value: com.databricks.sql.acl.fs.CredentialScopeFileSystem. Old value to be restored: com.databricks.common.filesystem.LokiFileSystem.
25/11/26 07:45:18 INFO DatabricksFileSystemV2Factory: Creating wasbs file system for wasbs://root@dbstoragedyxwjqklqf7me.blob.core.chinacloudapi.cn
25/11/26 07:45:18 INFO AzureNativeFileSystemStore: URI scheme: wasbs, using https for connections
25/11/26 07:45:18 INFO NativeAzureFileSystem: Delete with limit configurations: deleteFileCountLimitEnabled=false, deleteFileCountLimit=-1
25/11/26 07:45:18 INFO DbfsHadoop3: Initialized DBFS with DBFSV2 as the delegate.
25/11/26 07:45:18 INFO HiveConf: Found configuration file file:/databricks/hive/conf/hive-site.xml
25/11/26 07:45:18 INFO SessionManager: HiveServer2: Background operation thread pool size: 100
25/11/26 07:45:18 INFO SessionManager: HiveServer2: Background operation thread wait queue size: 100
25/11/26 07:45:18 INFO SessionManager: HiveServer2: Background operation thread keepalive time: 10 seconds
25/11/26 07:45:18 INFO AbstractService: Service:OperationManager is inited.
25/11/26 07:45:18 INFO AbstractService: Service:SessionManager is inited.
25/11/26 07:45:18 INFO SparkSQLCLIService: Service: CLIService is inited.
25/11/26 07:45:18 INFO AbstractService: Service:ThriftHttpCLIService is inited.
25/11/26 07:45:18 INFO HiveThriftServer2: Service: HiveServer2 is inited.
25/11/26 07:45:18 INFO AbstractService: Service:OperationManager is started.
25/11/26 07:45:18 INFO AbstractService: Service:SessionManager is started.
25/11/26 07:45:18 INFO SparkSQLCLIService: Service: CLIService is started.
25/11/26 07:45:18 INFO AbstractService: Service:ThriftHttpCLIService is started.
25/11/26 07:45:18 INFO ThriftCLIService: HTTP Server SSL: adding excluded protocols: [SSLv2, SSLv3]
25/11/26 07:45:18 INFO ThriftCLIService: HTTP Server SSL: SslContextFactory.getExcludeProtocols = [SSL, SSLv2, SSLv2Hello, SSLv3]
25/11/26 07:45:18 INFO Server: jetty-9.4.46.v20220331; built: 2022-03-31T16:38:08.030Z; git: bc17a0369a11ecf40bb92c839b9ef0a8ac50ea18; jvm 1.8.0_462-b08
25/11/26 07:45:18 INFO session: DefaultSessionIdManager workerName=node0
25/11/26 07:45:18 INFO session: No SessionScavenger set, using defaults
25/11/26 07:45:18 INFO session: node0 Scavenging every 660000ms
25/11/26 07:45:18 WARN SecurityHandler: ServletContext@o.e.j.s.ServletContextHandler@536af138{/,null,STARTING} has uncovered http methods for path: /*
25/11/26 07:45:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@536af138{/,null,AVAILABLE}
25/11/26 07:45:18 INFO SslContextFactory: x509=X509@344ae64b(1,h=[az-chinanorth2.workers.prod.ns.databricks.com],a=[],w=[]) for Server@31287930[provider=null,keyStore=file:///databricks/keys/jetty-ssl-driver-keystore.jks,trustStore=null]
25/11/26 07:45:18 INFO AbstractConnector: Started ServerConnector@3710b3d9{SSL, (ssl, http/1.1)}{0.0.0.0:10000}
25/11/26 07:45:18 INFO Server: Started @25658ms
25/11/26 07:45:18 INFO ThriftCLIService: Started ThriftHttpCLIService in https mode on port 10000 path=/cliservice/* with 5...500 worker threads
25/11/26 07:45:18 INFO AbstractService: Service:HiveServer2 is started.
25/11/26 07:45:18 INFO HiveThriftServer2: HiveThriftServer2 started
25/11/26 07:45:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7c80c68f{/sqlserver,null,AVAILABLE,@Spark}
25/11/26 07:45:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@23b34af8{/sqlserver/json,null,AVAILABLE,@Spark}
25/11/26 07:45:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3df17e4b{/sqlserver/session,null,AVAILABLE,@Spark}
25/11/26 07:45:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7618e4bf{/sqlserver/session/json,null,AVAILABLE,@Spark}
25/11/26 07:45:18 INFO DatabricksILoop$: Trying to load dynamic config on startup: /databricks/driver/conf/dynamicSparkConfig.conf
25/11/26 07:45:18 INFO DatabricksILoop$: Read the dynamic config: ArrayBuffer(SaferConf(spark.databricks.dataLineage.mergeIntoV2Enabled,false,1731558697,241113190524268,1), SaferConf(spark.databricks.cloudFiles.aws.restrictSNSPolicyPrincipalAndAccount,false,1749573002,250606224725199,2), SaferConf(spark.databricks.unityCatalog.clientWithCaller.enabled,true,1753369006,250606151049532,1), SaferConf(spark.databricks.delta.merge.failSourceCachedAfterMaterialization,true,1763647692,251110154546851,1), SaferConf(spark.databricks.autotune.maintenance.enableMetricsForAllUCManagedTables,true,1756330524,250618183020206,1), SaferConf(spark.databricks.sql.jdbcDialectForbidQueriesWithForbiddenKeywords,true,1763644302,250811103850235,6), SaferConf(spark.databricks.unityCatalog.client.UCSEWithMessageTemplateAndClass.enabled,true,1763685074,250930185930488,2), SaferConf(spark.sql.optimizer.optimizeCsvJsonExprs.useSchemaField,false,1728499876,241008194704608,1), SaferConf(spark.databricks.delta.identifierExtraction.newCodePath.enabled,true,1747764696,250221192257794,3), SaferConf(spark.databricks.sql.inlineOuterRefsToConstants.enabled,false,1747429458,250319214018422,2), SaferConf(spark.databricks.autotune.maintenance.client.pushIntervalMinutes,1,1752168673,250118155345061,2), SaferConf(spark.databricks.unityCatalog.client.newErrorClasses.enabled,false,1755882681,250403002450986,1), SaferConf(spark.databricks.sql.jdbcDialectIgnoreQueriesWithForbiddenKeywords,false,1737662132,250123131150571,1), SaferConf(spark.databricks.delta.merge.disableSourceMaterializationNotAllowed,true,1761939217,250429083126347,2)) from /databricks/driver/conf/dynamicSparkConfig.conf, version 1764127249701
25/11/26 07:45:18 INFO LibraryResolutionManager: Preferred maven central mirror is configured to https://maven.aliyun.com/repository/central
25/11/26 07:45:18 WARN OutgoingDirectNotebookBufferRateLimiter$: No value specified for db-outgoing-buffer-throttler-burst. Using default: 100000000000
25/11/26 07:45:18 WARN OutgoingDirectNotebookBufferRateLimiter$: No value specified for db-outgoing-buffer-throttler-steady-rate. Using default: 6000000000
25/11/26 07:45:18 WARN OutgoingDirectNotebookBufferRateLimiter$: No value specified for db-outgoing-buffer-throttler-warning-interval-sec. Using default: 60
25/11/26 07:45:18 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
25/11/26 07:45:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@595dda6d{/StreamingQuery,null,AVAILABLE,@Spark}
25/11/26 07:45:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@98e2a07{/StreamingQuery/json,null,AVAILABLE,@Spark}
25/11/26 07:45:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5b7c79da{/StreamingQuery/statistics,null,AVAILABLE,@Spark}
25/11/26 07:45:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2694b6f6{/StreamingQuery/statistics/json,null,AVAILABLE,@Spark}
25/11/26 07:45:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6423fba7{/static/sql,null,AVAILABLE,@Spark}
25/11/26 07:45:18 INFO DriverCorral: metastoreType: InternalMysqlMetastore(DbMetastoreConfig{host=consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn, port=3306, dbName=organization2559323315997869, user=[REDACTED], proxyHost=consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn, proxyPort=9207, proxyUser=[REDACTED]}), enableMetastoreHealthCheck: true
25/11/26 07:45:19 INFO JettyServer$: Creating thread pool with name ...
25/11/26 07:45:19 INFO JettyServer$: Thread pool created
25/11/26 07:45:19 INFO JettyServer$: Creating thread pool with name ...
25/11/26 07:45:19 INFO JettyServer$: Thread pool created
25/11/26 07:45:19 INFO DriverDaemon: Starting driver daemon...
25/11/26 07:45:19 WARN SparkConfUtils$: Setting the same key twice for spark.hadoop.hive.server2.keystore.password
25/11/26 07:45:19 WARN SparkConfUtils$: Setting the same key twice for spark.databricks.io.directoryCommit.enableLogicalDelete
25/11/26 07:45:19 WARN SparkConfUtils$: Setting the same key twice for spark.hadoop.hive.server2.keystore.path
25/11/26 07:45:19 INFO SparkConfUtils$: Customize spark config according to file /tmp/custom-spark.conf
25/11/26 07:45:19 WARN SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
25/11/26 07:45:19 INFO DriverDaemon$: Attempting to run: 'set up ttyd daemon'
25/11/26 07:45:19 INFO DriverDaemon$: Attempting to run: 'Configuring RStudio daemon'
25/11/26 07:45:19 INFO DriverDaemon$: Resetting the default python executable
25/11/26 07:45:19 INFO Utils: resolved command to be run: List(virtualenv, /local_disk0/.ephemeral_nfs/cluster_libraries/python, -p, /databricks/python/bin/python, --no-download, --no-setuptools, --no-wheel)
25/11/26 07:45:19 INFO PythonEnvCloneHelper$: Created python virtualenv: /local_disk0/.ephemeral_nfs/cluster_libraries/python
25/11/26 07:45:19 INFO Utils: resolved command to be run: List(/databricks/python/bin/python, -c, import sys; dirs=[p for p in sys.path if 'package' in p]; print(' '.join(dirs)))
25/11/26 07:45:19 INFO Utils: resolved command to be run: List(/local_disk0/.ephemeral_nfs/cluster_libraries/python/bin/python, -c, from distutils.sysconfig import get_python_lib; print(get_python_lib()))
25/11/26 07:45:19 INFO PythonEnvCloneHelper$: Created sites.pth at /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sites.pth
25/11/26 07:45:19 INFO ClusterWidePythonEnvManager: Registered /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages with the WatchService sun.nio.fs.LinuxWatchService$LinuxWatchKey@bca34d
25/11/26 07:45:19 INFO DriverDaemon$: Attempting to run: 'Update root virtualenv'
25/11/26 07:45:19 INFO DriverDaemon$: Finished updating /etc/environment
25/11/26 07:45:19 INFO DriverDaemon$$anon$1: Thread to send message is ready
25/11/26 07:45:19 INFO NetstatUtil$: Running netstat -lnpt
25/11/26 07:45:19 INFO NetstatUtil$: netstat -lnpt
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 0.0.0.0:7681            0.0.0.0:*               LISTEN      781/ttyd            
tcp        0      0 127.0.0.1:1101          0.0.0.0:*               LISTEN      2064/R              
tcp        0      0 127.0.0.1:1100          0.0.0.0:*               LISTEN      953/R               
tcp        0      0 0.0.0.0:2812            0.0.0.0:*               LISTEN      78/monit            
tcp        0      0 127.0.0.53:53           0.0.0.0:*               LISTEN      47/systemd-resolved 
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      69/sshd: /usr/sbin/ 
tcp6       0      0 10.139.64.5:36197       :::*                    LISTEN      5191/java           
tcp6       0      0 :::15001                :::*                    LISTEN      5191/java           
tcp6       0      0 :::15002                :::*                    LISTEN      5191/java           
tcp6       0      0 :::7071                 :::*                    LISTEN      332/java            
tcp6       0      0 :::6060                 :::*                    LISTEN      332/java            
tcp6       0      0 10.139.64.5:42943       :::*                    LISTEN      5191/java           
tcp6       0      0 10.139.64.5:7077        :::*                    LISTEN      430/java            
tcp6       0      0 10.139.64.5:40000       :::*                    LISTEN      430/java            
tcp6       0      0 10.139.64.5:40001       :::*                    LISTEN      5191/java           
tcp6       0      0 :::2812                 :::*                    LISTEN      78/monit            
tcp6       0      0 :::10000                :::*                    LISTEN      5191/java           
tcp6       0      0 :::22                   :::*                    LISTEN      69/sshd: /usr/sbin/ 
tcp6       0      0 :::1021                 :::*                    LISTEN      168/wsfs            
tcp6       0      0 :::1017                 :::*                    LISTEN      168/wsfs            
tcp6       0      0 :::1015                 :::*                    LISTEN      199/goofys-dbr      

25/11/26 07:45:19 INFO Server: jetty-9.4.46.v20220331; built: 2022-03-31T16:38:08.030Z; git: bc17a0369a11ecf40bb92c839b9ef0a8ac50ea18; jvm 1.8.0_462-b08
25/11/26 07:45:19 INFO AbstractConnector: Started ServerConnector@27631923{HTTP/1.1, (http/1.1)}{0.0.0.0:6061}
25/11/26 07:45:19 INFO Server: Started @26817ms
25/11/26 07:45:19 INFO Server: jetty-9.4.46.v20220331; built: 2022-03-31T16:38:08.030Z; git: bc17a0369a11ecf40bb92c839b9ef0a8ac50ea18; jvm 1.8.0_462-b08
25/11/26 07:45:19 INFO SslContextFactory: x509=X509@3689931e(1,h=[az-chinanorth2.workers.prod.ns.databricks.com],a=[],w=[]) for Server@757908d8[provider=null,keyStore=null,trustStore=null]
25/11/26 07:45:19 INFO SslContextFactory: No Cipher Suite matching 'TLS_CHACHA20_POLY1305_SHA256' is supported
25/11/26 07:45:19 WARN config: Weak cipher suite TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA enabled for Server@757908d8[provider=null,keyStore=null,trustStore=null]
25/11/26 07:45:19 WARN config: Weak cipher suite TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA enabled for Server@757908d8[provider=null,keyStore=null,trustStore=null]
25/11/26 07:45:19 INFO AbstractConnector: Started ServerConnector@1ecb3cde{SSL, (ssl, http/1.1)}{0.0.0.0:6062}
25/11/26 07:45:19 INFO Server: Started @26878ms
25/11/26 07:45:19 INFO DriverDaemon: Started comm channel server
25/11/26 07:45:19 INFO DriverDaemon: Driver daemon started.
25/11/26 07:45:20 INFO DynamicInfoServiceConf: Configured feature flag data source LaunchDarkly
25/11/26 07:45:20 INFO DynamicInfoServiceConf: Configured feature flag data source LaunchDarkly
25/11/26 07:45:20 WARN DynamicInfoServiceConf: REGION environment variable is not defined. getConfForCurrentRegion will always return default value
25/11/26 07:45:20 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.139.64.4:34964) with ID 0, ResourceProfileId 0
25/11/26 07:45:21 INFO Utils: resolved command to be run: WrappedArray(getconf, PAGESIZE)
25/11/26 07:45:21 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:36153 with 4.4 GiB RAM, BlockManagerId(0, 10.139.64.4, 36153, None)
25/11/26 07:45:21 WARN SQLConf: The SQL config 'spark.sql.hive.convertCTAS' has been deprecated in Spark v3.1 and may be removed in the future. Set 'spark.sql.legacy.createHiveTableByDefault' to false instead.
25/11/26 07:45:21 WARN SQLConf: The SQL config 'spark.sql.hive.convertCTAS' has been deprecated in Spark v3.1 and may be removed in the future. Set 'spark.sql.legacy.createHiveTableByDefault' to false instead.
25/11/26 07:45:21 INFO DriverCorral: Loading the root classloader
25/11/26 07:45:21 INFO DriverCorral: Starting sql repl ReplId-4e367-d5e24-ed2f4-7
25/11/26 07:45:21 INFO DriverCorral: Starting sql repl ReplId-7ed12-bb7f0-a8e2a-a
25/11/26 07:45:21 INFO DriverCorral: Starting sql repl ReplId-68d27-dc7e7-9f1b4-f
25/11/26 07:45:21 INFO DriverCorral: Starting sql repl ReplId-72985-76400-84864-5
25/11/26 07:45:21 INFO SQLDriverWrapper: setupRepl:ReplId-68d27-dc7e7-9f1b4-f: finished to load
25/11/26 07:45:21 INFO SQLDriverWrapper: setupRepl:ReplId-7ed12-bb7f0-a8e2a-a: finished to load
25/11/26 07:45:21 INFO SQLDriverWrapper: setupRepl:ReplId-72985-76400-84864-5: finished to load
25/11/26 07:45:21 INFO SQLDriverWrapper: setupRepl:ReplId-4e367-d5e24-ed2f4-7: finished to load
25/11/26 07:45:21 INFO DriverCorral: Starting sql repl ReplId-2081c-b6a22-9b69d-9
25/11/26 07:45:22 INFO SQLDriverWrapper: setupRepl:ReplId-2081c-b6a22-9b69d-9: finished to load
25/11/26 07:45:22 WARN SQLConf: The SQL config 'spark.sql.hive.convertCTAS' has been deprecated in Spark v3.1 and may be removed in the future. Set 'spark.sql.legacy.createHiveTableByDefault' to false instead.
25/11/26 07:45:22 WARN SQLConf: The SQL config 'spark.sql.hive.convertCTAS' has been deprecated in Spark v3.1 and may be removed in the future. Set 'spark.sql.legacy.createHiveTableByDefault' to false instead.
25/11/26 07:45:22 INFO DriverCorral: Starting r repl ReplId-47e29-ebcb1-8378e-8
25/11/26 07:45:22 INFO ROutputStreamHandler: Connection succeeded on port 43559
25/11/26 07:45:22 INFO ROutputStreamHandler: Connection succeeded on port 37979
25/11/26 07:45:22 INFO RDriverLocal: 1. RDriverLocal.82a93214-fec2-4acd-8ade-feafba71d0b5: object created with for ReplId-47e29-ebcb1-8378e-8.
25/11/26 07:45:22 INFO RDriverLocal: 2. RDriverLocal.82a93214-fec2-4acd-8ade-feafba71d0b5: initializing ...
25/11/26 07:45:22 INFO RDriverLocal: 3. RDriverLocal.82a93214-fec2-4acd-8ade-feafba71d0b5: started RBackend thread on port 35781
25/11/26 07:45:22 INFO RDriverLocal: 4. RDriverLocal.82a93214-fec2-4acd-8ade-feafba71d0b5: waiting for SparkR to be installed ...
25/11/26 07:45:31 INFO RDriverLocal$: SparkR installation completed.
25/11/26 07:45:31 INFO RDriverLocal: 5. RDriverLocal.82a93214-fec2-4acd-8ade-feafba71d0b5: launching R process ...
25/11/26 07:45:31 INFO RDriverLocal: 6. RDriverLocal.82a93214-fec2-4acd-8ade-feafba71d0b5: cgroup isolation disabled, not placing R process in REPL cgroup.
25/11/26 07:45:31 INFO RDriverLocal$: Skip port 1100
25/11/26 07:45:31 INFO RDriverLocal$: Skip port 1101
25/11/26 07:45:31 INFO RDriverLocal: 7. RDriverLocal.82a93214-fec2-4acd-8ade-feafba71d0b5: starting R process on port 1102 (attempt 1) ...
25/11/26 07:45:31 INFO RDriverLocal$: Debugging command for R process builder: SIMBASPARKINI=/etc/simba.sparkodbc.ini R_LIBS=/local_disk0/.ephemeral_nfs/envs/rEnv-2ef4bc8f-559c-43f7-9d27-5f8ca887bdcd:/databricks/spark/R/lib:/local_disk0/.ephemeral_nfs/cluster_libraries/r LD_LIBRARY_PATH=/opt/simba/sparkodbc/lib/64/ SPARKR_BACKEND_CONNECTION_TIMEOUT=604800 DB_STREAM_BEACON_STRING_START=DATABRICKS_STREAM_START-ReplId-47e29-ebcb1-8378e-8 DB_STDOUT_STREAM_PORT=43559 SPARKR_BACKEND_AUTH_SECRET=e7f67506ad530e2d6644c5c1676aaeecd9585fedeee8cca8789426251cf7a966 DB_STREAM_BEACON_STRING_END=DATABRICKS_STREAM_END-ReplId-47e29-ebcb1-8378e-8 EXISTING_SPARKR_BACKEND_PORT=35781 ODBCINI=/etc/odbc.ini DB_STDERR_STREAM_PORT=37979 /bin/bash /local_disk0/tmp/_startR.sh3878632621231690076resource.r /local_disk0/tmp/_rServeScript.r8358262645126220461resource.r 1102 None
25/11/26 07:45:31 INFO RDriverLocal: 8. RDriverLocal.82a93214-fec2-4acd-8ade-feafba71d0b5: setting up BufferedStreamThread with bufferSize: 1000.
25/11/26 07:45:32 INFO RDriverLocal: 9. RDriverLocal.82a93214-fec2-4acd-8ade-feafba71d0b5: R process started with RServe listening on port 1102.
25/11/26 07:45:32 INFO RDriverLocal: 10. RDriverLocal.82a93214-fec2-4acd-8ade-feafba71d0b5: starting interpreter to talk to R process ...
25/11/26 07:45:33 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
25/11/26 07:45:33 INFO ROutputStreamHandler: Successfully connected to stdout in the RShell.
25/11/26 07:45:33 INFO ROutputStreamHandler: Successfully connected to stderr in the RShell.
25/11/26 07:45:33 INFO RDriverLocal: 11. RDriverLocal.82a93214-fec2-4acd-8ade-feafba71d0b5: R interpreter is connected.
25/11/26 07:45:33 INFO RDriverWrapper: setupRepl:ReplId-47e29-ebcb1-8378e-8: finished to load
25/11/26 07:46:18 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:46:19 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:47:18 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:47:19 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:48:18 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:48:19 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:49:18 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:49:19 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:50:06 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:3306/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:50:06 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:50:06 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:50:06 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:50:06 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:50:06 INFO MetastoreMonitor: Metastore healthcheck successful (connection duration = 217 milliseconds)
25/11/26 07:50:06 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:9207/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:50:06 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:50:06 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:50:06 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:50:06 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:50:06 INFO MetastoreMonitor: PoPProxy healthcheck successful (connection duration = 216 milliseconds)
25/11/26 07:50:18 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:50:19 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:50:19 INFO SecuredHiveExternalCatalog: creating hiveClient from java.lang.Throwable
	at org.apache.spark.sql.hive.HiveExternalCatalog.client$lzycompute(HiveExternalCatalog.scala:81)
	at org.apache.spark.sql.hive.HiveExternalCatalog.client(HiveExternalCatalog.scala:79)
	at org.apache.spark.sql.hive.HiveExternalCatalog.maybeSynchronized(HiveExternalCatalog.scala:115)
	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$withClient$1(HiveExternalCatalog.scala:155)
	at com.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:397)
	at com.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)
	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:154)
	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:326)
	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:309)
	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:299)
	at com.databricks.backend.daemon.driver.DriverCorral.$anonfun$new$5(DriverCorral.scala:485)
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:41)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:100)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:105)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:104)
	at com.databricks.backend.daemon.driver.DriverCorral.$anonfun$new$4(DriverCorral.scala:485)
	at com.databricks.backend.daemon.driver.DriverCorral.$anonfun$new$4$adapted(DriverCorral.scala:484)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.backend.daemon.driver.DriverCorral.$anonfun$new$3(DriverCorral.scala:484)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:657)
	at com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:678)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.threading.NamedTimer$$anon$1.withAttributionContext(NamedTimer.scala:95)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)
	at com.databricks.threading.NamedTimer$$anon$1.withAttributionTags(NamedTimer.scala:95)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:652)
	at com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:569)
	at com.databricks.threading.NamedTimer$$anon$1.recordOperationWithResultTags(NamedTimer.scala:95)
	at com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:560)
	at com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:528)
	at com.databricks.threading.NamedTimer$$anon$1.recordOperation(NamedTimer.scala:95)
	at com.databricks.threading.NamedTimer$$anon$1.$anonfun$run$2(NamedTimer.scala:104)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)
	at com.databricks.threading.NamedTimer$$anon$1.withAttributionContext(NamedTimer.scala:95)
	at com.databricks.logging.UsageLogging.disableTracing(UsageLogging.scala:1380)
	at com.databricks.logging.UsageLogging.disableTracing$(UsageLogging.scala:1379)
	at com.databricks.threading.NamedTimer$$anon$1.disableTracing(NamedTimer.scala:95)
	at com.databricks.threading.NamedTimer$$anon$1.$anonfun$run$1(NamedTimer.scala:103)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.UntrustedUtils$.tryLog(UntrustedUtils.scala:109)
	at com.databricks.threading.NamedTimer$$anon$1.run(NamedTimer.scala:102)
	at java.util.TimerThread.mainLoop(Timer.java:555)
	at java.util.TimerThread.run(Timer.java:505)

25/11/26 07:50:19 WARN SQLConf: The SQL config 'spark.sql.hive.convertCTAS' has been deprecated in Spark v3.1 and may be removed in the future. Set 'spark.sql.legacy.createHiveTableByDefault' to false instead.
25/11/26 07:50:19 INFO HiveUtils: Initializing HiveMetastoreConnection version 0.13.0 using file:/databricks/databricks-hive/----ws_3_3--mvn--hadoop3--org.apache.logging.log4j--log4j-slf4j-impl--org.apache.logging.log4j__log4j-slf4j-impl__2.18.0.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.geronimo.specs--geronimo-jaspic_1.0_spec--org.apache.geronimo.specs__geronimo-jaspic_1.0_spec__1.0.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--javax.transaction--transaction-api--javax.transaction__transaction-api__1.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.antlr--ST4--org.antlr__ST4__4.0.4.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.codehaus.groovy--groovy-all--org.codehaus.groovy__groovy-all__2.1.6.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--jline--jline--jline__jline__0.9.94.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--com.esotericsoftware.minlog--minlog--com.esotericsoftware.minlog__minlog__1.2.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--commons-codec--commons-codec--commons-codec__commons-codec__1.8.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive--hive-common--org.apache.hive__hive-common__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--commons-io--commons-io--commons-io__commons-io__2.5.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--oro--oro--oro__oro__2.0.8.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--antlr--antlr--antlr__antlr__2.7.7.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.ant--ant-launcher--org.apache.ant__ant-launcher__1.9.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.eclipse.jetty.aggregate--jetty-all--org.eclipse.jetty.aggregate__jetty-all__7.6.0.v20120127.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.derby--derby--org.apache.derby__derby__10.10.1.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--net.sf.jpam--jpam--net.sf.jpam__jpam__1.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.commons--commons-lang3--org.apache.commons__commons-lang3__3.4.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--commons-collections--commons-collections--commons-collections__commons-collections__3.2.2.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--commons-cli--commons-cli--commons-cli__commons-cli__1.2.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive--hive-metastore--org.apache.hive__hive-metastore__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--stax--stax-api--stax__stax-api__1.0.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--com.zaxxer--HikariCP--com.zaxxer__HikariCP__2.5.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--com.esotericsoftware.reflectasm--reflectasm-shaded--com.esotericsoftware.reflectasm__reflectasm-shaded__1.07.jar:file:/databricks/databricks-hive/----ws_3_3--mvn--hadoop3--org.apache.logging.log4j--log4j-1.2-api--org.apache.logging.log4j__log4j-1.2-api__2.18.0.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive--hive-jdbc--org.apache.hive__hive-jdbc__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive--hive-exec--org.apache.hive__hive-exec__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--javax.transaction--jta--javax.transaction__jta__1.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.ow2.asm--asm--org.ow2.asm__asm__4.0.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.geronimo.specs--geronimo-annotation_1.0_spec--org.apache.geronimo.specs__geronimo-annotation_1.0_spec__1.1.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.objenesis--objenesis--org.objenesis__objenesis__1.2.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.codehaus.jackson--jackson-core-asl--org.codehaus.jackson__jackson-core-asl__1.9.13.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive--hive-beeline--org.apache.hive__hive-beeline__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.velocity--velocity--org.apache.velocity__velocity__1.5.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive--hive-ant--org.apache.hive__hive-ant__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.xerial.snappy--snappy-java--org.xerial.snappy__snappy-java__1.0.5.jar:file:/databricks/databricks-hive/----ws_3_3--mvn--hadoop3--org.slf4j--slf4j-api--org.slf4j__slf4j-api__1.7.36.jar:file:/databricks/databricks-hive/----ws_3_3--mvn--hadoop3--org.apache.logging.log4j--log4j-api--org.apache.logging.log4j__log4j-api__2.18.0.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--javax.activation--activation--javax.activation__activation__1.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.geronimo.specs--geronimo-jta_1.1_spec--org.apache.geronimo.specs__geronimo-jta_1.1_spec__1.1.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.antlr--antlr-runtime--org.antlr__antlr-runtime__3.4.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive.shims--hive-shims-0.23--org.apache.hive.shims__hive-shims-0.23__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.thrift--libthrift--org.apache.thrift__libthrift__0.9.2.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.datanucleus--datanucleus-rdbms--org.datanucleus__datanucleus-rdbms__4.1.19.jar:file:/databricks/databricks-hive/manifest.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--asm--asm--asm__asm__3.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.mortbay.jetty--jetty--org.mortbay.jetty__jetty__6.1.26.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--com.thoughtworks.paranamer--paranamer--com.thoughtworks.paranamer__paranamer__2.8.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive--hive-shims--org.apache.hive__hive-shims__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.avro--avro--org.apache.avro__avro__1.7.5.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.ant--ant--org.apache.ant__ant__1.9.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive.shims--hive-shims-0.20S--org.apache.hive.shims__hive-shims-0.20S__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--com.google.code.findbugs--jsr305--com.google.code.findbugs__jsr305__1.3.9.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--asm--asm-tree--asm__asm-tree__3.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.zookeeper--zookeeper--org.apache.zookeeper__zookeeper__3.4.5.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.datanucleus--javax.jdo--org.datanucleus__javax.jdo__3.2.0-m3.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--commons-lang--commons-lang--commons-lang__commons-lang__2.4.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--commons-httpclient--commons-httpclient--commons-httpclient__commons-httpclient__3.0.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.codehaus.jackson--jackson-mapper-asl--org.codehaus.jackson__jackson-mapper-asl__1.9.13.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.mortbay.jetty--servlet-api--org.mortbay.jetty__servlet-api__2.5-20081211.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--asm--asm-commons--asm__asm-commons__3.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--com.jolbox--bonecp--com.jolbox__bonecp__0.8.0.RELEASE.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--javax.mail--mail--javax.mail__mail__1.4.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--junit--junit--junit__junit__3.8.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive.shims--hive-shims-0.20--org.apache.hive.shims__hive-shims-0.20__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--commons-logging--commons-logging--commons-logging__commons-logging__1.1.3.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.httpcomponents--httpclient--org.apache.httpcomponents__httpclient__4.4.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive--hive-service--org.apache.hive__hive-service__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.datanucleus--datanucleus-core--org.datanucleus__datanucleus-core__4.1.17.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive--hive-serde--org.apache.hive__hive-serde__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--com.google.guava--guava--com.google.guava__guava__11.0.2.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.antlr--stringtemplate--org.antlr__stringtemplate__3.2.1.jar:file:/databricks/databricks-hive/----ws_3_3--mvn--hadoop3--org.apache.logging.log4j--log4j-core--org.apache.logging.log4j__log4j-core__2.18.0.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.commons--commons-compress--org.apache.commons__commons-compress__1.9.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--javax.jdo--jdo-api--javax.jdo__jdo-api__3.0.1.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--javax.servlet--servlet-api--javax.servlet__servlet-api__2.5.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive--hive-cli--org.apache.hive__hive-cli__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--com.esotericsoftware.kryo--kryo--com.esotericsoftware.kryo__kryo__2.21.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.thrift--libfb303--org.apache.thrift__libfb303__0.9.0.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.datanucleus--datanucleus-api-jdo--org.datanucleus__datanucleus-api-jdo__4.2.4.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive.shims--hive-shims-common-secure--org.apache.hive.shims__hive-shims-common-secure__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.mortbay.jetty--jetty-util--org.mortbay.jetty__jetty-util__6.1.26.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.httpcomponents--httpcore--org.apache.httpcomponents__httpcore__4.2.5.jar:file:/databricks/databricks-hive/----ws_3_3--maven-trees--hive-metastore-databricks-log4j2--org.apache.hive.shims--hive-shims-common--org.apache.hive.shims__hive-shims-common__0.13.1-databricks-10.jar:file:/databricks/databricks-hive/bonecp-configs.jar
25/11/26 07:50:19 INFO PoolingHiveClient: Hive metastore connection pool implementation is HikariCP
25/11/26 07:50:19 INFO LocalHiveClientsPool: Create Hive Metastore client pool of size 20
25/11/26 07:50:19 INFO DriverCorral: DBFS health check ok
25/11/26 07:50:19 INFO HiveClientImpl: Warehouse location for Hive client (version 0.13.1) is dbfs:/user/hive/warehouse
25/11/26 07:50:19 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
25/11/26 07:50:19 INFO ObjectStore: ObjectStore, initialize called
25/11/26 07:50:19 INFO Persistence: Property datanucleus.fixedDatastore unknown - will be ignored
25/11/26 07:50:19 INFO Persistence: Property datanucleus.connectionPool.idleTimeout unknown - will be ignored
25/11/26 07:50:19 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
25/11/26 07:50:19 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
25/11/26 07:50:19 INFO HikariDataSource: HikariPool-1 - Started.
25/11/26 07:50:20 INFO HikariDataSource: HikariPool-2 - Started.
25/11/26 07:50:20 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
25/11/26 07:50:21 INFO ObjectStore: Initialized ObjectStore
25/11/26 07:50:21 INFO HiveMetaStore: Added admin role in metastore
25/11/26 07:50:21 INFO HiveMetaStore: Added public role in metastore
25/11/26 07:50:21 INFO HiveMetaStore: No user is added in admin role, since config is empty
25/11/26 07:50:21 INFO HiveMetaStore: 0: get_database: default
25/11/26 07:50:21 INFO audit: ugi=root	ip=unknown-ip-addr	cmd=get_database: default	
25/11/26 07:50:21 INFO HiveMetaStore: 0: get_database: default
25/11/26 07:50:21 INFO audit: ugi=root	ip=unknown-ip-addr	cmd=get_database: default	
25/11/26 07:50:21 INFO DriverCorral: Metastore health check ok
25/11/26 07:51:18 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:51:19 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:52:18 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:52:19 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:53:18 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:53:19 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:54:18 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:54:19 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:55:06 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:3306/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:55:06 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:55:06 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:55:06 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:55:06 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:55:06 INFO MetastoreMonitor: Metastore healthcheck successful (connection duration = 215 milliseconds)
25/11/26 07:55:06 INFO DataSourceFactory$: DataSource Jdbc URL: jdbc:mariadb://consolidated-chinanorth3-prod-metastore-0.mysql.database.chinacloudapi.cn:9207/organization2559323315997869?useSSL=true&sslMode=VERIFY_CA&disableSslHostnameVerification=true&trustServerCertificate=false&serverSslCert=/databricks/common/mysql-ssl-ca-cert.crt
25/11/26 07:55:06 INFO HikariDataSource: metastore-monitor - Starting...
25/11/26 07:55:06 INFO HikariDataSource: metastore-monitor - Start completed.
25/11/26 07:55:07 INFO HikariDataSource: metastore-monitor - Shutdown initiated...
25/11/26 07:55:07 INFO HikariDataSource: metastore-monitor - Shutdown completed.
25/11/26 07:55:07 INFO MetastoreMonitor: PoPProxy healthcheck successful (connection duration = 197 milliseconds)
25/11/26 07:55:18 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:55:18 INFO DriverCorral: DBFS health check ok
25/11/26 07:55:18 INFO HiveMetaStore: 0: get_database: default
25/11/26 07:55:18 INFO audit: ugi=root	ip=unknown-ip-addr	cmd=get_database: default	
25/11/26 07:55:19 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:55:19 INFO DriverCorral: Metastore health check ok
25/11/26 07:56:18 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:56:19 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:57:18 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:57:19 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:58:18 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:58:19 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
25/11/26 07:59:18 INFO DriverCorral: Received SAFEr configs with version 1764127249701
25/11/26 07:59:19 ERROR CommandLineHelper$: Command [REDACTED] failed with exit code 1 out: err:
